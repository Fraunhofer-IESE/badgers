{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Badgers","text":"<p>Badgers is a python library for generating bad data - more precisely: to augment existing data with data quality deficits such as outliers, missing values, noise, etc.</p> <p>As a basic principle, badgers provides a set of objects (called generators) that follow a simple API: each generator provides a <code>generator(X,y,**params)</code> function that takes as argument <code>X</code> (the input features), <code>y</code> (the class labels, the regression target, or None), a set of specific parameters and returns the transformed <code>Xt</code> and <code>yt</code>.</p> <p>Why would you generate bad data? you might ask (and you should! isn't that honestly a strange idea?).</p> <p>We think data quality has to be taken seriously. With badgers we hope to provide a tool that can help manage and understand the impact of data quality in a systematic and controlled way.</p> <p>You might think of using badgers for things like robustness analysis (i.e., how does my model or my data analysis pipeline performs in the presence of noise, outliers, missing values, data drift, etc.), or for chaos data engineering (e.g., what happens if we inject quality defects into production systems?).</p> <p>Badgers provides a set of predefined generators for different modalities (tabular data, time series, text, etc.) and different data quality problems (outliers, noise, drift, etc.). Of course many data quality problems are use case dependent and it is not possible to implement all generators. Therefore, the idea is that badgers can serve as a structure for developing novel generators (see how to develop novel generators in the dev-tutorials section).</p> <p>Want to try badgers? Then go to the getting started section or dive into the tutorials section.</p>"},{"location":"about/","title":"About","text":""},{"location":"about/#thanks-to","title":"Thanks to:","text":"<p>The development of badgers was initially driven by Julien Siebert at the Data Science Department of the Fraunhofer Institute for Experimental Software Engineering (IESE) in Kaiserslautern, Germany.</p> <p>The original idea came during internal discussions with Patricia Kelbert, Adam Trendowicz, and Michael Kl\u00e4s.</p> <p>A big thanks to Daniel Seifert for taking the time to investigate and automate all the many things that make our lives as package contributors easier.</p>"},{"location":"about/#citing-badgers","title":"Citing Badgers","text":"<p>If you use badgers in scientific publications, you can cite the following paper:</p> <p>Julien Siebert, Daniel Seifert, Patricia Kelbert, Michael Kl\u00e4s, Adam Trendowicz (2023). Badgers: generating data quality deficits with Python. https://arxiv.org/abs/2307.04468</p> <pre><code>@misc{siebert2023badgers,\n      title={Badgers: generating data quality deficits with Python}, \n      author={Julien Siebert and Daniel Seifert and Patricia Kelbert and Michael Kl\u00e4s and Adam Trendowicz},\n      year={2023},\n      eprint={2307.04468},\n      archivePrefix={arXiv},\n      primaryClass={cs.LG}\n}\n</code></pre>"},{"location":"about/#read-more","title":"Read more","text":"<p>https://www.iese.fraunhofer.de/blog/badgers-open-source-python-bibliothek/ (German)</p> <p>https://www.iese.fraunhofer.de/blog/datenqualitaet-machine-learning/ (German)</p>"},{"location":"about/#contributing-to-badgers","title":"Contributing to Badgers","text":"<p>Every contribution is welcome, please have a look at dev-tutorials section and CONTRIBUTING.md for more info.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>See https://github.com/Fraunhofer-IESE/badgers/releases</p>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"<p>Code adapted from: https://mkdocstrings.github.io/recipes/</p> In\u00a0[\u00a0]: Copied! <pre>from pathlib import Path\nimport mkdocs_gen_files\n</pre> from pathlib import Path import mkdocs_gen_files In\u00a0[\u00a0]: Copied! <pre>nav = mkdocs_gen_files.Nav()\n</pre> nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>src_dir = 'badgers'\nreference_dir = 'reference'\nfor path in sorted(Path(src_dir).rglob('*.py')):\n    module_path = path.with_suffix('')\n    doc_path = path.with_suffix('.md')\n    full_doc_path = Path(reference_dir, doc_path)\n\n    parts = tuple(module_path.parts)\n    if parts[-1] == '__init__':\n        parts = parts[:-1]\n        doc_path = doc_path.with_name('index.md')\n        full_doc_path = full_doc_path.with_name('index.md')\n    elif parts[-1] == '__main__':\n        continue\n\n    nav[parts] = doc_path.as_posix()\n\n    with mkdocs_gen_files.open(full_doc_path, 'w') as fd:\n        identifier = '.'.join(parts)\n        print('::: ' + identifier, file=fd)\n</pre> src_dir = 'badgers' reference_dir = 'reference' for path in sorted(Path(src_dir).rglob('*.py')):     module_path = path.with_suffix('')     doc_path = path.with_suffix('.md')     full_doc_path = Path(reference_dir, doc_path)      parts = tuple(module_path.parts)     if parts[-1] == '__init__':         parts = parts[:-1]         doc_path = doc_path.with_name('index.md')         full_doc_path = full_doc_path.with_name('index.md')     elif parts[-1] == '__main__':         continue      nav[parts] = doc_path.as_posix()      with mkdocs_gen_files.open(full_doc_path, 'w') as fd:         identifier = '.'.join(parts)         print('::: ' + identifier, file=fd) In\u00a0[\u00a0]: Copied! <pre>with mkdocs_gen_files.open(f'{reference_dir}/SUMMARY.md', 'w') as nav_file:\n    nav_file.writelines(nav.build_literate_nav())\n</pre> with mkdocs_gen_files.open(f'{reference_dir}/SUMMARY.md', 'w') as nav_file:     nav_file.writelines(nav.build_literate_nav())"},{"location":"getting-started/","title":"Getting started","text":"<p>Install <code>badgers</code> with pip:</p> <pre><code>pip install badgers\n</code></pre> <p>Import badgers as any other library and start using it:</p> <pre><code>from sklearn.datasets import make_blobs\nfrom badgers.generators.tabular_data.noise import GaussianNoiseGenerator\n\nX, y = make_blobs()\ntrf = GaussianNoiseGenerator()\nXt, yt = trf.generate(X, y, noise_std=0.5)\n</code></pre> <p>More examples are available in the tutorials section.</p> <p>The API documentation is also available in the API section.</p> <p>Those interested in developing their own generators and/or contribute to badgers can have a look at the dev-tutorials section, and CONTRIBUTING.md.</p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#other-python-packages","title":"Other python packages","text":""},{"location":"resources/#data-generation","title":"Data generation","text":"<p>Faker: a Python package that generates fake data for you. https://faker.readthedocs.io </p>"},{"location":"resources/#fake-tabular-data-generation","title":"Fake tabular data generation","text":"<ul> <li>https://gitlab.com/healthdatahub/tsfaker</li> <li>https://github.com/tirthajyoti/pydbgen</li> <li>https://github.com/plaitpy/plaitpy</li> <li>https://github.com/EDS-APHP-legacy/pySyntheticDatasetGenerator</li> </ul>"},{"location":"resources/#fake-time-series-generation","title":"Fake time series generation","text":"<ul> <li>https://github.com/aphp/dsfaker</li> </ul>"},{"location":"resources/#data-augmentation","title":"Data Augmentation","text":""},{"location":"resources/#natural-language-processing","title":"Natural Language Processing","text":"<p>NLPaug: Data augmentation for NLP https://makcedward.github.io/ </p>"},{"location":"resources/#computer-vision","title":"Computer vision","text":"<p>Augmentor: a Python package designed to aid the augmentation and artificial generation of image data for machine learning tasks. https://augmentor.readthedocs.io/en/stable/</p> <p>Albumentations: Fast image augmentation library and an easy-to-use wrapper around other libraries. https://github.com/albumentations-team/albumentations</p> <p>Imgaug: a library for image augmentation in machine learning experiments.  https://imgaug.readthedocs.io/en/latest/</p>"},{"location":"resources/#data-quality-issues-detection","title":"Data quality issues detection","text":"<p>Pyod:  A Comprehensive and Scalable Python Library for Outlier Detection (Anomaly Detection) https://pyod.readthedocs.io </p> <p>Autoimpute: a Python package for analysis and implementation of Imputation Methods. https://autoimpute.readthedocs.io/en/latest/</p> <p>Imbalanced-learn: a Python Package to Tackle the Curse of Imbalanced Datasets in Machine Learning https://imbalanced-learn.org/stable/</p>"},{"location":"resources/#blog-posts","title":"Blog posts","text":"<p>https://neptune.ai/blog/data-augmentation-nlp</p> <p>https://neptune.ai/blog/data-augmentation-in-python</p>"},{"location":"resources/#scientific-literature","title":"Scientific literature","text":""},{"location":"resources/#outliers-generation","title":"Outliers generation","text":"<p>Georg Steinbuss and Klemens B\u00f6hm. 2021. Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey. ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages. https://doi.org/10.1145/3447822</p> <p>Marian Turowski, Moritz Weber, Oliver Neumann, Benedikt Heidrich, Kaleb Phipps, H\u00fcseyin K. \u00c7akmak, Ralf Mikut, and Veit Hagenmeyer. 2022. Modeling and generating synthetic anomalies for energy and power time series. In Proceedings of the Thirteenth ACM International Conference on Future Energy Systems (e-Energy '22). Association for Computing Machinery, New York, NY, USA, 471\u2013484. https://doi.org/10.1145/3538637.3539760</p>"},{"location":"resources/#missing-values","title":"Missing Values","text":"<p>Santos, M.S., Pereira, R.C., Costa, A.F., Soares, J.P., Santos, J., &amp; Abreu, P.H. (2019). Generating Synthetic Missing Data: A Review by Missing Mechanism. IEEE Access, 7, 11651-11667. https://ieeexplore.ieee.org/document/8605316</p>"},{"location":"dev/Create-New-Tabular-Generators/","title":"Creating a (tabular_data) generator: Scenario","text":"In\u00a0[1]: Copied! <pre>import badgers\n</pre> import badgers  In\u00a0[2]: Copied! <pre>from badgers.core.base import GeneratorMixin\n</pre> from badgers.core.base import GeneratorMixin In\u00a0[3]: Copied! <pre>class MyGenerator(GeneratorMixin):\n\n    def __init__(self):\n        \"\"\"Constructor code goes here\"\"\"\n        pass\n\n    def generate(self, X, y, **params):\n        \"\"\"Generate code goes here\"\"\"\n        pass\n</pre> class MyGenerator(GeneratorMixin):      def __init__(self):         \"\"\"Constructor code goes here\"\"\"         pass      def generate(self, X, y, **params):         \"\"\"Generate code goes here\"\"\"         pass In\u00a0[4]: Copied! <pre>import numpy as np\nfrom numpy.random import default_rng\n</pre> import numpy as np from numpy.random import default_rng In\u00a0[5]: Copied! <pre>class MyGenerator(GeneratorMixin):\n\n    def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    def generate(self, X, y, **params):\n        \"\"\"Generate code goes here\"\"\"\n        pass\n</pre> class MyGenerator(GeneratorMixin):      def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):         \"\"\"         :param random_generator: A random generator         \"\"\"         self.random_generator = random_generator      def generate(self, X, y, **params):         \"\"\"Generate code goes here\"\"\"         pass In\u00a0[6]: Copied! <pre>from badgers.core.decorators.tabular_data import preprocess_inputs\n</pre> from badgers.core.decorators.tabular_data import preprocess_inputs In\u00a0[7]: Copied! <pre>class MyGenerator(GeneratorMixin):\n\n    def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @preprocess_inputs\n    def generate(self, X, y, **params):\n        \"\"\"Generate code goes here\"\"\"\n        pass\n</pre> class MyGenerator(GeneratorMixin):      def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):         \"\"\"         :param random_generator: A random generator         \"\"\"         self.random_generator = random_generator      @preprocess_inputs     def generate(self, X, y, **params):         \"\"\"Generate code goes here\"\"\"         pass In\u00a0[8]: Copied! <pre>from sklearn.preprocessing import StandardScaler\n</pre> from sklearn.preprocessing import StandardScaler  In\u00a0[9]: Copied! <pre>class MyGenerator(GeneratorMixin):\n\n    def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @preprocess_inputs\n    def generate(self, X, y, **params):\n        \"\"\"Generate code goes here\"\"\"\n        # instanciating a StandardScaler object to standardize X and \"de\"-standardize X\n        scaler = StandardScaler()\n        Xt = scaler.fit_transform(X)\n        # Generate some noise from the Poisson distribution\n        noise = self.random_generator.poisson(size=X.shape)\n        # multiply Xt with noise\n        Xt *= noise\n        # inverse the standardization transformation\n        Xt = scaler.inverse_transform(Xt)\n        # cast Xt to a pandas DataFrame\n        Xt = pd.DataFrame(data=Xt, columns=X.columns, index=X.index)\n        # return Xt and y\n        return Xt, y\n</pre> class MyGenerator(GeneratorMixin):      def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):         \"\"\"         :param random_generator: A random generator         \"\"\"         self.random_generator = random_generator      @preprocess_inputs     def generate(self, X, y, **params):         \"\"\"Generate code goes here\"\"\"         # instanciating a StandardScaler object to standardize X and \"de\"-standardize X         scaler = StandardScaler()         Xt = scaler.fit_transform(X)         # Generate some noise from the Poisson distribution         noise = self.random_generator.poisson(size=X.shape)         # multiply Xt with noise         Xt *= noise         # inverse the standardization transformation         Xt = scaler.inverse_transform(Xt)         # cast Xt to a pandas DataFrame         Xt = pd.DataFrame(data=Xt, columns=X.columns, index=X.index)         # return Xt and y         return Xt, y  In\u00a0[10]: Copied! <pre>from sklearn.datasets import make_blobs\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n</pre> from sklearn.datasets import make_blobs import pandas as pd import seaborn as sns import matplotlib.pyplot as plt In\u00a0[11]: Copied! <pre># create a seed that will be used all along\nseed = 12345\n</pre> # create a seed that will be used all along seed = 12345 In\u00a0[12]: Copied! <pre># let's make some fake data\n\nX, y = make_blobs(centers=4, random_state=seed, cluster_std=0.5)\n\n# cast to pandas DataFrame (just for convenience)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y, name='labels')\n</pre> # let's make some fake data  X, y = make_blobs(centers=4, random_state=seed, cluster_std=0.5)  # cast to pandas DataFrame (just for convenience) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y, name='labels') In\u00a0[13]: Copied! <pre># plot the data\nfig, ax = plt.subplots(figsize=(8,6))\nsns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=ax)\n</pre> # plot the data fig, ax = plt.subplots(figsize=(8,6)) sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=ax) Out[13]: <pre>&lt;Axes: xlabel='dimension_0', ylabel='dimension_1'&gt;</pre> In\u00a0[14]: Copied! <pre># setting the random generator with our previous seed\nrandom_generator = default_rng(seed=seed)\ngenerator = MyGenerator(random_generator=random_generator)\n</pre> # setting the random generator with our previous seed random_generator = default_rng(seed=seed) generator = MyGenerator(random_generator=random_generator) In\u00a0[15]: Copied! <pre># we create a copy of X and y because our generator acutally changes X and (potentially) y\nXt, yt = generator.generate(X=X.copy(), y=y.copy())\n</pre> # we create a copy of X and y because our generator acutally changes X and (potentially) y Xt, yt = generator.generate(X=X.copy(), y=y.copy()) In\u00a0[16]: Copied! <pre># Some sanity checks:\n\n# y and yt should contain the same values since we haven't touch anything in y\nassert all(y==yt)\n\n# Xt should be a pandas DataFrame\nassert type(Xt) is pd.DataFrame\n\n# X and Xt should have the same shape\nassert X.shape == Xt.shape\n\n# X and Xt should also have the same columns\nassert all(X.columns == Xt.columns)\n</pre> # Some sanity checks:  # y and yt should contain the same values since we haven't touch anything in y assert all(y==yt)  # Xt should be a pandas DataFrame assert type(Xt) is pd.DataFrame  # X and Xt should have the same shape assert X.shape == Xt.shape  # X and Xt should also have the same columns assert all(X.columns == Xt.columns) In\u00a0[17]: Copied! <pre># plot the data\nfig, axes = plt.subplots(1, 2, figsize=(8,4), sharex=True, sharey=True)\nsns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=axes[0])\nsns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette('tab10')[:4], ax=axes[1])\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\nplt.tight_layout()\n</pre> # plot the data fig, axes = plt.subplots(1, 2, figsize=(8,4), sharex=True, sharey=True) sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=axes[0]) sns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette('tab10')[:4], ax=axes[1]) axes[0].set_title('Original') axes[1].set_title('Transformed') plt.tight_layout() In\u00a0[18]: Copied! <pre>from typing import Tuple\n\nclass MyGenerator(GeneratorMixin):\n    \"\"\"\n    A generator that multiplies our values with some noise that follows a Poisson distribution (we could name it PoissonMultiplicativeNoiseGenerator)\n    \"\"\"\n\n    def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @preprocess_inputs\n    def generate(self, X: pd.DataFrame, y:pd.Series, lam:float=1.) -&gt; Tuple[pd.DataFrame,pd.Series]:\n        \"\"\"\n        It first standardizes the X values, applies the multiplicative Poisson noise, then \"de\"-standardizes the values\n        :param X: our input values (pd.DataFrame)\n        :param y: not used (just there for API convention) could be classes labels, target values or - as in our cases - None\n        :param lam: the am parameter from `numpy.random.Generator.poisson` see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.poisson.html\n        : return Xt, yt the transformed X and y\n        \"\"\"\n        # instanciating a StandardScaler object to standardize X and \"de\"-standardize X\n        scaler = StandardScaler()\n        Xt = scaler.fit_transform(X)\n        # Generate some noise from the Poisson distribution\n        noise = self.random_generator.poisson(size=X.shape, lam=lam)\n        # multiply Xt with noise\n        Xt *= noise\n        # inverse the standardization transformation\n        Xt = scaler.inverse_transform(Xt)\n        # cast Xt to a pandas DataFrame\n        Xt = pd.DataFrame(data=Xt, columns=X.columns, index=X.index)\n        # return Xt and y\n        return Xt, y\n</pre> from typing import Tuple  class MyGenerator(GeneratorMixin):     \"\"\"     A generator that multiplies our values with some noise that follows a Poisson distribution (we could name it PoissonMultiplicativeNoiseGenerator)     \"\"\"      def __init__(self, random_generator:np.random.Generator=default_rng(seed=0)):         \"\"\"         :param random_generator: A random generator         \"\"\"         self.random_generator = random_generator      @preprocess_inputs     def generate(self, X: pd.DataFrame, y:pd.Series, lam:float=1.) -&gt; Tuple[pd.DataFrame,pd.Series]:         \"\"\"         It first standardizes the X values, applies the multiplicative Poisson noise, then \"de\"-standardizes the values         :param X: our input values (pd.DataFrame)         :param y: not used (just there for API convention) could be classes labels, target values or - as in our cases - None         :param lam: the am parameter from `numpy.random.Generator.poisson` see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.poisson.html         : return Xt, yt the transformed X and y         \"\"\"         # instanciating a StandardScaler object to standardize X and \"de\"-standardize X         scaler = StandardScaler()         Xt = scaler.fit_transform(X)         # Generate some noise from the Poisson distribution         noise = self.random_generator.poisson(size=X.shape, lam=lam)         # multiply Xt with noise         Xt *= noise         # inverse the standardization transformation         Xt = scaler.inverse_transform(Xt)         # cast Xt to a pandas DataFrame         Xt = pd.DataFrame(data=Xt, columns=X.columns, index=X.index)         # return Xt and y         return Xt, y  In\u00a0[19]: Copied! <pre>generator = MyGenerator()\n</pre> generator = MyGenerator() In\u00a0[20]: Copied! <pre>Xt_lam1, yt_lam1 = generator.generate(X=X.copy(), y=y.copy(), lam=1.)\nXt_lam2, yt_lam2 = generator.generate(X=X.copy(), y=y.copy(), lam=2.)\nXt_lam5, yt_lam5 = generator.generate(X=X.copy(), y=y.copy(), lam=5.)\n</pre> Xt_lam1, yt_lam1 = generator.generate(X=X.copy(), y=y.copy(), lam=1.) Xt_lam2, yt_lam2 = generator.generate(X=X.copy(), y=y.copy(), lam=2.) Xt_lam5, yt_lam5 = generator.generate(X=X.copy(), y=y.copy(), lam=5.) In\u00a0[21]: Copied! <pre># plot the data\nfig, axes = plt.subplots(2, 2, figsize=(8,8), sharex=True, sharey=True)\nsns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=axes[0,0])\nsns.scatterplot(data=Xt_lam1, x='dimension_0', y='dimension_1', hue=yt_lam1, palette=sns.color_palette('tab10')[:4], ax=axes[0,1])\nsns.scatterplot(data=Xt_lam2, x='dimension_0', y='dimension_1', hue=yt_lam2, palette=sns.color_palette('tab10')[:4], ax=axes[1,0])\nsns.scatterplot(data=Xt_lam5, x='dimension_0', y='dimension_1', hue=yt_lam5, palette=sns.color_palette('tab10')[:4], ax=axes[1,1])\naxes[0,0].set_title('Original')\naxes[0,1].set_title('Transformed (lam=1)')\naxes[1,0].set_title('Transformed (lam=2)')\naxes[1,1].set_title('Transformed (lam=5)')\nplt.tight_layout()\n</pre> # plot the data fig, axes = plt.subplots(2, 2, figsize=(8,8), sharex=True, sharey=True) sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette('tab10')[:4], ax=axes[0,0]) sns.scatterplot(data=Xt_lam1, x='dimension_0', y='dimension_1', hue=yt_lam1, palette=sns.color_palette('tab10')[:4], ax=axes[0,1]) sns.scatterplot(data=Xt_lam2, x='dimension_0', y='dimension_1', hue=yt_lam2, palette=sns.color_palette('tab10')[:4], ax=axes[1,0]) sns.scatterplot(data=Xt_lam5, x='dimension_0', y='dimension_1', hue=yt_lam5, palette=sns.color_palette('tab10')[:4], ax=axes[1,1]) axes[0,0].set_title('Original') axes[0,1].set_title('Transformed (lam=1)') axes[1,0].set_title('Transformed (lam=2)') axes[1,1].set_title('Transformed (lam=5)') plt.tight_layout() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"dev/Create-New-Tabular-Generators/#creating-a-tabular_data-generator-scenario","title":"Creating a (tabular_data) generator: Scenario\u00b6","text":"<p>Imagine we want to create an generator that multiplies values in a dataframe with some Poisson noise (don't ask me why).</p> <p>That is we have some data X and we want to generate X * noise where noise comes from a Poisson distribution. Just to add some spices, we first want to standardize X, then apply the noise, and finally we want to come back to the initial scales (i.e., we inverse the standardization).</p> <p>We will leave y alone for this example.</p>"},{"location":"dev/Create-New-Tabular-Generators/#create-the-generator-class","title":"Create the generator class\u00b6","text":"<p>First each generator inherits form the GeneratorMixin (so we need to import it first)</p> <p>This enforces the generator to implement a <code>generate(X, y, **params)</code> function</p>"},{"location":"dev/Create-New-Tabular-Generators/#add-a-random-generator","title":"Add a random generator\u00b6","text":"<p>That is just best practice so that we can seed the random number generator and reproduce the generation</p> <p>We add it to the constructor code, give it a type hint (it should be a numpy.random.Generator object) and the default value is the default_rng from numpy with seed = 0</p>"},{"location":"dev/Create-New-Tabular-Generators/#preprocess-the-inputs","title":"Preprocess the inputs\u00b6","text":"<p>As a convention for tabular data generators, X is expected to be a pandas DataFrame object.</p> <p>Note that badgers implements a utility to preprocess inputs such as lists, list of lists, numpy arrays and convert them to pandas DataFrame. So that a user can actually input other data types than just pandas DataFrame.</p> <p>This utility comes in the form of a decorator and is called <code>preprocess_inputs</code>.</p> <p>It can be imported from <code>badgers.core.decorators.tabular_data</code>.</p> <p>Let's add it to the <code>generate(X, y, **params)</code> function.</p> <p>This will make sure that X is always a pandas DataFrame (and y is a pandas Series, but for now it does not play a role, since we are not transforming y)</p>"},{"location":"dev/Create-New-Tabular-Generators/#add-the-code-to-transformgenerate-the-data","title":"Add the code to transform/generate the data.\u00b6","text":"<p>The generation algorithm goes like this:</p> <ul> <li>first standardize X (mean = 0, standard deviation = 1).</li> <li>apply the noise (in our case we multiply X with noise, where noise ~ Poisson distriution).</li> <li>finally de-standardise to go back to the initial scales of X</li> </ul> <p>We are going to use the StandardScaler from scikit-learn to standardize and \"de\"-standardize our data.</p> <p>We are going to use numpy for the Poisson distribution (for that we use the <code>random_generator</code> object).</p>"},{"location":"dev/Create-New-Tabular-Generators/#lets-try-it","title":"Let's try it\u00b6","text":"<p>First, we generate some data using sklearn make_blob utility.</p> <p>Second, we instantiate our generator and apply the generate function on our data.</p> <p>Finally, we plot the data using seaborn (or matplotlib or plotly, or bokeh...)</p>"},{"location":"dev/Create-New-Tabular-Generators/#create-some-fake-data-and-plot-it","title":"Create some fake data and plot it\u00b6","text":""},{"location":"dev/Create-New-Tabular-Generators/#instantiate-our-generator","title":"Instantiate our generator\u00b6","text":""},{"location":"dev/Create-New-Tabular-Generators/#transforming-the-data","title":"Transforming the data\u00b6","text":""},{"location":"dev/Create-New-Tabular-Generators/#plot-the-initial-and-the-transformed-data","title":"Plot the initial and the transformed data\u00b6","text":""},{"location":"dev/Create-New-Tabular-Generators/#lets-add-some-parameters","title":"Let's add some parameters\u00b6","text":"<p>The poisson function from numpy has a parameter <code>lam</code> we can include it in our generate function.</p>"},{"location":"dev/Create-New-Tabular-Generators/#instantiate-the-generator-generate-data-with-different-lam-values-and-plot-the-results","title":"Instantiate the generator, generate data with different <code>lam</code> values and plot the results\u00b6","text":""},{"location":"dev/Create-New-Tabular-Generators/#final-notes","title":"Final notes:\u00b6","text":"<p>In badgers all generators are organized first by type of modality (tabular_data, time_series, text, etc.) and by type of data quality problem (noise, outliers, drift, etc.): for instance <code>badgers.generators.tabular_data.noise</code>, <code>badgers.generators.time_series.noise</code>, etc.</p> <p>By convention I created a parent class for all generators that \"belong together\".</p> <p>For instance in <code>badgers.generators.tabular_data.noise</code> there is a <code>NoiseGenerator</code>class that serves as parent for the other generators for instance <code>GaussianNoiseClassesGenerator</code> and <code>GaussianNoiseClassesGenerator</code>.</p> <p>This is sometimes useful to do so. For example for storing intern attributes that all generators of this family will need (that is te case in missing values, or in patterns generation).</p> <p>Some parameters (like <code>lam</code> in our example) will be more specific and might be called at \"generation\" time (i.e., once we call <code>generate(X, y, **params)</code>). The advantage is that one creates only one object and can call the <code>generate</code> function with different parameters.</p> <p>Which parameters need to be give at construction time and at generation time depends on the use case (so far, as of version 0.0.6, I tried to keep the minimum in the constructor and add the parameters in the <code>generate</code> function).</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>badgers<ul> <li>core<ul> <li>base</li> <li>decorators<ul> <li>tabular_data</li> <li>time_series</li> </ul> </li> <li>pipeline</li> <li>utils</li> </ul> </li> <li>generators<ul> <li>geolocated_data</li> <li>graph<ul> <li>missingness</li> </ul> </li> <li>image</li> <li>tabular_data<ul> <li>drift</li> <li>imbalance</li> <li>missingness</li> <li>noise</li> <li>outliers<ul> <li>distribution_sampling</li> <li>instance_sampling</li> <li>low_density_sampling</li> </ul> </li> </ul> </li> <li>text<ul> <li>typos</li> </ul> </li> <li>time_series<ul> <li>changepoints</li> <li>missingness</li> <li>noise</li> <li>outliers</li> <li>patterns</li> <li>seasons</li> <li>transmission_errors</li> <li>trends</li> <li>utils</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/badgers/","title":"Index","text":"<p>Top-level package for Badgers.</p>"},{"location":"reference/badgers/core/","title":"Index","text":"<p>Module containing all core things (utilities, base classes, decorators, etc.) used by the transformers</p>"},{"location":"reference/badgers/core/base/","title":"base","text":""},{"location":"reference/badgers/core/base/#badgers.core.base.GeneratorMixin","title":"<code>GeneratorMixin</code>","text":"Source code in <code>badgers/core/base.py</code> <pre><code>class GeneratorMixin:\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n\n        :param X: the input\n        :param y: the target\n        :param params: optional parameters\n        :return: Xt, yt\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/core/base/#badgers.core.base.GeneratorMixin.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input</p> required <code>y</code> <p>the target</p> required <code>params</code> <p>optional parameters</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>Xt, yt</p> Source code in <code>badgers/core/base.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n\n    :param X: the input\n    :param y: the target\n    :param params: optional parameters\n    :return: Xt, yt\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/core/pipeline/","title":"pipeline","text":""},{"location":"reference/badgers/core/pipeline/#badgers.core.pipeline.Pipeline","title":"<code>Pipeline</code>","text":"<p>Class for chaining different generators together.</p> <p>Not compatible with scikit-learn Pipelines Only words for python 3.7 as it relies upon dictionaries, and they need to be ordered</p> Source code in <code>badgers/core/pipeline.py</code> <pre><code>class Pipeline:\n    \"\"\"\n    Class for chaining different generators together.\n\n    Not compatible with scikit-learn Pipelines\n    Only words for python 3.7 as it relies upon dictionaries, and they need to be ordered\n    \"\"\"\n\n    def __init__(self, generators: Dict):\n        \"\"\"\n        Creates a Pipeline consisting of different generators\n        :param generators: a dictionary containing as keys the generator names and as values the generators instances\n        \"\"\"\n        self.generators = generators\n\n    def generate(self, X, y, params: Dict = None):\n        \"\"\"\n        Calls all generators generate function in the order\n\n        :param X: the input features\n        :param y: the class labels, regression targets, or None\n        :param params: a dictionary containing as key: the generator names and\n        as values: the parameters for each corresponding generate function\n        :return: Xt, yt\n        \"\"\"\n        if params is None:\n            params = dict()\n        for name, generator in self.generators.items():\n            X, y = generator.generate(X, y, **params.get(name, dict()))\n        return X, y\n</code></pre>"},{"location":"reference/badgers/core/pipeline/#badgers.core.pipeline.Pipeline.__init__","title":"<code>__init__(generators)</code>","text":"<p>Creates a Pipeline consisting of different generators</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Dict</code> <p>a dictionary containing as keys the generator names and as values the generators instances</p> required Source code in <code>badgers/core/pipeline.py</code> <pre><code>def __init__(self, generators: Dict):\n    \"\"\"\n    Creates a Pipeline consisting of different generators\n    :param generators: a dictionary containing as keys the generator names and as values the generators instances\n    \"\"\"\n    self.generators = generators\n</code></pre>"},{"location":"reference/badgers/core/pipeline/#badgers.core.pipeline.Pipeline.generate","title":"<code>generate(X, y, params=None)</code>","text":"<p>Calls all generators generate function in the order</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features</p> required <code>y</code> <p>the class labels, regression targets, or None</p> required <code>params</code> <code>Dict</code> <p>a dictionary containing as key: the generator names and as values: the parameters for each corresponding generate function</p> <code>None</code> <p>Returns:</p> Type Description <p>Xt, yt</p> Source code in <code>badgers/core/pipeline.py</code> <pre><code>def generate(self, X, y, params: Dict = None):\n    \"\"\"\n    Calls all generators generate function in the order\n\n    :param X: the input features\n    :param y: the class labels, regression targets, or None\n    :param params: a dictionary containing as key: the generator names and\n    as values: the parameters for each corresponding generate function\n    :return: Xt, yt\n    \"\"\"\n    if params is None:\n        params = dict()\n    for name, generator in self.generators.items():\n        X, y = generator.generate(X, y, **params.get(name, dict()))\n    return X, y\n</code></pre>"},{"location":"reference/badgers/core/utils/","title":"utils","text":""},{"location":"reference/badgers/core/utils/#badgers.core.utils.normalize_proba","title":"<code>normalize_proba(p)</code>","text":"<p>Make sure the probability array respects the following constraints:  - the sum of each column must be equal to 1 (or very close to 1)</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>array</code> <p>The probability array to normalize</p> required <p>Returns:</p> Type Description <code>array</code> <p>The normalized array</p> Source code in <code>badgers/core/utils.py</code> <pre><code>def normalize_proba(p: np.array) -&gt; np.array:\n    \"\"\"\n    Make sure the probability array respects the following constraints:\n     - the sum of each column must be equal to 1 (or very close to 1)\n\n    :param p: The probability array to normalize\n    :return: The normalized array\n    \"\"\"\n    # make the sum of each column = 1\n    sum = p.sum(axis=0)\n    # assure that no division by 0\n    if isinstance(sum, np.ndarray) and sum.ndim &gt; 1:\n        sum[sum == 0] = 1\n    # normalize\n    p = p / sum\n    return p\n</code></pre>"},{"location":"reference/badgers/core/utils/#badgers.core.utils.random_sign","title":"<code>random_sign(random_generator=default_rng(0), size=(1,))</code>","text":"<p>Generates an array full of ones, with randomly assigned signs.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>a random number generator</p> <code>default_rng(0)</code> <code>size</code> <code>Tuple[int]</code> <p>the shape of the array to generate</p> <code>(1,)</code> <p>Returns:</p> Type Description <code>array</code> <p>an array full of ones, with randomly assigned signs</p> Source code in <code>badgers/core/utils.py</code> <pre><code>def random_sign(random_generator: numpy.random.Generator = default_rng(0), size: Tuple[int] = (1,)) -&gt; np.array:\n    \"\"\"\n    Generates an array full of ones, with randomly assigned signs.\n\n    :param random_generator: a random number generator\n    :param size: the shape of the array to generate\n    :return: an array full of ones, with randomly assigned signs\n    \"\"\"\n    signs = np.ones(shape=size)\n    mask = random_generator.random(size=size) &lt; 0.5\n    signs[mask] *= -1\n    return signs\n</code></pre>"},{"location":"reference/badgers/core/utils/#badgers.core.utils.random_spherical_coordinate","title":"<code>random_spherical_coordinate(random_generator=default_rng(0), size=None, radius=None)</code>","text":"<p>Randomly generates points on a hypersphere of dimension <code>size</code></p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>a random number generator</p> <code>default_rng(0)</code> <code>size</code> <code>int</code> <p>the dimension of the hypersphere</p> <code>None</code> <code>radius</code> <code>float</code> <p>the radius of the hypersphere</p> <code>None</code> <p>Returns:</p> Type Description <code>array</code> <p>an array of shape (<code>size</code>,) containing the values of the point generated</p> Source code in <code>badgers/core/utils.py</code> <pre><code>def random_spherical_coordinate(random_generator: numpy.random.Generator = default_rng(0),\n                                size: int = None,\n                                radius: float = None) -&gt; np.array:\n    \"\"\"\n    Randomly generates points on a hypersphere of dimension `size`\n    :param random_generator: a random number generator\n    :param size: the dimension of the hypersphere\n    :param radius: the radius of the hypersphere\n    :return: an array of shape (`size`,) containing the values of the point generated\n    \"\"\"\n    assert size &gt; 0\n    if size == 1:\n        x = random_sign(random_generator, size=(1,)) * radius\n    elif size == 2:\n        phi = random_generator.uniform(0, 2. * np.pi)\n        x = np.array([radius * np.cos(phi), radius * np.sin(phi)])\n    else:\n        phis = np.concatenate([\n            random_generator.uniform(0, np.pi, size=size - 2),\n            [random_generator.uniform(0, 2. * np.pi)]\n        ])\n\n        cos_phis = np.cos(phis)\n        sin_phis = np.sin(phis)\n\n        x = np.array(\n            [radius * cos_phis[i] * np.prod(sin_phis[:i]) for i in range(size - 1)] + [radius * np.prod(sin_phis)]\n        )\n    return x\n</code></pre>"},{"location":"reference/badgers/core/decorators/","title":"Index","text":""},{"location":"reference/badgers/core/decorators/tabular_data/","title":"tabular_data","text":""},{"location":"reference/badgers/core/decorators/tabular_data/#badgers.core.decorators.tabular_data.preprocess_inputs","title":"<code>preprocess_inputs(generate_func)</code>","text":"<p>Validates and convert X and y for tabular data generators</p> <p>Preprocessing: X is converted to a pandas DataFrame y is converted to a pandas Series</p> Source code in <code>badgers/core/decorators/tabular_data.py</code> <pre><code>def preprocess_inputs(generate_func):\n    \"\"\"\n    Validates and convert X and y for tabular data generators\n\n    Preprocessing:\n    X is converted to a pandas DataFrame\n    y is converted to a pandas Series\n    \"\"\"\n\n    @functools.wraps(generate_func)\n    def wrapper(self, X, y, **kwargs):\n        # Validate and preprocess X\n        if isinstance(X, list):\n            X = pd.DataFrame(X)\n        elif isinstance(X, np.ndarray):\n            # if it is a numpy array first check the dimensionality, if dimension is 1 then reshape, if the dimension &gt; 2 then raise error\n            if X.ndim == 1:\n                X = X.reshape(-1, 1)\n            if X.ndim &gt; 2:\n                raise ValueError(\n                    \"X has more than 2 dimensions where it is expected to have either 1 or 2!\"\n                )\n            X = pd.DataFrame(data=X)\n        elif isinstance(X, pd.Series):\n            X = X.to_frame()\n        elif isinstance(X, pd.DataFrame):\n            # do nothing here\n            pass\n        else:\n            raise ValueError(f\"X must be a list, numpy array, pandas Series, or pandas DataFrame\\nX is: {type(X)}\")\n\n        # Validate and preprocess y\n        if y is not None:\n            if isinstance(y, list):\n                y = pd.Series(y)\n            elif isinstance(y, np.ndarray):\n                y = pd.Series(y)\n            elif isinstance(y, pd.Series):\n                pass\n            else:\n                raise ValueError(\"y must be a list, numpy array, or pandas Series\")\n\n        # Call the original function with the preprocessed inputs\n        return generate_func(self, X, y, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"reference/badgers/core/decorators/time_series/","title":"time_series","text":""},{"location":"reference/badgers/core/decorators/time_series/#badgers.core.decorators.time_series.preprocess_inputs","title":"<code>preprocess_inputs(generate_func)</code>","text":"<p>Validates and convert X and y for time series data generators</p> <p>Preprocessing: X is converted to a pandas DataFrame y is converted to a pandas Series</p> Source code in <code>badgers/core/decorators/time_series.py</code> <pre><code>def preprocess_inputs(generate_func):\n    \"\"\"\n    Validates and convert X and y for time series data generators\n\n    Preprocessing:\n    X is converted to a pandas DataFrame\n    y is converted to a pandas Series\n    \"\"\"\n\n    @functools.wraps(generate_func)\n    def wrapper(self, X, y, **kwargs):\n        # Validate and preprocess X\n        if isinstance(X, list):\n            X = pd.DataFrame(X)\n        elif isinstance(X, np.ndarray):\n            # if it is a numpy array first check the dimensionality,\n            # if dimension is 1 then reshape, if the dimension &gt; 2 then raise error\n            if X.ndim == 1:\n                X = X.reshape(-1, 1)\n            if X.ndim &gt; 2:\n                raise ValueError(\n                    \"X has more than 2 dimensions where it is expected to have either 1 or 2!\"\n                )\n            X = pd.DataFrame(data=X)\n        elif isinstance(X, pd.Series):\n            X = X.to_frame()\n        elif isinstance(X, pd.DataFrame):\n            # do nothing here\n            pass\n        else:\n            raise ValueError(f\"X must be a list, numpy array, pandas Series, or pandas DataFrame\\nX is: {type(X)}\")\n\n        # Validate and preprocess y\n        if y is not None:\n            if isinstance(y, list):\n                y = pd.Series(y)\n            elif isinstance(y, np.ndarray):\n                y = pd.Series(y)\n            elif isinstance(y, pd.Series):\n                pass\n            else:\n                raise ValueError(\"y must be a list, numpy array, or pandas Series\")\n\n        # Call the original function with the preprocessed inputs\n        return generate_func(self, X, y, **kwargs)\n\n    return wrapper\n</code></pre>"},{"location":"reference/badgers/generators/","title":"Index","text":"<p>Module containing all generators</p>"},{"location":"reference/badgers/generators/geolocated_data/","title":"geolocated_data","text":"<p>Module containing all the transformers that accept geolocated data as input</p>"},{"location":"reference/badgers/generators/graph/","title":"Index","text":"<p>This module contains all the generator functions designed to process and yield data from graph inputs.</p>"},{"location":"reference/badgers/generators/graph/missingness/","title":"missingness","text":""},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.EdgesMissingCompletelyAtRandom","title":"<code>EdgesMissingCompletelyAtRandom</code>","text":"<p>               Bases: <code>MissingGenerator</code></p> <p>Removes edges from the graph uniformly at random.</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>class EdgesMissingCompletelyAtRandom(MissingGenerator):\n    \"\"\"\n    Removes edges from the graph uniformly at random.\n    \"\"\"\n\n    def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n        \"\"\"\n        Initialize the missingness generator.\n\n        :param random_generator: A NumPy random number generator.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    def generate(self, X, y=None, percentage_missing: float = 0.1) -&gt; Tuple:\n        \"\"\"\n        Generate a graph with a specified percentage of missing edges.\n\n        :param X: The input graph from which edges will be removed.\n        :type X: nx.Graph\n        :param y: Optional target data associated with the edges in the graph.\n                  If provided, the corresponding elements will also be removed.\n                  Can be a dictionary where keys are edge tuples and values are target values.\n        :type y: dict, optional\n        :param percentage_missing: The percentage of edges to be removed (float value between 0 and 1).\n        :type percentage_missing: float\n        :return: A tuple containing the modified graph with missing edges and the modified target data (if provided).\n        :rtype: Tuple[nx.Graph, Optional[dict]]\n        \"\"\"\n        assert 0 &lt; percentage_missing &lt; 1\n        if not isinstance(X, nx.Graph):\n            raise NotImplementedError('badgers does only support networkx.Graph objects for graphs')\n\n        edges_to_be_removed = self.random_generator.choice(\n            X.edges(),\n            int(X.number_of_edges() * percentage_missing),\n            replace=False\n        )\n\n        Xt = X.copy()\n        Xt.remove_edges_from(edges_to_be_removed)\n\n        if y is None:\n            yt = None\n        elif isinstance(y, dict):\n            yt = copy(y)\n            for e in edges_to_be_removed:\n                del yt[e]\n        else:\n            raise ValueError(f'This type of y is not supported {type(y)}, {y}')\n\n        return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.EdgesMissingCompletelyAtRandom.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the missingness generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n    \"\"\"\n    Initialize the missingness generator.\n\n    :param random_generator: A NumPy random number generator.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.EdgesMissingCompletelyAtRandom.generate","title":"<code>generate(X, y=None, percentage_missing=0.1)</code>","text":"<p>Generate a graph with a specified percentage of missing edges.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Graph</code> <p>The input graph from which edges will be removed.</p> required <code>y</code> <code>(dict, optional)</code> <p>Optional target data associated with the edges in the graph. If provided, the corresponding elements will also be removed. Can be a dictionary where keys are edge tuples and values are target values.</p> <code>None</code> <code>percentage_missing</code> <code>float</code> <p>The percentage of edges to be removed (float value between 0 and 1).</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple[nx.Graph, Optional[dict]]</code> <p>A tuple containing the modified graph with missing edges and the modified target data (if provided).</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>def generate(self, X, y=None, percentage_missing: float = 0.1) -&gt; Tuple:\n    \"\"\"\n    Generate a graph with a specified percentage of missing edges.\n\n    :param X: The input graph from which edges will be removed.\n    :type X: nx.Graph\n    :param y: Optional target data associated with the edges in the graph.\n              If provided, the corresponding elements will also be removed.\n              Can be a dictionary where keys are edge tuples and values are target values.\n    :type y: dict, optional\n    :param percentage_missing: The percentage of edges to be removed (float value between 0 and 1).\n    :type percentage_missing: float\n    :return: A tuple containing the modified graph with missing edges and the modified target data (if provided).\n    :rtype: Tuple[nx.Graph, Optional[dict]]\n    \"\"\"\n    assert 0 &lt; percentage_missing &lt; 1\n    if not isinstance(X, nx.Graph):\n        raise NotImplementedError('badgers does only support networkx.Graph objects for graphs')\n\n    edges_to_be_removed = self.random_generator.choice(\n        X.edges(),\n        int(X.number_of_edges() * percentage_missing),\n        replace=False\n    )\n\n    Xt = X.copy()\n    Xt.remove_edges_from(edges_to_be_removed)\n\n    if y is None:\n        yt = None\n    elif isinstance(y, dict):\n        yt = copy(y)\n        for e in edges_to_be_removed:\n            del yt[e]\n    else:\n        raise ValueError(f'This type of y is not supported {type(y)}, {y}')\n\n    return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.MissingGenerator","title":"<code>MissingGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for missing nodes transformer</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>class MissingGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for missing nodes transformer\n    \"\"\"\n\n    def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n        \"\"\"\n\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y=None, **params) -&gt; Tuple:\n        \"\"\"\n        This method should be overridden by subclasses.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.MissingGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A random generator</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n    \"\"\"\n\n    :param random_generator: A random generator\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.MissingGenerator.generate","title":"<code>generate(X, y=None, **params)</code>  <code>abstractmethod</code>","text":"<p>This method should be overridden by subclasses.</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y=None, **params) -&gt; Tuple:\n    \"\"\"\n    This method should be overridden by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.NodesMissingCompletelyAtRandom","title":"<code>NodesMissingCompletelyAtRandom</code>","text":"<p>               Bases: <code>MissingGenerator</code></p> <p>Removes nodes from the graph uniformly at random.</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>class NodesMissingCompletelyAtRandom(MissingGenerator):\n    \"\"\"\n    Removes nodes from the graph uniformly at random.\n    \"\"\"\n\n    def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n        \"\"\"\n        Initialize the missingness generator.\n\n        :param random_generator: A NumPy random number generator.\n                               Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    def generate(self, X, y=None, percentage_missing: float = 0.1) -&gt; Tuple:\n        \"\"\"\n        Generate a graph with a specified percentage of missing nodes.\n\n        :param X: The input graph from which nodes will be removed.\n        :type X: nx.Graph\n        :param y: Optional target array associated with the nodes in the graph.\n                  If provided, the corresponding elements will also be removed.\n        :type y: np.ndarray, optional\n        :param percentage_missing: The percentage of nodes to be removed (float value between 0 and 1).\n        :type percentage_missing: float\n        :return: A tuple containing the modified graph with missing nodes and the modified target array (if provided).\n        :rtype: Tuple[nx.Graph, Optional[np.ndarray]]\n        \"\"\"\n        assert 0 &lt; percentage_missing &lt; 1\n        if not isinstance(X, nx.Graph):\n            raise NotImplementedError('badgers does only support networkx.Graph objects for graphs')\n\n        nodes_to_be_removed = self.random_generator.choice(\n            X.nodes(),\n            int(X.number_of_nodes() * percentage_missing),\n            replace=False\n        )\n\n        Xt = X.copy()\n        Xt.remove_nodes_from(nodes_to_be_removed)\n\n        if y is not None:\n            yt = np.delete(y, nodes_to_be_removed)\n        else:\n            yt = None\n\n        return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.NodesMissingCompletelyAtRandom.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the missingness generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n    \"\"\"\n    Initialize the missingness generator.\n\n    :param random_generator: A NumPy random number generator.\n                           Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/graph/missingness/#badgers.generators.graph.missingness.NodesMissingCompletelyAtRandom.generate","title":"<code>generate(X, y=None, percentage_missing=0.1)</code>","text":"<p>Generate a graph with a specified percentage of missing nodes.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Graph</code> <p>The input graph from which nodes will be removed.</p> required <code>y</code> <code>(ndarray, optional)</code> <p>Optional target array associated with the nodes in the graph. If provided, the corresponding elements will also be removed.</p> <code>None</code> <code>percentage_missing</code> <code>float</code> <p>The percentage of nodes to be removed (float value between 0 and 1).</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple[nx.Graph, Optional[np.ndarray]]</code> <p>A tuple containing the modified graph with missing nodes and the modified target array (if provided).</p> Source code in <code>badgers/generators/graph/missingness.py</code> <pre><code>def generate(self, X, y=None, percentage_missing: float = 0.1) -&gt; Tuple:\n    \"\"\"\n    Generate a graph with a specified percentage of missing nodes.\n\n    :param X: The input graph from which nodes will be removed.\n    :type X: nx.Graph\n    :param y: Optional target array associated with the nodes in the graph.\n              If provided, the corresponding elements will also be removed.\n    :type y: np.ndarray, optional\n    :param percentage_missing: The percentage of nodes to be removed (float value between 0 and 1).\n    :type percentage_missing: float\n    :return: A tuple containing the modified graph with missing nodes and the modified target array (if provided).\n    :rtype: Tuple[nx.Graph, Optional[np.ndarray]]\n    \"\"\"\n    assert 0 &lt; percentage_missing &lt; 1\n    if not isinstance(X, nx.Graph):\n        raise NotImplementedError('badgers does only support networkx.Graph objects for graphs')\n\n    nodes_to_be_removed = self.random_generator.choice(\n        X.nodes(),\n        int(X.number_of_nodes() * percentage_missing),\n        replace=False\n    )\n\n    Xt = X.copy()\n    Xt.remove_nodes_from(nodes_to_be_removed)\n\n    if y is not None:\n        yt = np.delete(y, nodes_to_be_removed)\n    else:\n        yt = None\n\n    return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/image/","title":"image","text":"<p>Module containing all the transformers that accept image data as input</p>"},{"location":"reference/badgers/generators/tabular_data/","title":"Index","text":"<p>This module contains all the generator functions designed to process and yield data from tabular inputs.</p>"},{"location":"reference/badgers/generators/tabular_data/drift/","title":"drift","text":""},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.DriftGenerator","title":"<code>DriftGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that add noise to tabular data</p> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>class DriftGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that add noise to tabular data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the drift generator.\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params):\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.DriftGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the drift generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the drift generator.\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftClassesGenerator","title":"<code>RandomShiftClassesGenerator</code>","text":"<p>               Bases: <code>DriftGenerator</code></p> <p>Randomly shift (geometrical translation) values of each class independently of one another. Data are first standardized (mean = 0, var = 1) and for each class a random number is added to all instances.</p> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>class RandomShiftClassesGenerator(DriftGenerator):\n    \"\"\"\n    Randomly shift (geometrical translation) values of each class independently of one another.\n    Data are first standardized (mean = 0, var = 1) and\n    for each class a random number is added to all instances.\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomShiftClassesGenerator.\n\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, shift_std: Union[float, np.array] = 0.1):\n        \"\"\"\n        Randomly shift (geometrical translation) values of each class independently of one another.\n        Data are first standardized (mean = 0, var = 1) and for each class a random number is added to all instances.\n\n        :param X: Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).\n        :param y: Target variable, a 1D array-like object representing the class labels.\n        :param shift_std: Standard deviation of the normal distribution from which the random shifts are drawn.\n                          Can be a single float (applied to all classes) or an array of floats (one per class).\n        :return: A tuple containing the modified feature matrix `X'` and the original target `y`.\n        \"\"\"\n        # extract unique labels\n        classes = np.unique(y)\n        # normalize X\n        scaler = StandardScaler()\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n        # generate random values for the shift\n        shifts = self.random_generator.normal(loc=0, scale=shift_std, size=len(classes))\n        # add shift\n        for c, s in zip(classes, shifts):\n            Xt[y == c] += s\n        # inverse transform\n        return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftClassesGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomShiftClassesGenerator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomShiftClassesGenerator.\n\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftClassesGenerator.generate","title":"<code>generate(X, y, shift_std=0.1)</code>","text":"<p>Randomly shift (geometrical translation) values of each class independently of one another. Data are first standardized (mean = 0, var = 1) and for each class a random number is added to all instances.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).</p> required <code>y</code> <p>Target variable, a 1D array-like object representing the class labels.</p> required <code>shift_std</code> <code>Union[float, array]</code> <p>Standard deviation of the normal distribution from which the random shifts are drawn. Can be a single float (applied to all classes) or an array of floats (one per class).</p> <code>0.1</code> <p>Returns:</p> Type Description <p>A tuple containing the modified feature matrix <code>X'</code> and the original target <code>y</code>.</p> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, shift_std: Union[float, np.array] = 0.1):\n    \"\"\"\n    Randomly shift (geometrical translation) values of each class independently of one another.\n    Data are first standardized (mean = 0, var = 1) and for each class a random number is added to all instances.\n\n    :param X: Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).\n    :param y: Target variable, a 1D array-like object representing the class labels.\n    :param shift_std: Standard deviation of the normal distribution from which the random shifts are drawn.\n                      Can be a single float (applied to all classes) or an array of floats (one per class).\n    :return: A tuple containing the modified feature matrix `X'` and the original target `y`.\n    \"\"\"\n    # extract unique labels\n    classes = np.unique(y)\n    # normalize X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n    # generate random values for the shift\n    shifts = self.random_generator.normal(loc=0, scale=shift_std, size=len(classes))\n    # add shift\n    for c, s in zip(classes, shifts):\n        Xt[y == c] += s\n    # inverse transform\n    return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftGenerator","title":"<code>RandomShiftGenerator</code>","text":"<p>               Bases: <code>DriftGenerator</code></p> <p>Randomly shift (geometrical translation) values of each column independently of one another. Data are first standardized (mean = 0, var = 1) and a random number is added to each column. The ith columns is simply translated: <code>$x_i \\left arrow x_i + \\epsilon_i$</code></p> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>class RandomShiftGenerator(DriftGenerator):\n    \"\"\"\n    Randomly shift (geometrical translation) values of each column independently of one another.\n    Data are first standardized (mean = 0, var = 1) and a random number is added to each column.\n    The ith columns is simply translated: `$x_i \\left arrow x_i + \\epsilon_i$`\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomShiftGenerator.\n\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y=None, shift_std: Union[float, np.array] = 0.1):\n        \"\"\"\n        Randomly shift (geometrical translation) values of each column independently of one another.\n        Data are first standardized (mean = 0, var = 1), and a random number drawn from a normal distribution\n        with mean 0 and standard deviation `shift_std` is added to each column.\n        The ith column is simply translated: `$x_i \\leftarrow x_i + \\epsilon_i$`, where $\\epsilon_i \\sim \\mathcal{N}(0, \\text{shift\\_std})$.\n\n        :param X: Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).\n        :param y: Target variable, a 1D array-like object (optional). Not used in this implementation.\n        :param shift_std: Standard deviation of the normal distribution from which the random shifts are drawn.\n                          Can be a single float (applied to all columns) or an array of floats (one per column).\n        :return: A tuple containing the modified feature matrix `X'` and the original target `y`.\n        \"\"\"\n        # normalize X\n        scaler = StandardScaler()\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n        # generate random values for the shift for each column\n        shift = self.random_generator.normal(loc=0, scale=shift_std, size=X.shape[1])\n        # add shift\n        Xt += shift\n        # inverse transform\n        return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomShiftGenerator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomShiftGenerator.\n\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/drift/#badgers.generators.tabular_data.drift.RandomShiftGenerator.generate","title":"<code>generate(X, y=None, shift_std=0.1)</code>","text":"<p>Randomly shift (geometrical translation) values of each column independently of one another. Data are first standardized (mean = 0, var = 1), and a random number drawn from a normal distribution with mean 0 and standard deviation <code>shift_std</code> is added to each column. The ith column is simply translated: <code>$x_i \\leftarrow x_i + \\epsilon_i$</code>, where $\\epsilon_i \\sim \\mathcal{N}(0,         ext{shift_std})$.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).</p> required <code>y</code> <p>Target variable, a 1D array-like object (optional). Not used in this implementation.</p> <code>None</code> <code>shift_std</code> <code>Union[float, array]</code> <p>Standard deviation of the normal distribution from which the random shifts are drawn. Can be a single float (applied to all columns) or an array of floats (one per column).</p> <code>0.1</code> <p>Returns:</p> Type Description <p>A tuple containing the modified feature matrix <code>X'</code> and the original target <code>y</code>.</p> Source code in <code>badgers/generators/tabular_data/drift.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, shift_std: Union[float, np.array] = 0.1):\n    \"\"\"\n    Randomly shift (geometrical translation) values of each column independently of one another.\n    Data are first standardized (mean = 0, var = 1), and a random number drawn from a normal distribution\n    with mean 0 and standard deviation `shift_std` is added to each column.\n    The ith column is simply translated: `$x_i \\leftarrow x_i + \\epsilon_i$`, where $\\epsilon_i \\sim \\mathcal{N}(0, \\text{shift\\_std})$.\n\n    :param X: Input features, a 2D array-like object (e.g., a Pandas DataFrame or a NumPy array).\n    :param y: Target variable, a 1D array-like object (optional). Not used in this implementation.\n    :param shift_std: Standard deviation of the normal distribution from which the random shifts are drawn.\n                      Can be a single float (applied to all columns) or an array of floats (one per column).\n    :return: A tuple containing the modified feature matrix `X'` and the original target `y`.\n    \"\"\"\n    # normalize X\n    scaler = StandardScaler()\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n    # generate random values for the shift for each column\n    shift = self.random_generator.normal(loc=0, scale=shift_std, size=X.shape[1])\n    # add shift\n    Xt += shift\n    # inverse transform\n    return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/","title":"imbalance","text":""},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.ImbalanceGenerator","title":"<code>ImbalanceGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that makes tabular data imbalanced</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>class ImbalanceGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that makes tabular data imbalanced\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the ImbalanceGenerator with a specified random number generator.\n\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y=None, **params):\n        \"\"\"\n        Abstract method to generate imbalanced data from the input data.\n        This should be overridden\n\n        :param X: Input features, can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: Target variable, can be a pandas Series or a numpy array.\n                  If None, it is assumed that the target is not provided.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param params: Additional keyword arguments that might be required for specific implementations.\n        :type params: dict\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.ImbalanceGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the ImbalanceGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the ImbalanceGenerator with a specified random number generator.\n\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.ImbalanceGenerator.generate","title":"<code>generate(X, y=None, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate imbalanced data from the input data. This should be overridden</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>Input features, can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>Target variable, can be a pandas Series or a numpy array. If None, it is assumed that the target is not provided.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Additional keyword arguments that might be required for specific implementations.</p> <code>{}</code> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y=None, **params):\n    \"\"\"\n    Abstract method to generate imbalanced data from the input data.\n    This should be overridden\n\n    :param X: Input features, can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: Target variable, can be a pandas Series or a numpy array.\n              If None, it is assumed that the target is not provided.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param params: Additional keyword arguments that might be required for specific implementations.\n    :type params: dict\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingClassesGenerator","title":"<code>RandomSamplingClassesGenerator</code>","text":"<p>               Bases: <code>ImbalanceGenerator</code></p> <p>Randomly samples data points within predefined classes</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>class RandomSamplingClassesGenerator(ImbalanceGenerator):\n    \"\"\"\n    Randomly samples data points within predefined classes\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0), ):\n        \"\"\"\n        Initialize the RandomSamplingClassesGenerator with a specified random number generator.\n\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.transformed_labels_ = None\n\n    @preprocess_inputs\n    def generate(self, X, y, proportion_classes: dict = None):\n        \"\"\"\n        Randomly samples instances for each class based on the specified proportions.\n\n        :param X: Input features, can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: Target variable, must be a pandas Series or a numpy array.\n        :type y: Union[pandas.Series, numpy.ndarray]\n        :param proportion_classes: A dictionary specifying the desired proportion of each class.\n                                   The keys are class labels and the values are the desired proportions.\n                                   For example, to have 50% of class 'A', 30% of class 'B', and 20% of class 'C',\n                                   use `proportion_classes={'A': 0.5, 'B': 0.3, 'C': 0.2}`.\n        :type proportion_classes: dict, optional\n        :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]\n        \"\"\"\n        # local variables\n        Xt = []\n        transformed_labels = []\n\n        for label, prop in proportion_classes.items():\n            size = int(prop * X.shape[0])\n            Xt.append(self.random_generator.choice(X[y == label], size=size, replace=True))\n            transformed_labels += [label] * size\n\n        Xt = pd.DataFrame(\n            data=np.vstack(Xt),\n            columns=X.columns\n        )\n\n        yt = pd.Series(data=transformed_labels)\n\n        return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingClassesGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomSamplingClassesGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0), ):\n    \"\"\"\n    Initialize the RandomSamplingClassesGenerator with a specified random number generator.\n\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.transformed_labels_ = None\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingClassesGenerator.generate","title":"<code>generate(X, y, proportion_classes=None)</code>","text":"<p>Randomly samples instances for each class based on the specified proportions.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>Input features, can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>Union[Series, ndarray]</code> <p>Target variable, must be a pandas Series or a numpy array.</p> required <code>proportion_classes</code> <code>dict</code> <p>A dictionary specifying the desired proportion of each class. The keys are class labels and the values are the desired proportions. For example, to have 50% of class 'A', 30% of class 'B', and 20% of class 'C', use <code>proportion_classes={'A': 0.5, 'B': 0.3, 'C': 0.2}</code>.</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]</code> <p>A tuple containing the sampled features (Xt) and the corresponding target values (yt).</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, proportion_classes: dict = None):\n    \"\"\"\n    Randomly samples instances for each class based on the specified proportions.\n\n    :param X: Input features, can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: Target variable, must be a pandas Series or a numpy array.\n    :type y: Union[pandas.Series, numpy.ndarray]\n    :param proportion_classes: A dictionary specifying the desired proportion of each class.\n                               The keys are class labels and the values are the desired proportions.\n                               For example, to have 50% of class 'A', 30% of class 'B', and 20% of class 'C',\n                               use `proportion_classes={'A': 0.5, 'B': 0.3, 'C': 0.2}`.\n    :type proportion_classes: dict, optional\n    :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]\n    \"\"\"\n    # local variables\n    Xt = []\n    transformed_labels = []\n\n    for label, prop in proportion_classes.items():\n        size = int(prop * X.shape[0])\n        Xt.append(self.random_generator.choice(X[y == label], size=size, replace=True))\n        transformed_labels += [label] * size\n\n    Xt = pd.DataFrame(\n        data=np.vstack(Xt),\n        columns=X.columns\n    )\n\n    yt = pd.Series(data=transformed_labels)\n\n    return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingFeaturesGenerator","title":"<code>RandomSamplingFeaturesGenerator</code>","text":"<p>               Bases: <code>ImbalanceGenerator</code></p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>class RandomSamplingFeaturesGenerator(ImbalanceGenerator):\n\n    def __init__(self, random_generator=default_rng(seed=0), ):\n        \"\"\"\n        Initialize the RandomSamplingFeaturesGenerator with a specified random number generator.\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y=None, sampling_proba_func=lambda X: normalize_proba(X.iloc[:, 0])):\n        \"\"\"\n        Randomly samples instances based on the feature values in X using a specified sampling probability function.\n\n        The sampling probability function is applied to the input features X to determine the probability of each instance being sampled.\n        By default, the first column of X is used to compute the normalized sampling probabilities.\n\n        :param X: Input features, can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: Target variable, can be a pandas Series or a numpy array.\n                  If None, it is assumed that the target is not provided.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param sampling_proba_func: A function that takes as input data (X) and returns a series of sampling probabilities.\n                                    The function should ensure that the probabilities are normalized.\n        :type sampling_proba_func: callable\n        :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n                 If y is None, only the sampled features (Xt) are returned.\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n        \"\"\"\n        # total number of instances that will be missing\n        # sampling\n        sampling_proba = sampling_proba_func(X)\n        sampling_mask = self.random_generator.choice(X.shape[0], p=sampling_proba, size=X.shape[0], replace=True)\n        Xt = X.iloc[sampling_mask,:]\n        yt = y[sampling_mask] if y is not None else y\n        return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingFeaturesGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomSamplingFeaturesGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0), ):\n    \"\"\"\n    Initialize the RandomSamplingFeaturesGenerator with a specified random number generator.\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingFeaturesGenerator.generate","title":"<code>generate(X, y=None, sampling_proba_func=lambda X: normalize_proba(X.iloc[:, 0]))</code>","text":"<p>Randomly samples instances based on the feature values in X using a specified sampling probability function.</p> <p>The sampling probability function is applied to the input features X to determine the probability of each instance being sampled. By default, the first column of X is used to compute the normalized sampling probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>Input features, can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>Target variable, can be a pandas Series or a numpy array. If None, it is assumed that the target is not provided.</p> <code>None</code> <code>sampling_proba_func</code> <code>callable</code> <p>A function that takes as input data (X) and returns a series of sampling probabilities. The function should ensure that the probabilities are normalized.</p> <code>lambda X: normalize_proba(iloc[:, 0])</code> <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]</code> <p>A tuple containing the sampled features (Xt) and the corresponding target values (yt). If y is None, only the sampled features (Xt) are returned.</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, sampling_proba_func=lambda X: normalize_proba(X.iloc[:, 0])):\n    \"\"\"\n    Randomly samples instances based on the feature values in X using a specified sampling probability function.\n\n    The sampling probability function is applied to the input features X to determine the probability of each instance being sampled.\n    By default, the first column of X is used to compute the normalized sampling probabilities.\n\n    :param X: Input features, can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: Target variable, can be a pandas Series or a numpy array.\n              If None, it is assumed that the target is not provided.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param sampling_proba_func: A function that takes as input data (X) and returns a series of sampling probabilities.\n                                The function should ensure that the probabilities are normalized.\n    :type sampling_proba_func: callable\n    :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n             If y is None, only the sampled features (Xt) are returned.\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n    \"\"\"\n    # total number of instances that will be missing\n    # sampling\n    sampling_proba = sampling_proba_func(X)\n    sampling_mask = self.random_generator.choice(X.shape[0], p=sampling_proba, size=X.shape[0], replace=True)\n    Xt = X.iloc[sampling_mask,:]\n    yt = y[sampling_mask] if y is not None else y\n    return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingTargetsGenerator","title":"<code>RandomSamplingTargetsGenerator</code>","text":"<p>               Bases: <code>ImbalanceGenerator</code></p> <p>Randomly samples data points</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>class RandomSamplingTargetsGenerator(ImbalanceGenerator):\n    \"\"\"\n    Randomly samples data points\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomSamplingTargetsGenerator with a specified random number generator.\n\n        :param random_generator: A NumPy random number generator used to generate random numbers.\n                                 Defaults to a default random number generator seeded with 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.transformed_labels_ = None\n\n    @preprocess_inputs\n    def generate(self, X, y, sampling_proba_func=lambda y: normalize_proba(y)):\n        \"\"\"\n        Randomly samples instances based on the target values in y using a specified sampling probability function.\n\n        The sampling probability function is applied to the target values y to determine the probability of each instance being sampled.\n        By default, the target values are used to compute the normalized sampling probabilities.\n\n        :param X: Input features, can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: Target variable, must be a pandas Series or a numpy array.\n        :type y: Union[pandas.Series, numpy.ndarray]\n        :param sampling_proba_func: A function that takes as input target values (y) and returns a series of sampling probabilities.\n                                    The function should ensure that the probabilities are normalized.\n        :type sampling_proba_func: callable\n        :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]\n        \"\"\"\n        sampling_probabilities_ = sampling_proba_func(y)\n        sampling_mask = self.random_generator.choice(X.shape[0], p=sampling_probabilities_, size=X.shape[0],\n                                                     replace=True)\n\n        Xt = X.iloc[sampling_mask, :]\n        yt = y[sampling_mask]\n\n        return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingTargetsGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomSamplingTargetsGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator used to generate random numbers. Defaults to a default random number generator seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomSamplingTargetsGenerator with a specified random number generator.\n\n    :param random_generator: A NumPy random number generator used to generate random numbers.\n                             Defaults to a default random number generator seeded with 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.transformed_labels_ = None\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/imbalance/#badgers.generators.tabular_data.imbalance.RandomSamplingTargetsGenerator.generate","title":"<code>generate(X, y, sampling_proba_func=lambda y: normalize_proba(y))</code>","text":"<p>Randomly samples instances based on the target values in y using a specified sampling probability function.</p> <p>The sampling probability function is applied to the target values y to determine the probability of each instance being sampled. By default, the target values are used to compute the normalized sampling probabilities.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>Input features, can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>Union[Series, ndarray]</code> <p>Target variable, must be a pandas Series or a numpy array.</p> required <code>sampling_proba_func</code> <code>callable</code> <p>A function that takes as input target values (y) and returns a series of sampling probabilities. The function should ensure that the probabilities are normalized.</p> <code>lambda y: normalize_proba(y)</code> <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]</code> <p>A tuple containing the sampled features (Xt) and the corresponding target values (yt).</p> Source code in <code>badgers/generators/tabular_data/imbalance.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, sampling_proba_func=lambda y: normalize_proba(y)):\n    \"\"\"\n    Randomly samples instances based on the target values in y using a specified sampling probability function.\n\n    The sampling probability function is applied to the target values y to determine the probability of each instance being sampled.\n    By default, the target values are used to compute the normalized sampling probabilities.\n\n    :param X: Input features, can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: Target variable, must be a pandas Series or a numpy array.\n    :type y: Union[pandas.Series, numpy.ndarray]\n    :param sampling_proba_func: A function that takes as input target values (y) and returns a series of sampling probabilities.\n                                The function should ensure that the probabilities are normalized.\n    :type sampling_proba_func: callable\n    :return: A tuple containing the sampled features (Xt) and the corresponding target values (yt).\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray]]\n    \"\"\"\n    sampling_probabilities_ = sampling_proba_func(y)\n    sampling_mask = self.random_generator.choice(X.shape[0], p=sampling_probabilities_, size=X.shape[0],\n                                                 replace=True)\n\n    Xt = X.iloc[sampling_mask, :]\n    yt = y[sampling_mask]\n\n    return Xt, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/","title":"missingness","text":""},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingAtRandom","title":"<code>DummyMissingAtRandom</code>","text":"<p>               Bases: <code>MissingValueGenerator</code></p> <p>A generator that removes values at random (MAR [1]), where the probability of a data instance X[,i] missing depends upon another feature X[,j], where j is randomly chosen.</p> <p>See also [1] https://stefvanbuuren.name/fimd/sec-MCAR.html</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>class DummyMissingAtRandom(MissingValueGenerator):\n    \"\"\"\n    A generator that removes values at random (MAR [1]),\n    where the probability of a data instance X[_,i] missing depends upon another feature X[_,j],\n    where j is randomly chosen.\n\n    See also [1] https://stefvanbuuren.name/fimd/sec-MCAR.html\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the DummyMissingAtRandom class with a specified random generator.\n\n        :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, percentage_missing: float = 0.1):\n        \"\"\"\n        Introduces missing values into the input features `X` at random based on another feature,\n        where the probability of a data instance X[_,i] missing depends upon another feature X[_,j],\n        and j is randomly chosen.\n\n        :param X: The input features, which can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: The target variable, which can be a pandas Series or a numpy array.\n                  If not provided, it is assumed that the target is not needed and will be ignored.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n        :type percentage_missing: float\n        :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n        \"\"\"\n        assert 0 &lt;= percentage_missing &lt;= 1\n        # initialize probability with zeros\n        p = np.zeros_like(X)\n        # normalize values between 0 and 1\n        X_norm = ((X.max(axis=0) - X) / (X.max(axis=0) - X.min(axis=0))).values\n        # make columns i depends on all the other\n        if X.shape[1] &gt; 1:\n            for i in range(X.shape[1]):\n                j = self.random_generator.choice([x for x in range(X.shape[1]) if x != i])\n                p[:, i] = X_norm[:, j]\n        else:\n            p = X_norm\n        p = normalize_proba(p)\n\n        # compute number of missing values per column\n        nb_missing = int(X.shape[0] * percentage_missing)\n        # generate missing values indices\n        self.missing_values_indices_ = []\n        for col in range(X.shape[1]):\n            rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=p[:, col])\n            self.missing_values_indices_ += [(row, col) for row in rows]\n            # generate missing values\n            X.iloc[rows, col] = np.nan\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingAtRandom.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the DummyMissingAtRandom class with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator instance. Defaults to a new instance of <code>default_rng</code> with seed 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the DummyMissingAtRandom class with a specified random generator.\n\n    :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingAtRandom.generate","title":"<code>generate(X, y, percentage_missing=0.1)</code>","text":"<p>Introduces missing values into the input features <code>X</code> at random based on another feature, where the probability of a data instance X[,i] missing depends upon another feature X[,j], and j is randomly chosen.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>The input features, which can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>The target variable, which can be a pandas Series or a numpy array. If not provided, it is assumed that the target is not needed and will be ignored.</p> required <code>percentage_missing</code> <code>float</code> <p>The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]</code> <p>A tuple containing the modified input features <code>Xt</code> with introduced missing values and the original target <code>y</code>.</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, percentage_missing: float = 0.1):\n    \"\"\"\n    Introduces missing values into the input features `X` at random based on another feature,\n    where the probability of a data instance X[_,i] missing depends upon another feature X[_,j],\n    and j is randomly chosen.\n\n    :param X: The input features, which can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: The target variable, which can be a pandas Series or a numpy array.\n              If not provided, it is assumed that the target is not needed and will be ignored.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n    :type percentage_missing: float\n    :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n    \"\"\"\n    assert 0 &lt;= percentage_missing &lt;= 1\n    # initialize probability with zeros\n    p = np.zeros_like(X)\n    # normalize values between 0 and 1\n    X_norm = ((X.max(axis=0) - X) / (X.max(axis=0) - X.min(axis=0))).values\n    # make columns i depends on all the other\n    if X.shape[1] &gt; 1:\n        for i in range(X.shape[1]):\n            j = self.random_generator.choice([x for x in range(X.shape[1]) if x != i])\n            p[:, i] = X_norm[:, j]\n    else:\n        p = X_norm\n    p = normalize_proba(p)\n\n    # compute number of missing values per column\n    nb_missing = int(X.shape[0] * percentage_missing)\n    # generate missing values indices\n    self.missing_values_indices_ = []\n    for col in range(X.shape[1]):\n        rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=p[:, col])\n        self.missing_values_indices_ += [(row, col) for row in rows]\n        # generate missing values\n        X.iloc[rows, col] = np.nan\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingNotAtRandom","title":"<code>DummyMissingNotAtRandom</code>","text":"<p>               Bases: <code>MissingValueGenerator</code></p> <p>A generator that removes values not at random (MNAR [1]), where the probability of a data instance X[i,j] missing depends linearly upon its own value. A data point X[i,j] = max(X[:,j]) has a missing probability of 1. A data point X[i,j] = min(X[:,j]) has a missing probability of 0.</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>class DummyMissingNotAtRandom(MissingValueGenerator):\n    \"\"\"\n    A generator that removes values not at random (MNAR [1]),\n    where the probability of a data instance X[i,j] missing depends linearly upon its own value.\n    A data point X[i,j] = max(X[:,j]) has a missing probability of 1.\n    A data point X[i,j] = min(X[:,j]) has a missing probability of 0.\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the DummyMissingNotAtRandom class with a specified random generator.\n\n        :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, percentage_missing):\n        \"\"\"\n        Introduces missing values into the input features `X` not at random, where the probability of a data instance X[i,j] missing\n        depends linearly upon its own value. Specifically, a data point X[i,j] = max(X[:,j]) has a missing probability of 1, and a\n        data point X[i,j] = min(X[:,j]) has a missing probability of 0.\n\n        :param X: The input features, which can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: The target variable, which can be a pandas Series or a numpy array.\n                  If not provided, it is assumed that the target is not needed and will be ignored.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n        :type percentage_missing: float\n        :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n        \"\"\"\n        assert 0 &lt;= percentage_missing &lt;= 1\n\n        # normalize values between 0 and 1\n        p = ((X.max(axis=0) - X) / (X.max(axis=0) - X.min(axis=0))).values\n        # make the sum of each column = 1\n        p = normalize_proba(p)\n\n        # compute number of missing values per column\n        nb_missing = int(X.shape[0] * percentage_missing)\n        # generate missing values indices\n        self.missing_values_indices_ = []\n        for col in range(X.shape[1]):\n            rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=p[:, col])\n            self.missing_values_indices_ += [(row, col) for row in rows]\n            # generate missing values\n            X.iloc[rows, col] = np.nan\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingNotAtRandom.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the DummyMissingNotAtRandom class with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator instance. Defaults to a new instance of <code>default_rng</code> with seed 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the DummyMissingNotAtRandom class with a specified random generator.\n\n    :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.DummyMissingNotAtRandom.generate","title":"<code>generate(X, y, percentage_missing)</code>","text":"<p>Introduces missing values into the input features <code>X</code> not at random, where the probability of a data instance X[i,j] missing depends linearly upon its own value. Specifically, a data point X[i,j] = max(X[:,j]) has a missing probability of 1, and a data point X[i,j] = min(X[:,j]) has a missing probability of 0.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>The input features, which can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>The target variable, which can be a pandas Series or a numpy array. If not provided, it is assumed that the target is not needed and will be ignored.</p> required <code>percentage_missing</code> <code>float</code> <p>The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.</p> required <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]</code> <p>A tuple containing the modified input features <code>Xt</code> with introduced missing values and the original target <code>y</code>.</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, percentage_missing):\n    \"\"\"\n    Introduces missing values into the input features `X` not at random, where the probability of a data instance X[i,j] missing\n    depends linearly upon its own value. Specifically, a data point X[i,j] = max(X[:,j]) has a missing probability of 1, and a\n    data point X[i,j] = min(X[:,j]) has a missing probability of 0.\n\n    :param X: The input features, which can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: The target variable, which can be a pandas Series or a numpy array.\n              If not provided, it is assumed that the target is not needed and will be ignored.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n    :type percentage_missing: float\n    :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n    \"\"\"\n    assert 0 &lt;= percentage_missing &lt;= 1\n\n    # normalize values between 0 and 1\n    p = ((X.max(axis=0) - X) / (X.max(axis=0) - X.min(axis=0))).values\n    # make the sum of each column = 1\n    p = normalize_proba(p)\n\n    # compute number of missing values per column\n    nb_missing = int(X.shape[0] * percentage_missing)\n    # generate missing values indices\n    self.missing_values_indices_ = []\n    for col in range(X.shape[1]):\n        rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=p[:, col])\n        self.missing_values_indices_ += [(row, col) for row in rows]\n        # generate missing values\n        X.iloc[rows, col] = np.nan\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingCompletelyAtRandom","title":"<code>MissingCompletelyAtRandom</code>","text":"<p>               Bases: <code>MissingValueGenerator</code></p> <p>A generator that removes values completely at random (MCAR [1]) (uniform distribution over all data).</p> <p>See also [1] https://stefvanbuuren.name/fimd/sec-MCAR.html</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>class MissingCompletelyAtRandom(MissingValueGenerator):\n    \"\"\"\n    A generator that removes values completely at random (MCAR [1]) (uniform distribution over all data).\n\n    See also [1] https://stefvanbuuren.name/fimd/sec-MCAR.html\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the MissingCompletelyAtRandom class with a specified random generator.\n\n        :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n        :type random_generator: numpy.random.Generator\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, percentage_missing: float = 0.1):\n        \"\"\"\n        Introduces missing values into the input features `X` completely at random according to a specified percentage.\n\n        :param X: The input features, which can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: The target variable, which can be a pandas Series or a numpy array.\n                  If not provided, it is assumed that the target is not needed and will be ignored.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n        :type percentage_missing: float\n        :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n        :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n        \"\"\"\n        assert 0 &lt;= percentage_missing &lt;= 1\n        # compute number of missing values per column\n        nb_missing = int(X.shape[0] * percentage_missing)\n        # generate missing values indices\n        self.missing_values_indices_ = []\n        for col in range(X.shape[1]):\n            rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=None)\n            self.missing_values_indices_ += [(row, col) for row in rows]\n            # generate missing values\n            X.iloc[rows, col] = np.nan\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingCompletelyAtRandom.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the MissingCompletelyAtRandom class with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A NumPy random number generator instance. Defaults to a new instance of <code>default_rng</code> with seed 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the MissingCompletelyAtRandom class with a specified random generator.\n\n    :param random_generator: A NumPy random number generator instance. Defaults to a new instance of `default_rng` with seed 0.\n    :type random_generator: numpy.random.Generator\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingCompletelyAtRandom.generate","title":"<code>generate(X, y, percentage_missing=0.1)</code>","text":"<p>Introduces missing values into the input features <code>X</code> completely at random according to a specified percentage.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>The input features, which can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>The target variable, which can be a pandas Series or a numpy array. If not provided, it is assumed that the target is not needed and will be ignored.</p> required <code>percentage_missing</code> <code>float</code> <p>The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]</code> <p>A tuple containing the modified input features <code>Xt</code> with introduced missing values and the original target <code>y</code>.</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, percentage_missing: float = 0.1):\n    \"\"\"\n    Introduces missing values into the input features `X` completely at random according to a specified percentage.\n\n    :param X: The input features, which can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: The target variable, which can be a pandas Series or a numpy array.\n              If not provided, it is assumed that the target is not needed and will be ignored.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param percentage_missing: The proportion of values to be replaced with missing values, expressed as a float between 0 and 1.\n    :type percentage_missing: float\n    :return: A tuple containing the modified input features `Xt` with introduced missing values and the original target `y`.\n    :rtype: Tuple[Union[pandas.DataFrame, numpy.ndarray], Union[pandas.Series, numpy.ndarray, None]]\n    \"\"\"\n    assert 0 &lt;= percentage_missing &lt;= 1\n    # compute number of missing values per column\n    nb_missing = int(X.shape[0] * percentage_missing)\n    # generate missing values indices\n    self.missing_values_indices_ = []\n    for col in range(X.shape[1]):\n        rows = self.random_generator.choice(X.shape[0], size=nb_missing, replace=False, p=None)\n        self.missing_values_indices_ += [(row, col) for row in rows]\n        # generate missing values\n        X.iloc[rows, col] = np.nan\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingValueGenerator","title":"<code>MissingValueGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for missing values transformer</p> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>class MissingValueGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for missing values transformer\n    \"\"\"\n\n    def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random generator\n        \"\"\"\n        self.random_generator = random_generator\n        self.missing_values_indices_ = None\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params):\n        \"\"\"\n        Abstract method to generate missing values in the input data.\n        This should be overridden by subclasses.\n\n        :param X: Input features, can be a pandas DataFrame or a numpy array.\n        :type X: Union[pandas.DataFrame, numpy.ndarray]\n        :param y: Target variable, can be a pandas Series or a numpy array.\n                  If None, it is assumed that the target is not provided and will be ignored.\n        :type y: Union[pandas.Series, numpy.ndarray, None], optional\n        :param params: Additional keyword arguments that might be required for specific implementations.\n        :type params: dict\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingValueGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>A random generator</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>def __init__(self, random_generator: numpy.random.Generator = default_rng(seed=0)):\n    \"\"\"\n    :param random_generator: A random generator\n    \"\"\"\n    self.random_generator = random_generator\n    self.missing_values_indices_ = None\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/missingness/#badgers.generators.tabular_data.missingness.MissingValueGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate missing values in the input data. This should be overridden by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>Union[DataFrame, ndarray]</code> <p>Input features, can be a pandas DataFrame or a numpy array.</p> required <code>y</code> <code>(Union[Series, ndarray, None], optional)</code> <p>Target variable, can be a pandas Series or a numpy array. If None, it is assumed that the target is not provided and will be ignored.</p> required <code>params</code> <code>dict</code> <p>Additional keyword arguments that might be required for specific implementations.</p> <code>{}</code> Source code in <code>badgers/generators/tabular_data/missingness.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params):\n    \"\"\"\n    Abstract method to generate missing values in the input data.\n    This should be overridden by subclasses.\n\n    :param X: Input features, can be a pandas DataFrame or a numpy array.\n    :type X: Union[pandas.DataFrame, numpy.ndarray]\n    :param y: Target variable, can be a pandas Series or a numpy array.\n              If None, it is assumed that the target is not provided and will be ignored.\n    :type y: Union[pandas.Series, numpy.ndarray, None], optional\n    :param params: Additional keyword arguments that might be required for specific implementations.\n    :type params: dict\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/","title":"noise","text":""},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseClassesGenerator","title":"<code>GaussianNoiseClassesGenerator</code>","text":"<p>               Bases: <code>NoiseGenerator</code></p> <p>A generator that adds Gaussian white noise to each class separately.</p> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>class GaussianNoiseClassesGenerator(NoiseGenerator):\n    \"\"\"\n    A generator that adds Gaussian white noise to each class separately.\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the GaussianNoiseClassesGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance from numpy.random,\n                                 used to introduce randomness in the noise generation process.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, noise_std_per_class=dict()):\n        \"\"\"\n        Add Gaussian white noise to the data separately for each class.\n        The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1.\n        Gaussian noise is then generated from a normal distribution with a standard deviation specified in `noise_std_per_class` for each class.\n        This noise is added to the standardized data for each class separately.\n\n        :param X: Input features (pandas DataFrame or numpy array).\n        :param y: Target variable (pandas Series or numpy array).\n        :param noise_std_per_class: A dictionary specifying the standard deviation of the noise to be added for each class.\n            Keys are class labels, and values are the noise standard deviations for the corresponding classes.\n        :return: Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.\n        \"\"\"\n        # standardize X\n        scaler = StandardScaler()\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n        # add noise and repeat for each class\n\n        tmp_Xt = []\n        tmp_yt = []\n        for label, noise_std in noise_std_per_class.items():\n            data_class = np.array(Xt[y == label])\n            noisy_data_class = data_class + self.random_generator.normal(loc=0, scale=noise_std, size=data_class.shape)\n            labels = np.array([label] * data_class.shape[0])\n            tmp_Xt.append(noisy_data_class.copy())\n            tmp_yt.append(labels)\n\n        Xt = np.concatenate(tmp_Xt, axis=0)\n        yt = np.concatenate(tmp_yt, axis=0)\n        # inverse standardization\n        Xt = scaler.inverse_transform(Xt)\n        return pd.DataFrame(data=Xt, columns=X.columns, index=X.index), pd.Series(yt)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseClassesGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the GaussianNoiseClassesGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance from numpy.random, used to introduce randomness in the noise generation process.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the GaussianNoiseClassesGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance from numpy.random,\n                             used to introduce randomness in the noise generation process.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseClassesGenerator.generate","title":"<code>generate(X, y, noise_std_per_class=dict())</code>","text":"<p>Add Gaussian white noise to the data separately for each class. The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1. Gaussian noise is then generated from a normal distribution with a standard deviation specified in <code>noise_std_per_class</code> for each class. This noise is added to the standardized data for each class separately.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>Target variable (pandas Series or numpy array).</p> required <code>noise_std_per_class</code> <p>A dictionary specifying the standard deviation of the noise to be added for each class. Keys are class labels, and values are the noise standard deviations for the corresponding classes.</p> <code>dict()</code> <p>Returns:</p> Type Description <p>Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.</p> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, noise_std_per_class=dict()):\n    \"\"\"\n    Add Gaussian white noise to the data separately for each class.\n    The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1.\n    Gaussian noise is then generated from a normal distribution with a standard deviation specified in `noise_std_per_class` for each class.\n    This noise is added to the standardized data for each class separately.\n\n    :param X: Input features (pandas DataFrame or numpy array).\n    :param y: Target variable (pandas Series or numpy array).\n    :param noise_std_per_class: A dictionary specifying the standard deviation of the noise to be added for each class.\n        Keys are class labels, and values are the noise standard deviations for the corresponding classes.\n    :return: Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.\n    \"\"\"\n    # standardize X\n    scaler = StandardScaler()\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n    # add noise and repeat for each class\n\n    tmp_Xt = []\n    tmp_yt = []\n    for label, noise_std in noise_std_per_class.items():\n        data_class = np.array(Xt[y == label])\n        noisy_data_class = data_class + self.random_generator.normal(loc=0, scale=noise_std, size=data_class.shape)\n        labels = np.array([label] * data_class.shape[0])\n        tmp_Xt.append(noisy_data_class.copy())\n        tmp_yt.append(labels)\n\n    Xt = np.concatenate(tmp_Xt, axis=0)\n    yt = np.concatenate(tmp_yt, axis=0)\n    # inverse standardization\n    Xt = scaler.inverse_transform(Xt)\n    return pd.DataFrame(data=Xt, columns=X.columns, index=X.index), pd.Series(yt)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseGenerator","title":"<code>GaussianNoiseGenerator</code>","text":"<p>               Bases: <code>NoiseGenerator</code></p> <p>A generator that adds Gaussian white noise to the tabular data.</p> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>class GaussianNoiseGenerator(NoiseGenerator):\n    \"\"\"\n    A generator that adds Gaussian white noise to the tabular data.\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n\n        :param random_generator: A random generator\n\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, noise_std):\n        \"\"\"\n        Adds Gaussian white noise to the input data.\n        The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1.\n        Gaussian noise is then generated from a normal distribution with a standard deviation equal to `noise_std`.\n        This noise is added to the standardized data.\n\n        :param X: Input features (pandas DataFrame or numpy array).\n        :param y: Target variable (pandas Series or numpy array), which remains unchanged.\n        :param noise_std: Standard deviation of the Gaussian noise to be added.\n        :return: Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.\n        \"\"\"\n        # standardize X\n        scaler = StandardScaler()\n        # fit, transform\n        Xt = scaler.fit_transform(X)\n        # add noise\n        Xt += self.random_generator.normal(loc=0, scale=noise_std, size=Xt.shape)\n        # inverse standardization\n        Xt = scaler.inverse_transform(Xt)\n        return pd.DataFrame(data=Xt, columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random generator</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n\n    :param random_generator: A random generator\n\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.GaussianNoiseGenerator.generate","title":"<code>generate(X, y, noise_std)</code>","text":"<p>Adds Gaussian white noise to the input data. The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1. Gaussian noise is then generated from a normal distribution with a standard deviation equal to <code>noise_std</code>. This noise is added to the standardized data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>Target variable (pandas Series or numpy array), which remains unchanged.</p> required <code>noise_std</code> <p>Standard deviation of the Gaussian noise to be added.</p> required <p>Returns:</p> Type Description <p>Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.</p> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, noise_std):\n    \"\"\"\n    Adds Gaussian white noise to the input data.\n    The data is first standardized such that each feature (column) has a mean of 0 and a variance of 1.\n    Gaussian noise is then generated from a normal distribution with a standard deviation equal to `noise_std`.\n    This noise is added to the standardized data.\n\n    :param X: Input features (pandas DataFrame or numpy array).\n    :param y: Target variable (pandas Series or numpy array), which remains unchanged.\n    :param noise_std: Standard deviation of the Gaussian noise to be added.\n    :return: Xt, yt where Xt is the noisy input features and yt is the unchanged target variable y.\n    \"\"\"\n    # standardize X\n    scaler = StandardScaler()\n    # fit, transform\n    Xt = scaler.fit_transform(X)\n    # add noise\n    Xt += self.random_generator.normal(loc=0, scale=noise_std, size=Xt.shape)\n    # inverse standardization\n    Xt = scaler.inverse_transform(Xt)\n    return pd.DataFrame(data=Xt, columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.NoiseGenerator","title":"<code>NoiseGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for generators that add noise to tabular data.</p> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>class NoiseGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for generators that add noise to tabular data.\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the NoiseGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance from numpy.random,\n                                 used to introduce randomness in the noise generation process.\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params):\n        \"\"\"\n        Abstract method to generate noisy data. Must be implemented by subclasses.\n\n        :param X: Input features (pandas DataFrame or numpy array).\n        :param y: Target variable (pandas Series or numpy array).\n        :param params: Additional parameters required for noise generation.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.NoiseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the NoiseGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance from numpy.random, used to introduce randomness in the noise generation process.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the NoiseGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance from numpy.random,\n                             used to introduce randomness in the noise generation process.\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/noise/#badgers.generators.tabular_data.noise.NoiseGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate noisy data. Must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>Target variable (pandas Series or numpy array).</p> required <code>params</code> <p>Additional parameters required for noise generation.</p> <code>{}</code> Source code in <code>badgers/generators/tabular_data/noise.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params):\n    \"\"\"\n    Abstract method to generate noisy data. Must be implemented by subclasses.\n\n    :param X: Input features (pandas DataFrame or numpy array).\n    :param y: Target variable (pandas Series or numpy array).\n    :param params: Additional parameters required for noise generation.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/","title":"Index","text":""},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.DecompositionAndOutlierGenerator","title":"<code>DecompositionAndOutlierGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>class DecompositionAndOutlierGenerator(OutliersGenerator):\n\n    def __init__(self, decomposition_transformer: sklearn.base.TransformerMixin, outlier_generator: OutliersGenerator):\n        \"\"\"\n        Initialize the DecompositionAndOutlierGenerator with a decomposition transformer and an outlier generator.\n\n        :param decomposition_transformer: The dimensionality reduction transformer to be applied to the data before generating outliers.\n        :param outlier_generator: The outlier generator to be used after the data has been transformed.\n        \"\"\"\n        assert hasattr(\n            decomposition_transformer,\n            'inverse_transform'), \\\n            f'the decomposition transformer class must implement the inverse_transform function.' \\\n            f'\\nUnfortunately the class {decomposition_transformer} does not'\n        super().__init__(random_generator=outlier_generator.random_generator)\n\n        self.decomposition_transformer = decomposition_transformer\n        self.outlier_generator = outlier_generator\n\n    @preprocess_inputs\n    def generate(self, X, y=None, **params):\n        \"\"\"\n        Randomly generate outliers by first applying a dimensionality reduction technique (sklearn.decomposition)\n        and an outlier transformer.\n\n        1. Standardize the input data (mean = 0, variance = 1)\n        2. Apply the dimensionality reduction transformer\n        3. Generates outliers by applying the outlier transformer\n        4. Inverse the dimensionality reduction and the standardization transformations\n\n        :param X: the input features\n        :param y: the regression target, class labels, or None\n        :param params:\n        :return:\n        \"\"\"\n\n        # standardize the data and apply the dimensionality reduction transformer\n        pipeline = make_pipeline(\n            StandardScaler(),\n            self.decomposition_transformer,\n        )\n        Xt = pipeline.fit_transform(X)\n        # add outliers using the zscore_transformer\n        Xt, yt = self.outlier_generator.generate(Xt, y, **params)\n        # inverse the manifold and standardization transformations\n        return pipeline.inverse_transform(Xt), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.DecompositionAndOutlierGenerator.__init__","title":"<code>__init__(decomposition_transformer, outlier_generator)</code>","text":"<p>Initialize the DecompositionAndOutlierGenerator with a decomposition transformer and an outlier generator.</p> <p>Parameters:</p> Name Type Description Default <code>decomposition_transformer</code> <code>TransformerMixin</code> <p>The dimensionality reduction transformer to be applied to the data before generating outliers.</p> required <code>outlier_generator</code> <code>OutliersGenerator</code> <p>The outlier generator to be used after the data has been transformed.</p> required Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>def __init__(self, decomposition_transformer: sklearn.base.TransformerMixin, outlier_generator: OutliersGenerator):\n    \"\"\"\n    Initialize the DecompositionAndOutlierGenerator with a decomposition transformer and an outlier generator.\n\n    :param decomposition_transformer: The dimensionality reduction transformer to be applied to the data before generating outliers.\n    :param outlier_generator: The outlier generator to be used after the data has been transformed.\n    \"\"\"\n    assert hasattr(\n        decomposition_transformer,\n        'inverse_transform'), \\\n        f'the decomposition transformer class must implement the inverse_transform function.' \\\n        f'\\nUnfortunately the class {decomposition_transformer} does not'\n    super().__init__(random_generator=outlier_generator.random_generator)\n\n    self.decomposition_transformer = decomposition_transformer\n    self.outlier_generator = outlier_generator\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.DecompositionAndOutlierGenerator.generate","title":"<code>generate(X, y=None, **params)</code>","text":"<p>Randomly generate outliers by first applying a dimensionality reduction technique (sklearn.decomposition) and an outlier transformer.</p> <ol> <li>Standardize the input data (mean = 0, variance = 1)</li> <li>Apply the dimensionality reduction transformer</li> <li>Generates outliers by applying the outlier transformer</li> <li>Inverse the dimensionality reduction and the standardization transformations</li> </ol> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features</p> required <code>y</code> <p>the regression target, class labels, or None</p> <code>None</code> <code>params</code> <code>{}</code> <p>Returns:</p> Type Description Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, **params):\n    \"\"\"\n    Randomly generate outliers by first applying a dimensionality reduction technique (sklearn.decomposition)\n    and an outlier transformer.\n\n    1. Standardize the input data (mean = 0, variance = 1)\n    2. Apply the dimensionality reduction transformer\n    3. Generates outliers by applying the outlier transformer\n    4. Inverse the dimensionality reduction and the standardization transformations\n\n    :param X: the input features\n    :param y: the regression target, class labels, or None\n    :param params:\n    :return:\n    \"\"\"\n\n    # standardize the data and apply the dimensionality reduction transformer\n    pipeline = make_pipeline(\n        StandardScaler(),\n        self.decomposition_transformer,\n    )\n    Xt = pipeline.fit_transform(X)\n    # add outliers using the zscore_transformer\n    Xt, yt = self.outlier_generator.generate(Xt, y, **params)\n    # inverse the manifold and standardization transformations\n    return pipeline.inverse_transform(Xt), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.OutliersGenerator","title":"<code>OutliersGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that add outliers to tabular data</p> Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>class OutliersGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that add outliers to tabular data\n    \"\"\"\n\n    def __init__(self, random_generator: np.random.Generator = default_rng(seed=0)):\n        \"\"\"\n        Initialize the OutliersGenerator with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y=None, **params):\n        \"\"\"\n        Abstract method to generate outliers data. Must be implemented by subclasses.\n\n        :param X: Input features (pandas DataFrame or numpy array).\n        :param y: Target variable (pandas Series or numpy array).\n        :param params: Additional parameters required for noise generation.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.OutliersGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the OutliersGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>def __init__(self, random_generator: np.random.Generator = default_rng(seed=0)):\n    \"\"\"\n    Initialize the OutliersGenerator with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/#badgers.generators.tabular_data.outliers.OutliersGenerator.generate","title":"<code>generate(X, y=None, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate outliers data. Must be implemented by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>Target variable (pandas Series or numpy array).</p> <code>None</code> <code>params</code> <p>Additional parameters required for noise generation.</p> <code>{}</code> Source code in <code>badgers/generators/tabular_data/outliers/__init__.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y=None, **params):\n    \"\"\"\n    Abstract method to generate outliers data. Must be implemented by subclasses.\n\n    :param X: Input features (pandas DataFrame or numpy array).\n    :param y: Target variable (pandas Series or numpy array).\n    :param params: Additional parameters required for noise generation.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/","title":"distribution_sampling","text":""},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HyperCubeSampling","title":"<code>HyperCubeSampling</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Sampling uniformly at random within a hypercube encapsulating all the instances</p> <p>See section 6.1.1 in [1]</p> <p>[1] Georg Steinbuss and Klemens B\u00f6hm. 2021.     Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.     ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.     https://doi.org/10.1145/3447822</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>class HyperCubeSampling(OutliersGenerator):\n    \"\"\"\n    Sampling uniformly at random within a hypercube encapsulating all the instances\n\n\n    See section 6.1.1 in [1]\n\n    [1] Georg Steinbuss and Klemens B\u00f6hm. 2021.\n        Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.\n        ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.\n        https://doi.org/10.1145/3447822\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the HyperCubeSampling with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        super().__init__(random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_outliers: int = 10, expansion: float = 0.0):\n        \"\"\"\n\n        How to set the values for expansion.\n        Per default expansion = 0, this means the hypercube will cover all the instances using min and max as boundaries\n        It is possible to make the hypercube bigger, as proposed in [1] section 6.1.1\n\n            Instances from Data usually determine the bounds a, b \u2208 IRd . For this reason, this approach\n            needs them as input. Tax and Duin [51] and Fan et al. [21] state only that these bounds should be\n            chosen so that the hyper-rectangle encapsulates all genuine instances. [ 48] uses the minimum and\n            maximum for each attribute obtained from Data. Theiler and Michael Cai [52] mention that the\n            boundary does not need to be far beyond these boundaries. Abe et al. [1] propose the rule that the\n            boundary should expand the minimum and maximum by 10%. D\u00e9sir et al. [17] propose to expand\n            the boundary by 20%.\n\n        For expanding the hypercube by 10% use expansion = 0.1, for 20% use 0.2, etc.\n\n        :param X: the input features (pandas DataFrame or numpy array).\n        :param y: the class labels, target values, or None (if not provided).\n        :param n_outliers: The number of outliers to generate.\n        :param expansion: how much the hypercube shall be expanded beyond (min,max) range, in percent (0.1 == 10%)\n        :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n                 If `y` is None, the returned target values will also be None.\n        \"\"\"\n        assert expansion &gt;= 0\n        low = 0 - expansion\n        high = 1 + expansion\n\n        scaler = MinMaxScaler()\n        scaler.fit(X)\n\n        outliers = self.random_generator.uniform(low=low, high=high, size=(n_outliers, X.shape[1]))\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HyperCubeSampling.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the HyperCubeSampling with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the HyperCubeSampling with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HyperCubeSampling.generate","title":"<code>generate(X, y, n_outliers=10, expansion=0.0)</code>","text":"<p>How to set the values for expansion. Per default expansion = 0, this means the hypercube will cover all the instances using min and max as boundaries It is possible to make the hypercube bigger, as proposed in [1] section 6.1.1</p> <pre><code>Instances from Data usually determine the bounds a, b \u2208 IRd . For this reason, this approach\nneeds them as input. Tax and Duin [51] and Fan et al. [21] state only that these bounds should be\nchosen so that the hyper-rectangle encapsulates all genuine instances. [ 48] uses the minimum and\nmaximum for each attribute obtained from Data. Theiler and Michael Cai [52] mention that the\nboundary does not need to be far beyond these boundaries. Abe et al. [1] propose the rule that the\nboundary should expand the minimum and maximum by 10%. D\u00e9sir et al. [17] propose to expand\nthe boundary by 20%.\n</code></pre> <p>For expanding the hypercube by 10% use expansion = 0.1, for 20% use 0.2, etc.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>the class labels, target values, or None (if not provided).</p> required <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate.</p> <code>10</code> <code>expansion</code> <code>float</code> <p>how much the hypercube shall be expanded beyond (min,max) range, in percent (0.1 == 10%)</p> <code>0.0</code> <p>Returns:</p> Type Description <p>A tuple containing the augmented feature matrix with added outliers and the corresponding target values. If <code>y</code> is None, the returned target values will also be None.</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_outliers: int = 10, expansion: float = 0.0):\n    \"\"\"\n\n    How to set the values for expansion.\n    Per default expansion = 0, this means the hypercube will cover all the instances using min and max as boundaries\n    It is possible to make the hypercube bigger, as proposed in [1] section 6.1.1\n\n        Instances from Data usually determine the bounds a, b \u2208 IRd . For this reason, this approach\n        needs them as input. Tax and Duin [51] and Fan et al. [21] state only that these bounds should be\n        chosen so that the hyper-rectangle encapsulates all genuine instances. [ 48] uses the minimum and\n        maximum for each attribute obtained from Data. Theiler and Michael Cai [52] mention that the\n        boundary does not need to be far beyond these boundaries. Abe et al. [1] propose the rule that the\n        boundary should expand the minimum and maximum by 10%. D\u00e9sir et al. [17] propose to expand\n        the boundary by 20%.\n\n    For expanding the hypercube by 10% use expansion = 0.1, for 20% use 0.2, etc.\n\n    :param X: the input features (pandas DataFrame or numpy array).\n    :param y: the class labels, target values, or None (if not provided).\n    :param n_outliers: The number of outliers to generate.\n    :param expansion: how much the hypercube shall be expanded beyond (min,max) range, in percent (0.1 == 10%)\n    :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n             If `y` is None, the returned target values will also be None.\n    \"\"\"\n    assert expansion &gt;= 0\n    low = 0 - expansion\n    high = 1 + expansion\n\n    scaler = MinMaxScaler()\n    scaler.fit(X)\n\n    outliers = self.random_generator.uniform(low=low, high=high, size=(n_outliers, X.shape[1]))\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HypersphereSamplingGenerator","title":"<code>HypersphereSamplingGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Generates outliers by sampling points from a hypersphere with radius at least 3 sigma</p> <p>Very similar to \"GaussTail\" in section 6.1.5 in [1]</p> <p>[1] Georg Steinbuss and Klemens B\u00f6hm. 2021.     Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.     ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.     https://doi.org/10.1145/3447822</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>class HypersphereSamplingGenerator(OutliersGenerator):\n    \"\"\"\n    Generates outliers by sampling points from a hypersphere with radius at least 3 sigma\n\n    Very similar to \"GaussTail\" in section 6.1.5 in [1]\n\n    [1] Georg Steinbuss and Klemens B\u00f6hm. 2021.\n        Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.\n        ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.\n        https://doi.org/10.1145/3447822\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the HypersphereSamplingGenerator with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        super().__init__(random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y=None, n_outliers: int = 10, scale: float = 1.0):\n        \"\"\"\n        Randomly generates outliers by sampling points from a hypersphere.\n\n        The process involves the following steps:\n        1. Standardize the input data so that it has a mean of 0 and a variance of 1.\n        2. Generate outliers by:\n           - choosing angles uniformly at random for each dimension of the data.\n           - setting the radius to be 3 plus a random number drawn from an exponential distribution\n             (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html).\n        3. Convert the spherical coordinates to Cartesian coordinates.\n        4. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.\n\n        :param X: the input features (pandas DataFrame or numpy array).\n        :param y: the class labels, target values, or None (if not provided).\n        :param n_outliers: The number of outliers to generate.\n        :param scale: float (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html)\n                    The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n                    non-negative.\n        :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n                 If `y` is None, the returned target values will also be None.\n        \"\"\"\n\n        # standardize X\n        scaler = StandardScaler()\n\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n\n        # computing outliers\n        outliers = np.array([\n            random_spherical_coordinate(\n                random_generator=self.random_generator,\n                size=Xt.shape[1],\n                radius=3. + self.random_generator.exponential(scale=scale)\n            )\n            for _ in range(n_outliers)\n        ])\n\n        # in case we only have 1 outlier, reshape the array to match sklearn convention\n        if outliers.shape[0] == 1:\n            outliers = outliers.reshape(1, -1)\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HypersphereSamplingGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the HypersphereSamplingGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the HypersphereSamplingGenerator with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.HypersphereSamplingGenerator.generate","title":"<code>generate(X, y=None, n_outliers=10, scale=1.0)</code>","text":"<p>Randomly generates outliers by sampling points from a hypersphere.</p> <p>The process involves the following steps: 1. Standardize the input data so that it has a mean of 0 and a variance of 1. 2. Generate outliers by:    - choosing angles uniformly at random for each dimension of the data.    - setting the radius to be 3 plus a random number drawn from an exponential distribution      (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html). 3. Convert the spherical coordinates to Cartesian coordinates. 4. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>the class labels, target values, or None (if not provided).</p> <code>None</code> <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate.</p> <code>10</code> <code>scale</code> <code>float</code> <p>float (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html) The scale parameter, :math:<code>\beta = 1/\\lambda</code>. Must be non-negative.</p> <code>1.0</code> <p>Returns:</p> Type Description <p>A tuple containing the augmented feature matrix with added outliers and the corresponding target values. If <code>y</code> is None, the returned target values will also be None.</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, n_outliers: int = 10, scale: float = 1.0):\n    \"\"\"\n    Randomly generates outliers by sampling points from a hypersphere.\n\n    The process involves the following steps:\n    1. Standardize the input data so that it has a mean of 0 and a variance of 1.\n    2. Generate outliers by:\n       - choosing angles uniformly at random for each dimension of the data.\n       - setting the radius to be 3 plus a random number drawn from an exponential distribution\n         (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html).\n    3. Convert the spherical coordinates to Cartesian coordinates.\n    4. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.\n\n    :param X: the input features (pandas DataFrame or numpy array).\n    :param y: the class labels, target values, or None (if not provided).\n    :param n_outliers: The number of outliers to generate.\n    :param scale: float (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html)\n                The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n                non-negative.\n    :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n             If `y` is None, the returned target values will also be None.\n    \"\"\"\n\n    # standardize X\n    scaler = StandardScaler()\n\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n\n    # computing outliers\n    outliers = np.array([\n        random_spherical_coordinate(\n            random_generator=self.random_generator,\n            size=Xt.shape[1],\n            radius=3. + self.random_generator.exponential(scale=scale)\n        )\n        for _ in range(n_outliers)\n    ])\n\n    # in case we only have 1 outlier, reshape the array to match sklearn convention\n    if outliers.shape[0] == 1:\n        outliers = outliers.reshape(1, -1)\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.ZScoreSamplingGenerator","title":"<code>ZScoreSamplingGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates outliers as data points with a z-score &gt; 3.</p> <p>Very similar to \"GaussTail\" in section 6.1.5 in [1]</p> <p>[1] Georg Steinbuss and Klemens B\u00f6hm. 2021.     Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.     ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.     https://doi.org/10.1145/3447822</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>class ZScoreSamplingGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly generates outliers as data points with a z-score &gt; 3.\n\n    Very similar to \"GaussTail\" in section 6.1.5 in [1]\n\n    [1] Georg Steinbuss and Klemens B\u00f6hm. 2021.\n        Generating Artificial Outliers in the Absence of Genuine Ones \u2014 A Survey.\n        ACM Trans. Knowl. Discov. Data 15, 2, Article 30 (April 2021), 37 pages.\n        https://doi.org/10.1145/3447822\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the ZScoreSamplingGenerator with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        super().__init__(random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_outliers: int = 10, scale: float = 1.0):\n        \"\"\"\n        Randomly generates outliers as data points with a z-score &gt; 3.\n\n        The process involves the following steps:\n        1. Standardize the input data so that it has a mean of 0 and a variance of 1.\n        2. Generate outliers by:\n           - choosing a random sign for each outlier.\n           - for each dimension of the data, set the value to be 3 plus a random number drawn from an exponential distribution\n            (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html).\n        3. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.\n\n        :param X: the input features (pandas DataFrame or numpy array).\n        :param y: the class labels, target values, or None (if not provided).\n        :param n_outliers: The number of outliers to generate.\n        :param scale: float or array_like of floats (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html)\n                    The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n                    non-negative.\n        :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n                 If `y` is None, the returned target values will also be None.\n        \"\"\"\n\n        # standardize X\n        scaler = StandardScaler()\n\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n\n        # generate outliers\n        outliers = np.array([\n            random_sign(self.random_generator, size=Xt.shape[1]) * (\n                3. + self.random_generator.exponential(size=Xt.shape[1], scale=scale))\n            for _ in range(n_outliers)\n        ])\n\n        # in case we only have 1 outlier, reshape the array to match sklearn convention\n        if outliers.shape[0] == 1:\n            outliers = outliers.reshape(1, -1)\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.ZScoreSamplingGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the ZScoreSamplingGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the ZScoreSamplingGenerator with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/distribution_sampling/#badgers.generators.tabular_data.outliers.distribution_sampling.ZScoreSamplingGenerator.generate","title":"<code>generate(X, y, n_outliers=10, scale=1.0)</code>","text":"<p>Randomly generates outliers as data points with a z-score &gt; 3.</p> <p>The process involves the following steps: 1. Standardize the input data so that it has a mean of 0 and a variance of 1. 2. Generate outliers by:    - choosing a random sign for each outlier.    - for each dimension of the data, set the value to be 3 plus a random number drawn from an exponential distribution     (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html). 3. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>the class labels, target values, or None (if not provided).</p> required <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate.</p> <code>10</code> <code>scale</code> <code>float</code> <p>float or array_like of floats (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html) The scale parameter, :math:<code>\beta = 1/\\lambda</code>. Must be non-negative.</p> <code>1.0</code> <p>Returns:</p> Type Description <p>A tuple containing the augmented feature matrix with added outliers and the corresponding target values. If <code>y</code> is None, the returned target values will also be None.</p> Source code in <code>badgers/generators/tabular_data/outliers/distribution_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_outliers: int = 10, scale: float = 1.0):\n    \"\"\"\n    Randomly generates outliers as data points with a z-score &gt; 3.\n\n    The process involves the following steps:\n    1. Standardize the input data so that it has a mean of 0 and a variance of 1.\n    2. Generate outliers by:\n       - choosing a random sign for each outlier.\n       - for each dimension of the data, set the value to be 3 plus a random number drawn from an exponential distribution\n        (see https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html).\n    3. Apply the inverse of the standardization transformation to convert the generated outliers back to the original scale.\n\n    :param X: the input features (pandas DataFrame or numpy array).\n    :param y: the class labels, target values, or None (if not provided).\n    :param n_outliers: The number of outliers to generate.\n    :param scale: float or array_like of floats (the scale parameter from https://numpy.org/doc/stable/reference/random/generated/numpy.random.Generator.exponential.html)\n                The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n                non-negative.\n    :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n             If `y` is None, the returned target values will also be None.\n    \"\"\"\n\n    # standardize X\n    scaler = StandardScaler()\n\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n\n    # generate outliers\n    outliers = np.array([\n        random_sign(self.random_generator, size=Xt.shape[1]) * (\n            3. + self.random_generator.exponential(size=Xt.shape[1], scale=scale))\n        for _ in range(n_outliers)\n    ])\n\n    # in case we only have 1 outlier, reshape the array to match sklearn convention\n    if outliers.shape[0] == 1:\n        outliers = outliers.reshape(1, -1)\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/instance_sampling/","title":"instance_sampling","text":""},{"location":"reference/badgers/generators/tabular_data/outliers/instance_sampling/#badgers.generators.tabular_data.outliers.instance_sampling.UniformInstanceAttributeSampling","title":"<code>UniformInstanceAttributeSampling</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates outliers by sampling from existing instances attributes uniformly at random</p> Source code in <code>badgers/generators/tabular_data/outliers/instance_sampling.py</code> <pre><code>class UniformInstanceAttributeSampling(OutliersGenerator):\n    \"\"\"\n    Randomly generates outliers by sampling from existing instances attributes uniformly at random\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the UniformInstanceAttributeSampling with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        super().__init__(random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_outliers: int = 10):\n        \"\"\"\n\n\n        :param X: the input features (pandas DataFrame or numpy array).\n        :param y: the class labels, target values, or None (if not provided).\n        :param n_outliers: The number of outliers to generate.\n        :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n                 If `y` is None, the returned target values will also be None.\n        \"\"\"\n\n        outliers = pd.DataFrame(\n            data=np.stack([self.random_generator.choice(X.iloc[:,i], size=n_outliers) for i in range(X.shape[1])]).T,\n            columns = X.columns\n        )\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return outliers, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/instance_sampling/#badgers.generators.tabular_data.outliers.instance_sampling.UniformInstanceAttributeSampling.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the UniformInstanceAttributeSampling with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/instance_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the UniformInstanceAttributeSampling with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/instance_sampling/#badgers.generators.tabular_data.outliers.instance_sampling.UniformInstanceAttributeSampling.generate","title":"<code>generate(X, y, n_outliers=10)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>the class labels, target values, or None (if not provided).</p> required <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate.</p> <code>10</code> <p>Returns:</p> Type Description <p>A tuple containing the augmented feature matrix with added outliers and the corresponding target values. If <code>y</code> is None, the returned target values will also be None.</p> Source code in <code>badgers/generators/tabular_data/outliers/instance_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_outliers: int = 10):\n    \"\"\"\n\n\n    :param X: the input features (pandas DataFrame or numpy array).\n    :param y: the class labels, target values, or None (if not provided).\n    :param n_outliers: The number of outliers to generate.\n    :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n             If `y` is None, the returned target values will also be None.\n    \"\"\"\n\n    outliers = pd.DataFrame(\n        data=np.stack([self.random_generator.choice(X.iloc[:,i], size=n_outliers) for i in range(X.shape[1])]).T,\n        columns = X.columns\n    )\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return outliers, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/","title":"low_density_sampling","text":""},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.HistogramSamplingGenerator","title":"<code>HistogramSamplingGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates outliers from low density regions. Low density regions are estimated through a histogram.</p> <p>WARNING: This computes a full histogram in d-dimensions (d = nb features / columns), which is O(d\u00b2). Should only be used with low dimensionality data! It will raise an error if the number of dimensions is greater than 5.</p> <p>TODO: this works but is very inefficient, better strategies are welcome!</p> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>class HistogramSamplingGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly generates outliers from low density regions.\n    Low density regions are estimated through a histogram.\n\n    -----------------------------------------\n    WARNING:\n    This computes a full histogram in d-dimensions (d = nb features / columns), which is O(d\u00b2).\n    Should only be used with low dimensionality data!\n    It will raise an error if the number of dimensions is greater than 5.\n    -----------------------------------------\n\n    TODO: this works but is very inefficient, better strategies are welcome!\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the HistogramSamplingGenerator with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n\n        super().__init__(random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y=None, n_outliers: int = 10,\n                 threshold_low_density: float = 0.1, bins: int = 10):\n        \"\"\"\n        Randomly generates outliers from low density regions. Low density regions are estimated through histograms\n\n        1. Standardize the input data (mean = 0, variance = 1)\n        2. Compute and normalize histogram for the data\n        3. Sample datapoint uniformly at random within bins of low density\n        4. Inverse the standardization transformation\n\n        :param X: the input features\n        :param y: not used\n        :param n_outliers: The number of outliers to generate\n        :param threshold_low_density: the threshold that defines a low density region (must be between 0 and 1)\n        :param bins: number of bins for the histogram\n        :return:\n        \"\"\"\n        assert 0 &lt; threshold_low_density &lt; 1\n        if X.shape[1] &gt; 5:\n            raise NotImplementedError('So far this generator only supports tabular data with at most 5 columns')\n        # standardize X\n        scaler = StandardScaler()\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n\n        # compute the histogram of the data\n        hist, edges = np.histogramdd(Xt, density=False, bins=bins)\n        # normalize\n        norm_hist = hist / (np.max(hist) - np.min(hist))\n        # get coordinates of the histogram where the density is low (below a certain threshold)\n        hist_coords_low_density = np.where(norm_hist &lt;= threshold_low_density)\n        # randomly pick some coordinates in the histogram where the density is low\n        hist_coords_random = self.random_generator.choice(list(zip(*hist_coords_low_density)), n_outliers,\n                                                          replace=True)\n\n        # computing outliers values\n        outliers = np.array([\n            [\n                self.random_generator.uniform(low=edges[i][c], high=edges[i][c + 1])\n                for i, c in enumerate(h_coords)\n            ]\n            for h_coords in hist_coords_random\n        ])\n\n        # in case we only have 1 outlier, reshape the array to match sklearn convention\n        if outliers.shape[0] == 1:\n            outliers = outliers.reshape(1, -1)\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.HistogramSamplingGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the HistogramSamplingGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the HistogramSamplingGenerator with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.HistogramSamplingGenerator.generate","title":"<code>generate(X, y=None, n_outliers=10, threshold_low_density=0.1, bins=10)</code>","text":"<p>Randomly generates outliers from low density regions. Low density regions are estimated through histograms</p> <ol> <li>Standardize the input data (mean = 0, variance = 1)</li> <li>Compute and normalize histogram for the data</li> <li>Sample datapoint uniformly at random within bins of low density</li> <li>Inverse the standardization transformation</li> </ol> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features</p> required <code>y</code> <p>not used</p> <code>None</code> <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate</p> <code>10</code> <code>threshold_low_density</code> <code>float</code> <p>the threshold that defines a low density region (must be between 0 and 1)</p> <code>0.1</code> <code>bins</code> <code>int</code> <p>number of bins for the histogram</p> <code>10</code> <p>Returns:</p> Type Description Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, n_outliers: int = 10,\n             threshold_low_density: float = 0.1, bins: int = 10):\n    \"\"\"\n    Randomly generates outliers from low density regions. Low density regions are estimated through histograms\n\n    1. Standardize the input data (mean = 0, variance = 1)\n    2. Compute and normalize histogram for the data\n    3. Sample datapoint uniformly at random within bins of low density\n    4. Inverse the standardization transformation\n\n    :param X: the input features\n    :param y: not used\n    :param n_outliers: The number of outliers to generate\n    :param threshold_low_density: the threshold that defines a low density region (must be between 0 and 1)\n    :param bins: number of bins for the histogram\n    :return:\n    \"\"\"\n    assert 0 &lt; threshold_low_density &lt; 1\n    if X.shape[1] &gt; 5:\n        raise NotImplementedError('So far this generator only supports tabular data with at most 5 columns')\n    # standardize X\n    scaler = StandardScaler()\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n\n    # compute the histogram of the data\n    hist, edges = np.histogramdd(Xt, density=False, bins=bins)\n    # normalize\n    norm_hist = hist / (np.max(hist) - np.min(hist))\n    # get coordinates of the histogram where the density is low (below a certain threshold)\n    hist_coords_low_density = np.where(norm_hist &lt;= threshold_low_density)\n    # randomly pick some coordinates in the histogram where the density is low\n    hist_coords_random = self.random_generator.choice(list(zip(*hist_coords_low_density)), n_outliers,\n                                                      replace=True)\n\n    # computing outliers values\n    outliers = np.array([\n        [\n            self.random_generator.uniform(low=edges[i][c], high=edges[i][c + 1])\n            for i, c in enumerate(h_coords)\n        ]\n        for h_coords in hist_coords_random\n    ])\n\n    # in case we only have 1 outlier, reshape the array to match sklearn convention\n    if outliers.shape[0] == 1:\n        outliers = outliers.reshape(1, -1)\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.IndependentHistogramsGenerator","title":"<code>IndependentHistogramsGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates outliers from low density regions. Low density regions are estimated through several independent histograms (one for each feature).</p> <p>For each feature (column), a histogram is computed (it approximates the marginal distribution). Values are generated from bins with a low number of data points.</p> <p>All values generated for each feature are simply concatenated (independence hypothesis!).</p> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>class IndependentHistogramsGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly generates outliers from low density regions.\n    Low density regions are estimated through several independent histograms (one for each feature).\n\n    For each feature (column), a histogram is computed (it approximates the marginal distribution).\n    Values are generated from bins with a low number of data points.\n\n    All values generated for each feature are simply concatenated (independence hypothesis!).\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y=None, n_outliers: int = 10, bins: int = 10):\n        \"\"\"\n        Randomly generates outliers from low density regions.\n        Low density regions are estimated through several independent histograms (one for each feature).\n\n        For each feature (column), a histogram is computed (it approximates the marginal distribution).\n        Values are generated from bins with a low number of data points.\n\n        All values generated for each feature are simply concatenated (independence hypothesis!).\n\n        :param X: the input features (pandas DataFrame or numpy array).\n        :param y: the class labels, target values, or None (not used).\n        :param n_outliers: The number of outliers to generate.\n        :param bins: The number of bins to use when creating histograms for each feature.\n        :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n                 If `y` is None, the returned target values will also be None.\n        \"\"\"\n        outliers = []\n\n        # loop over all features (columns)\n        for col in range(X.shape[1]):\n            # compute histogram of the current feature\n            hist, bin_edges = np.histogram(X.iloc[:, col], bins=bins)\n            # compute inverse density\n            inv_density = 1 - hist / np.max(hist)\n            # the sampling probability is proportional to the inverse density\n            p = inv_density / np.sum(inv_density)\n            # generate values:\n            # first, choose randomly from which bin the value must be sampled\n            indices = self.random_generator.choice(bins, p=p, size=n_outliers, replace=True)\n            # second, sample uniformly at random from the selected bin\n            values = [self.random_generator.uniform(low=bin_edges[i], high=bin_edges[i + 1]) for i in indices]\n            # append the values for the current feature\n            outliers.append(values)\n        # cast as a numpy array\n        outliers = np.array(outliers).T\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        return outliers, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.IndependentHistogramsGenerator.generate","title":"<code>generate(X, y=None, n_outliers=10, bins=10)</code>","text":"<p>Randomly generates outliers from low density regions. Low density regions are estimated through several independent histograms (one for each feature).</p> <p>For each feature (column), a histogram is computed (it approximates the marginal distribution). Values are generated from bins with a low number of data points.</p> <p>All values generated for each feature are simply concatenated (independence hypothesis!).</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features (pandas DataFrame or numpy array).</p> required <code>y</code> <p>the class labels, target values, or None (not used).</p> <code>None</code> <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate.</p> <code>10</code> <code>bins</code> <code>int</code> <p>The number of bins to use when creating histograms for each feature.</p> <code>10</code> <p>Returns:</p> Type Description <p>A tuple containing the augmented feature matrix with added outliers and the corresponding target values. If <code>y</code> is None, the returned target values will also be None.</p> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, n_outliers: int = 10, bins: int = 10):\n    \"\"\"\n    Randomly generates outliers from low density regions.\n    Low density regions are estimated through several independent histograms (one for each feature).\n\n    For each feature (column), a histogram is computed (it approximates the marginal distribution).\n    Values are generated from bins with a low number of data points.\n\n    All values generated for each feature are simply concatenated (independence hypothesis!).\n\n    :param X: the input features (pandas DataFrame or numpy array).\n    :param y: the class labels, target values, or None (not used).\n    :param n_outliers: The number of outliers to generate.\n    :param bins: The number of bins to use when creating histograms for each feature.\n    :return: A tuple containing the augmented feature matrix with added outliers and the corresponding target values.\n             If `y` is None, the returned target values will also be None.\n    \"\"\"\n    outliers = []\n\n    # loop over all features (columns)\n    for col in range(X.shape[1]):\n        # compute histogram of the current feature\n        hist, bin_edges = np.histogram(X.iloc[:, col], bins=bins)\n        # compute inverse density\n        inv_density = 1 - hist / np.max(hist)\n        # the sampling probability is proportional to the inverse density\n        p = inv_density / np.sum(inv_density)\n        # generate values:\n        # first, choose randomly from which bin the value must be sampled\n        indices = self.random_generator.choice(bins, p=p, size=n_outliers, replace=True)\n        # second, sample uniformly at random from the selected bin\n        values = [self.random_generator.uniform(low=bin_edges[i], high=bin_edges[i + 1]) for i in indices]\n        # append the values for the current feature\n        outliers.append(values)\n    # cast as a numpy array\n    outliers = np.array(outliers).T\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    return outliers, yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.LowDensitySamplingGenerator","title":"<code>LowDensitySamplingGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates outliers from low density regions. Low density regions are estimated using a KernelDensity estimator. Points are sampled uniformly at random and filtered out if they do not belong to a low density region</p> <p>TODO: this works but might not be efficient, a better sampling strategy is welcome</p> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>class LowDensitySamplingGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly generates outliers from low density regions.\n    Low density regions are estimated using a KernelDensity estimator.\n    Points are sampled uniformly at random and filtered out if they do not belong to a low density region\n\n    TODO: this works but might not be efficient, a better sampling strategy is welcome\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the LowDensitySamplingGenerator with a random number generator.\n\n        :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.density_estimator: KernelDensity = KernelDensity(bandwidth=\"scott\")\n\n    @preprocess_inputs\n    def generate(self, X, y=None, n_outliers: int = 10, threshold_low_density: float = 0.1, max_samples: int = 100):\n        \"\"\"\n        Generate data points belonging to low density regions.\n\n        Pseudo code:\n        - Standardize the data X\n        - Estimate the density based upon the original data X\n        - Computes a threshold for determining low density (so far 10th percentile)\n        - Sample uniformly at random within the hypercube [min, max]\n        - Estimate the density of the new points and filter out the ones with a density that is above the threshold\n\n        :param X: the input features\n        :param y: not used\n        :param n_outliers: The number of outliers to generate\n        :param threshold_low_density: the threshold that defines a low density region (must be between 0 and 1)\n        :param max_samples:\n        :return:\n        \"\"\"\n        assert 0 &lt; threshold_low_density &lt; 1\n        # standardize X\n        scaler = StandardScaler()\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n        # fit density estimator\n        self.density_estimator = self.density_estimator.fit(Xt)\n        low_density_threshold = np.percentile(self.density_estimator.score_samples(Xt), threshold_low_density)\n\n        if max_samples is None:\n            max_samples = n_outliers * 100\n\n        outliers = np.array([\n            x\n            for x in self.random_generator.uniform(\n                low=np.min(Xt, axis=0),\n                high=np.max(Xt, axis=0),\n                size=(max_samples, Xt.shape[1])\n            )\n            if self.density_estimator.score_samples(x.reshape(1, -1)) &lt;= low_density_threshold\n        ])\n\n        if outliers.shape[0] &lt; n_outliers:\n            warnings.warn(\n                f'LowDensitySamplingGenerator could not generate all {n_outliers} outliers. It only generated {len(outliers)}.')\n        else:\n            outliers = outliers[:n_outliers]\n\n        # in case we only have 1 outlier, reshape the array to match sklearn convention\n        if outliers.shape[0] == 1:\n            outliers = outliers.reshape(1, -1)\n\n        # add \"outliers\" as labels for outliers\n        yt = np.array([\"outliers\"] * len(outliers))\n\n        # in the case no outliers could be generated\n        if outliers.shape[0] == 0:\n            return outliers, yt\n\n        return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.LowDensitySamplingGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the LowDensitySamplingGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of numpy's random number generator (default is a new generator with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the LowDensitySamplingGenerator with a random number generator.\n\n    :param random_generator: An instance of numpy's random number generator (default is a new generator with seed 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.density_estimator: KernelDensity = KernelDensity(bandwidth=\"scott\")\n</code></pre>"},{"location":"reference/badgers/generators/tabular_data/outliers/low_density_sampling/#badgers.generators.tabular_data.outliers.low_density_sampling.LowDensitySamplingGenerator.generate","title":"<code>generate(X, y=None, n_outliers=10, threshold_low_density=0.1, max_samples=100)</code>","text":"<p>Generate data points belonging to low density regions.</p> <p>Pseudo code: - Standardize the data X - Estimate the density based upon the original data X - Computes a threshold for determining low density (so far 10th percentile) - Sample uniformly at random within the hypercube [min, max] - Estimate the density of the new points and filter out the ones with a density that is above the threshold</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>the input features</p> required <code>y</code> <p>not used</p> <code>None</code> <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate</p> <code>10</code> <code>threshold_low_density</code> <code>float</code> <p>the threshold that defines a low density region (must be between 0 and 1)</p> <code>0.1</code> <code>max_samples</code> <code>int</code> <code>100</code> <p>Returns:</p> Type Description Source code in <code>badgers/generators/tabular_data/outliers/low_density_sampling.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y=None, n_outliers: int = 10, threshold_low_density: float = 0.1, max_samples: int = 100):\n    \"\"\"\n    Generate data points belonging to low density regions.\n\n    Pseudo code:\n    - Standardize the data X\n    - Estimate the density based upon the original data X\n    - Computes a threshold for determining low density (so far 10th percentile)\n    - Sample uniformly at random within the hypercube [min, max]\n    - Estimate the density of the new points and filter out the ones with a density that is above the threshold\n\n    :param X: the input features\n    :param y: not used\n    :param n_outliers: The number of outliers to generate\n    :param threshold_low_density: the threshold that defines a low density region (must be between 0 and 1)\n    :param max_samples:\n    :return:\n    \"\"\"\n    assert 0 &lt; threshold_low_density &lt; 1\n    # standardize X\n    scaler = StandardScaler()\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n    # fit density estimator\n    self.density_estimator = self.density_estimator.fit(Xt)\n    low_density_threshold = np.percentile(self.density_estimator.score_samples(Xt), threshold_low_density)\n\n    if max_samples is None:\n        max_samples = n_outliers * 100\n\n    outliers = np.array([\n        x\n        for x in self.random_generator.uniform(\n            low=np.min(Xt, axis=0),\n            high=np.max(Xt, axis=0),\n            size=(max_samples, Xt.shape[1])\n        )\n        if self.density_estimator.score_samples(x.reshape(1, -1)) &lt;= low_density_threshold\n    ])\n\n    if outliers.shape[0] &lt; n_outliers:\n        warnings.warn(\n            f'LowDensitySamplingGenerator could not generate all {n_outliers} outliers. It only generated {len(outliers)}.')\n    else:\n        outliers = outliers[:n_outliers]\n\n    # in case we only have 1 outlier, reshape the array to match sklearn convention\n    if outliers.shape[0] == 1:\n        outliers = outliers.reshape(1, -1)\n\n    # add \"outliers\" as labels for outliers\n    yt = np.array([\"outliers\"] * len(outliers))\n\n    # in the case no outliers could be generated\n    if outliers.shape[0] == 0:\n        return outliers, yt\n\n    return scaler.inverse_transform(outliers), yt\n</code></pre>"},{"location":"reference/badgers/generators/text/","title":"Index","text":"<p>This module contains all the generator functions designed to process and yield data from text inputs.</p>"},{"location":"reference/badgers/generators/text/typos/","title":"typos","text":""},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.LeetSpeakGenerator","title":"<code>LeetSpeakGenerator</code>","text":"<p>               Bases: <code>TyposGenerator</code></p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>class LeetSpeakGenerator(TyposGenerator):\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the LeetSpeakGenerator with a given random number generator.\n\n        :param random_generator: A random number generator used to introduce randomness in leetspeak transformation.\n        :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.leet_speak_mapping = {\n            \"A\": [\"4\", \"/\\\\\", \"@\", \"/-\\\\\", \"^\", \"(L\", \"\\u0414\"],\n            \"B\": [\"I3\", \"8\", \"13\", \"|3\", \"\\u00df\", \"!3\", \"(3\", \"/3\", \")3\", \"|-]\", \"j3\"],\n            \"C\": [\"[\", \"\\u00a2\", \"&lt;\", \"(\", \"\\u00a9\"],\n            \"D\": [\")\", \"|)\", \"(|\", \"[)\", \"I&gt;\", \"|&gt;\", \"?\", \"T)\", \"I7\", \"cl\", \"|}\", \"|]\"],\n            \"E\": [\"3\", \"&amp;\", \"\\u00a3\", \"\\u20ac\", \"[-\", \"|=-\"],\n            \"F\": [\"|=\", \"\\u0192\", \"|#\", \"ph\", \"/=\", \"v\"],\n            \"G\": [\"6\", \"&amp;\", \"(_+\", \"9\", \"C-\", \"gee\", \"(?,\", \"[,\", \"{,\", \"&lt;-\", \"(.\"],\n            \"H\": [\"#\", \"/-/\", \"\\\\-\\\\\", \"[-]\", \"]-[\", \")-(\", \"(-)\", \":-:\", \"|~|\", \"|-|\", \"]~[\", \"}{\", \"!-!\", \"1-1\",\n                  \"\\\\-/\", \"I+I\", \"?\"],\n            \"I\": [\"1\", \"|\", \"][\", \"!\", \"eye\", \"3y3\"],\n            \"J\": [\",_|\", \"_|\", \"._|\", \"._]\", \"_]\", \",_]\", \"]\"],\n            \"K\": [\"&gt;|\", \"|&lt;\", \"1&lt;\", \"|c\", \"|(7&lt;\"],\n            \"L\": [\"1\", \"2\", \"\\u00a3\", \"7\", \"|_\", \"|\"],\n            \"M\": [\"/\\\\/\\\\\", \"/V\\\\\", \"[V]\", \"|\\\\/|\", \"^^\", \"&lt;\\\\/&gt;\", \"{V}\", \"(v)\", \"(V)\", \"|\\\\|\\\\\", \"]\\\\/[\", \"nn\", \"11\"],\n            \"N\": [\"^/\", \"|\\\\|\", \"/\\\\/\", \"[\\\\]\", \"&lt;\\\\&gt;\", \"{\\\\}\", \"/V\", \"^\", \"\\u0e17\", \"\\u0418\"],\n            \"O\": [\"0\", \"()\", \"oh\", \"[]\", \"p\", \"&lt;&gt;\", \"\\u00d8\"],\n            \"P\": [\"|*\", \"|o\", \"|\\u00ba\", \"?\", \"|^\", \"|&gt;\", \"|\\\"\", \"9\", \"[]D\", \"|\\u00b0\", \"|7\"],\n            \"Q\": [\"(_,)\", \"()_\", \"2\", \"0_\", \"&lt;|\", \"&amp;\", \"9\", \"\\u00b6\", \"\\u204b\", \"\\u2117\"],\n            \"R\": [\"I2\", \"9\", \"|`\", \"|~\", \"|?\", \"/2\", \"|^\", \"lz\", \"7\", \"2\", \"12\", \"\\u00ae\", \"[z\", \"\\u042f\", \".-\", \"|2\",\n                  \"|-\", \"3\"],\n            \"S\": [\"5\", \"$\", \"z\", \"\\u00a7\", \"ehs\", \"es\", \"2\"],\n            \"T\": [\"7\", \"+\", \"-|-\", \"']['\", \"\\u2020\", \"\\u00ab|\\u00bb\", \"~|~\"],\n            \"U\": [\"(_)\", \"|_|\", \"v\", \"L|\", \"\\u0e1a\"],\n            \"V\": [\"\\\\/\", \"|/\", \"\\\\|\"],\n            \"W\": [\"\\\\/\\\\/\", \"vv\", \"\\\\N\", \"'//\", \"\\\\\\\\'\", \"\\\\^/\", \"\\\\/\\\\/\", \"(n)\", \"\\\\V/\", \"\\\\X/\", \"\\\\|/\", \"\\\\_|_/\",\n                  \"\\\\_:_/\", \"uu\", \"2u\", \"\\\\\\\\//\\\\\\\\//\", \"\\u0e1e\", \"\\u20a9\"],\n            \"X\": [\"&gt;&lt;\", \"}{\", \"ecks\", \"\\u00d7\", \"?\", \"}{\", \")(\", \"][\"],\n            \"Y\": [\"j\", \"`/\", \"\\\\|/\", \"\\u00a5\", \"\\\\//\"],\n            \"Z\": [\"2\", \"7_\", \"-/_\", \"%\", \"&gt;_\", \"s\", \"~/_\", \"-\\\\_\", \"-|_\"]\n        }\n\n    def randomly_replace_letter(self, letter, replacement_proba):\n        \"\"\"\n        Randomly replace a letter with its leet counterpart based on the provided probability.\n\n        :param letter: The letter to potentially replace.\n        :type letter: str\n        :param replacement_proba: The probability of replacing the letter with its leet counterpart.\n        :type replacement_proba: float\n        :return: The replaced letter if a random draw is less than or equal to the replacement_proba, otherwise the original letter.\n        :rtype: str\n        \"\"\"\n        if letter.upper() in self.leet_speak_mapping:\n            if self.random_generator.random() &lt; replacement_proba:\n                letter = self.random_generator.choice(self.leet_speak_mapping[letter.upper()])\n\n        return letter\n\n    def generate(self, X, y, replacement_proba: float = 0.1) -&gt; Tuple:\n        \"\"\"\n        Apply leet speak transformation to a list of words.\n\n        :param X: A list of words where leet speak transformation is applied.\n        :param y: The labels associated with the words, which remain unchanged.\n        :param replacement_proba: The probability of replacing a letter with its leet counterpart.\n                                  This probability applies to each letter in each word independently.\n        :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n        \"\"\"\n        transformed_X = []\n        for word in X:\n            transformed_word = ''.join(\n                self.randomly_replace_letter(letter, replacement_proba) for letter in word\n            )\n            transformed_X.append(transformed_word)\n\n        return transformed_X, y\n        assert 0 &lt;= replacement_proba &lt;= 1\n        Xt = [\n            ''.join([self.randomly_replace_letter(l, replacement_proba=replacement_proba) for l in word])\n            for word in X\n        ]\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.LeetSpeakGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the LeetSpeakGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>numpy.random.Generator, default=default_rng(seed=0)</code> <p>A random number generator used to introduce randomness in leetspeak transformation.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the LeetSpeakGenerator with a given random number generator.\n\n    :param random_generator: A random number generator used to introduce randomness in leetspeak transformation.\n    :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.leet_speak_mapping = {\n        \"A\": [\"4\", \"/\\\\\", \"@\", \"/-\\\\\", \"^\", \"(L\", \"\\u0414\"],\n        \"B\": [\"I3\", \"8\", \"13\", \"|3\", \"\\u00df\", \"!3\", \"(3\", \"/3\", \")3\", \"|-]\", \"j3\"],\n        \"C\": [\"[\", \"\\u00a2\", \"&lt;\", \"(\", \"\\u00a9\"],\n        \"D\": [\")\", \"|)\", \"(|\", \"[)\", \"I&gt;\", \"|&gt;\", \"?\", \"T)\", \"I7\", \"cl\", \"|}\", \"|]\"],\n        \"E\": [\"3\", \"&amp;\", \"\\u00a3\", \"\\u20ac\", \"[-\", \"|=-\"],\n        \"F\": [\"|=\", \"\\u0192\", \"|#\", \"ph\", \"/=\", \"v\"],\n        \"G\": [\"6\", \"&amp;\", \"(_+\", \"9\", \"C-\", \"gee\", \"(?,\", \"[,\", \"{,\", \"&lt;-\", \"(.\"],\n        \"H\": [\"#\", \"/-/\", \"\\\\-\\\\\", \"[-]\", \"]-[\", \")-(\", \"(-)\", \":-:\", \"|~|\", \"|-|\", \"]~[\", \"}{\", \"!-!\", \"1-1\",\n              \"\\\\-/\", \"I+I\", \"?\"],\n        \"I\": [\"1\", \"|\", \"][\", \"!\", \"eye\", \"3y3\"],\n        \"J\": [\",_|\", \"_|\", \"._|\", \"._]\", \"_]\", \",_]\", \"]\"],\n        \"K\": [\"&gt;|\", \"|&lt;\", \"1&lt;\", \"|c\", \"|(7&lt;\"],\n        \"L\": [\"1\", \"2\", \"\\u00a3\", \"7\", \"|_\", \"|\"],\n        \"M\": [\"/\\\\/\\\\\", \"/V\\\\\", \"[V]\", \"|\\\\/|\", \"^^\", \"&lt;\\\\/&gt;\", \"{V}\", \"(v)\", \"(V)\", \"|\\\\|\\\\\", \"]\\\\/[\", \"nn\", \"11\"],\n        \"N\": [\"^/\", \"|\\\\|\", \"/\\\\/\", \"[\\\\]\", \"&lt;\\\\&gt;\", \"{\\\\}\", \"/V\", \"^\", \"\\u0e17\", \"\\u0418\"],\n        \"O\": [\"0\", \"()\", \"oh\", \"[]\", \"p\", \"&lt;&gt;\", \"\\u00d8\"],\n        \"P\": [\"|*\", \"|o\", \"|\\u00ba\", \"?\", \"|^\", \"|&gt;\", \"|\\\"\", \"9\", \"[]D\", \"|\\u00b0\", \"|7\"],\n        \"Q\": [\"(_,)\", \"()_\", \"2\", \"0_\", \"&lt;|\", \"&amp;\", \"9\", \"\\u00b6\", \"\\u204b\", \"\\u2117\"],\n        \"R\": [\"I2\", \"9\", \"|`\", \"|~\", \"|?\", \"/2\", \"|^\", \"lz\", \"7\", \"2\", \"12\", \"\\u00ae\", \"[z\", \"\\u042f\", \".-\", \"|2\",\n              \"|-\", \"3\"],\n        \"S\": [\"5\", \"$\", \"z\", \"\\u00a7\", \"ehs\", \"es\", \"2\"],\n        \"T\": [\"7\", \"+\", \"-|-\", \"']['\", \"\\u2020\", \"\\u00ab|\\u00bb\", \"~|~\"],\n        \"U\": [\"(_)\", \"|_|\", \"v\", \"L|\", \"\\u0e1a\"],\n        \"V\": [\"\\\\/\", \"|/\", \"\\\\|\"],\n        \"W\": [\"\\\\/\\\\/\", \"vv\", \"\\\\N\", \"'//\", \"\\\\\\\\'\", \"\\\\^/\", \"\\\\/\\\\/\", \"(n)\", \"\\\\V/\", \"\\\\X/\", \"\\\\|/\", \"\\\\_|_/\",\n              \"\\\\_:_/\", \"uu\", \"2u\", \"\\\\\\\\//\\\\\\\\//\", \"\\u0e1e\", \"\\u20a9\"],\n        \"X\": [\"&gt;&lt;\", \"}{\", \"ecks\", \"\\u00d7\", \"?\", \"}{\", \")(\", \"][\"],\n        \"Y\": [\"j\", \"`/\", \"\\\\|/\", \"\\u00a5\", \"\\\\//\"],\n        \"Z\": [\"2\", \"7_\", \"-/_\", \"%\", \"&gt;_\", \"s\", \"~/_\", \"-\\\\_\", \"-|_\"]\n    }\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.LeetSpeakGenerator.generate","title":"<code>generate(X, y, replacement_proba=0.1)</code>","text":"<p>Apply leet speak transformation to a list of words.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A list of words where leet speak transformation is applied.</p> required <code>y</code> <p>The labels associated with the words, which remain unchanged.</p> required <code>replacement_proba</code> <code>float</code> <p>The probability of replacing a letter with its leet counterpart. This probability applies to each letter in each word independently.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed list of words and the original labels <code>y</code> (unchanged).</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def generate(self, X, y, replacement_proba: float = 0.1) -&gt; Tuple:\n    \"\"\"\n    Apply leet speak transformation to a list of words.\n\n    :param X: A list of words where leet speak transformation is applied.\n    :param y: The labels associated with the words, which remain unchanged.\n    :param replacement_proba: The probability of replacing a letter with its leet counterpart.\n                              This probability applies to each letter in each word independently.\n    :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n    \"\"\"\n    transformed_X = []\n    for word in X:\n        transformed_word = ''.join(\n            self.randomly_replace_letter(letter, replacement_proba) for letter in word\n        )\n        transformed_X.append(transformed_word)\n\n    return transformed_X, y\n    assert 0 &lt;= replacement_proba &lt;= 1\n    Xt = [\n        ''.join([self.randomly_replace_letter(l, replacement_proba=replacement_proba) for l in word])\n        for word in X\n    ]\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.LeetSpeakGenerator.randomly_replace_letter","title":"<code>randomly_replace_letter(letter, replacement_proba)</code>","text":"<p>Randomly replace a letter with its leet counterpart based on the provided probability.</p> <p>Parameters:</p> Name Type Description Default <code>letter</code> <code>str</code> <p>The letter to potentially replace.</p> required <code>replacement_proba</code> <code>float</code> <p>The probability of replacing the letter with its leet counterpart.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The replaced letter if a random draw is less than or equal to the replacement_proba, otherwise the original letter.</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def randomly_replace_letter(self, letter, replacement_proba):\n    \"\"\"\n    Randomly replace a letter with its leet counterpart based on the provided probability.\n\n    :param letter: The letter to potentially replace.\n    :type letter: str\n    :param replacement_proba: The probability of replacing the letter with its leet counterpart.\n    :type replacement_proba: float\n    :return: The replaced letter if a random draw is less than or equal to the replacement_proba, otherwise the original letter.\n    :rtype: str\n    \"\"\"\n    if letter.upper() in self.leet_speak_mapping:\n        if self.random_generator.random() &lt; replacement_proba:\n            letter = self.random_generator.choice(self.leet_speak_mapping[letter.upper()])\n\n    return letter\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapCaseGenerator","title":"<code>SwapCaseGenerator</code>","text":"<p>               Bases: <code>TyposGenerator</code></p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>class SwapCaseGenerator(TyposGenerator):\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the SwapCaseGenerator with a given random number generator.\n\n        :param random_generator: A random number generator used to introduce randomness in case swapping.\n        :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n        \"\"\"\n        super().__init__(random_generator)\n\n    def randomly_swapcase_letter(self, letter, swapcase_proba):\n        \"\"\"\n        Randomly swap the case of a letter based on the provided probability.\n\n        :param letter: The letter whose case may be swapped.\n        :type letter: str\n        :param swapcase_proba: The probability of swapping the case of the letter.\n        :type swapcase_proba: float\n        :return: The letter with swapped case if a random draw is less than or equal to the swapcase_proba, otherwise the original letter.\n        :rtype: str\n        \"\"\"\n        if self.random_generator.random() &lt; swapcase_proba:\n            letter = letter.swapcase()\n\n        return letter\n\n    def generate(self, X, y, swapcase_proba: float = 0.1) -&gt; Tuple:\n        \"\"\"\n        Apply random case swapping to each letter in a list of words.\n\n        :param X: A list of words where random case swapping is applied.\n        :param y: The labels associated with the words, which remain unchanged.\n        :param swapcase_proba: The probability of swapping the case of each letter.\n                               This probability applies to each letter in each word independently.\n        :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n        \"\"\"\n        assert 0 &lt;= swapcase_proba &lt;= 1\n        Xt = [\n            ''.join([self.randomly_swapcase_letter(l, swapcase_proba=swapcase_proba) for l in word])\n            for word in X\n        ]\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapCaseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the SwapCaseGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>numpy.random.Generator, default=default_rng(seed=0)</code> <p>A random number generator used to introduce randomness in case swapping.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the SwapCaseGenerator with a given random number generator.\n\n    :param random_generator: A random number generator used to introduce randomness in case swapping.\n    :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapCaseGenerator.generate","title":"<code>generate(X, y, swapcase_proba=0.1)</code>","text":"<p>Apply random case swapping to each letter in a list of words.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A list of words where random case swapping is applied.</p> required <code>y</code> <p>The labels associated with the words, which remain unchanged.</p> required <code>swapcase_proba</code> <code>float</code> <p>The probability of swapping the case of each letter. This probability applies to each letter in each word independently.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed list of words and the original labels <code>y</code> (unchanged).</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def generate(self, X, y, swapcase_proba: float = 0.1) -&gt; Tuple:\n    \"\"\"\n    Apply random case swapping to each letter in a list of words.\n\n    :param X: A list of words where random case swapping is applied.\n    :param y: The labels associated with the words, which remain unchanged.\n    :param swapcase_proba: The probability of swapping the case of each letter.\n                           This probability applies to each letter in each word independently.\n    :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n    \"\"\"\n    assert 0 &lt;= swapcase_proba &lt;= 1\n    Xt = [\n        ''.join([self.randomly_swapcase_letter(l, swapcase_proba=swapcase_proba) for l in word])\n        for word in X\n    ]\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapCaseGenerator.randomly_swapcase_letter","title":"<code>randomly_swapcase_letter(letter, swapcase_proba)</code>","text":"<p>Randomly swap the case of a letter based on the provided probability.</p> <p>Parameters:</p> Name Type Description Default <code>letter</code> <code>str</code> <p>The letter whose case may be swapped.</p> required <code>swapcase_proba</code> <code>float</code> <p>The probability of swapping the case of the letter.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The letter with swapped case if a random draw is less than or equal to the swapcase_proba, otherwise the original letter.</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def randomly_swapcase_letter(self, letter, swapcase_proba):\n    \"\"\"\n    Randomly swap the case of a letter based on the provided probability.\n\n    :param letter: The letter whose case may be swapped.\n    :type letter: str\n    :param swapcase_proba: The probability of swapping the case of the letter.\n    :type swapcase_proba: float\n    :return: The letter with swapped case if a random draw is less than or equal to the swapcase_proba, otherwise the original letter.\n    :rtype: str\n    \"\"\"\n    if self.random_generator.random() &lt; swapcase_proba:\n        letter = letter.swapcase()\n\n    return letter\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapLettersGenerator","title":"<code>SwapLettersGenerator</code>","text":"<p>               Bases: <code>TyposGenerator</code></p> <p>Swap adjacent letters in words randomly except for the first and the last letters. Example: 'kilogram' --&gt; 'kilogarm'</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>class SwapLettersGenerator(TyposGenerator):\n    \"\"\"\n    Swap adjacent letters in words randomly except for the first and the last letters.\n    Example: 'kilogram' --&gt; 'kilogarm'\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the SwapLettersGenerator with a given random number generator.\n\n        :param random_generator: A random number generator used to introduce randomness in letter swapping.\n        :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n        \"\"\"\n        super().__init__(random_generator)\n\n    def generate(self, X, y, swap_proba:float=0.1) -&gt; Tuple:\n        \"\"\"\n        For each word with a length greater than 3, apply a single swap with probability `swap_proba`.\n        The position of the swap is chosen randomly among possible adjacent pairs of letters,\n        excluding the first and last letters of the word.\n        :param X: A list of words where typos are introduced.\n        :param y: Not used in this method.\n        :param swap_proba: Probability that a word with more than 3 characters will have one adjacent pair of letters swapped.\n                           This probability applies to each eligible word independently.\n        :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n        \"\"\"\n        for i in range(len(X)):\n            if len(X[i]) &gt; 3 and self.random_generator.random() &lt;= swap_proba:\n                # get the ith word in the list and make it a list of letters\n                word = list(X[i])\n                # randomly chose letters to switch\n                idx = self.random_generator.integers(1, len(word) - 2)\n                word[idx], word[idx + 1] = word[idx + 1], word[idx]\n                # save the word with switched letters as string\n                X[i] = ''.join(word)\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapLettersGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the SwapLettersGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>numpy.random.Generator, default=default_rng(seed=0)</code> <p>A random number generator used to introduce randomness in letter swapping.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the SwapLettersGenerator with a given random number generator.\n\n    :param random_generator: A random number generator used to introduce randomness in letter swapping.\n    :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n    \"\"\"\n    super().__init__(random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.SwapLettersGenerator.generate","title":"<code>generate(X, y, swap_proba=0.1)</code>","text":"<p>For each word with a length greater than 3, apply a single swap with probability <code>swap_proba</code>. The position of the swap is chosen randomly among possible adjacent pairs of letters, excluding the first and last letters of the word.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A list of words where typos are introduced.</p> required <code>y</code> <p>Not used in this method.</p> required <code>swap_proba</code> <code>float</code> <p>Probability that a word with more than 3 characters will have one adjacent pair of letters swapped. This probability applies to each eligible word independently.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed list of words and the original labels <code>y</code> (unchanged).</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def generate(self, X, y, swap_proba:float=0.1) -&gt; Tuple:\n    \"\"\"\n    For each word with a length greater than 3, apply a single swap with probability `swap_proba`.\n    The position of the swap is chosen randomly among possible adjacent pairs of letters,\n    excluding the first and last letters of the word.\n    :param X: A list of words where typos are introduced.\n    :param y: Not used in this method.\n    :param swap_proba: Probability that a word with more than 3 characters will have one adjacent pair of letters swapped.\n                       This probability applies to each eligible word independently.\n    :return: A tuple containing the transformed list of words and the original labels `y` (unchanged).\n    \"\"\"\n    for i in range(len(X)):\n        if len(X[i]) &gt; 3 and self.random_generator.random() &lt;= swap_proba:\n            # get the ith word in the list and make it a list of letters\n            word = list(X[i])\n            # randomly chose letters to switch\n            idx = self.random_generator.integers(1, len(word) - 2)\n            word[idx], word[idx + 1] = word[idx + 1], word[idx]\n            # save the word with switched letters as string\n            X[i] = ''.join(word)\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.TyposGenerator","title":"<code>TyposGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers creating typos in a list of words</p> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>class TyposGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers creating typos in a list of words\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the TyposGenerator with a given random number generator.\n\n        :param random_generator: A random number generator used to introduce randomness in typo generation.\n        :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/text/typos/#badgers.generators.text.typos.TyposGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the TyposGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>numpy.random.Generator, default=default_rng(seed=0)</code> <p>A random number generator used to introduce randomness in typo generation.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/text/typos.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the TyposGenerator with a given random number generator.\n\n    :param random_generator: A random number generator used to introduce randomness in typo generation.\n    :type random_generator: numpy.random.Generator, default=default_rng(seed=0)\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/time_series/","title":"Index","text":"<p>Module containing all the transformers that accept time series data as input</p>"},{"location":"reference/badgers/generators/time_series/changepoints/","title":"changepoints","text":""},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.ChangePointsGenerator","title":"<code>ChangePointsGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for generators that generate changepoints in time-series data</p> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>class ChangePointsGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for generators that generate changepoints in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0), ):\n        \"\"\"\n        Initialize the ChangePointsGenerator with a given random number generator.\n\n        :param random_generator: A random number generator instance (default is numpy's default_rng with seed 0).\n        \"\"\"\n        self.random_generator = random_generator\n        self.changepoints = None\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n        Abstract method that generates changepoints in the given time-series data.\n\n        This method must be overridden by subclasses.\n\n        :param X: Input features of the time-series data.\n        :param y: Target values of the time-series data.\n        :param params: Additional parameters required for changepoint generation.\n        :return: A tuple containing the modified time-series data and the generated changepoints.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.ChangePointsGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the ChangePointsGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is numpy's default_rng with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0), ):\n    \"\"\"\n    Initialize the ChangePointsGenerator with a given random number generator.\n\n    :param random_generator: A random number generator instance (default is numpy's default_rng with seed 0).\n    \"\"\"\n    self.random_generator = random_generator\n    self.changepoints = None\n</code></pre>"},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.ChangePointsGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method that generates changepoints in the given time-series data.</p> <p>This method must be overridden by subclasses.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features of the time-series data.</p> required <code>y</code> <p>Target values of the time-series data.</p> required <code>params</code> <p>Additional parameters required for changepoint generation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified time-series data and the generated changepoints.</p> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n    Abstract method that generates changepoints in the given time-series data.\n\n    This method must be overridden by subclasses.\n\n    :param X: Input features of the time-series data.\n    :param y: Target values of the time-series data.\n    :param params: Additional parameters required for changepoint generation.\n    :return: A tuple containing the modified time-series data and the generated changepoints.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.RandomChangeInMeanGenerator","title":"<code>RandomChangeInMeanGenerator</code>","text":"<p>               Bases: <code>ChangePointsGenerator</code></p> <p>Generate randomly change in mean changepoints</p> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>class RandomChangeInMeanGenerator(ChangePointsGenerator):\n    \"\"\"\n    Generate randomly change in mean changepoints\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomChangeInMeanGenerator with a given random number generator.\n\n        :param random_generator: A random number generator instance (default is numpy's default_rng with seed 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_changepoints: int = 10, min_change: float = -5,\n                 max_change: float = 5) -&gt; Tuple:\n        \"\"\"\n        Generate random changepoints in the time-series data where the mean changes at each changepoint.\n\n        :param X: Input features of the time-series data.\n        :param y: Target values of the time-series data.\n        :param n_changepoints: Number of changepoints to generate.\n        :param min_change: Minimum value of the change in mean.\n        :param max_change: Maximum value of the change in mean.\n        :return: A tuple containing the modified time-series data and the generated changepoints.\n        \"\"\"\n        # Generate change points\n        self.changepoints = list(\n            zip(\n                self.random_generator.integers(int(0.05 * len(X)), int(0.95 * len(X)), size=n_changepoints),\n                self.random_generator.uniform(min_change, max_change, size=n_changepoints)\n            )\n        )\n\n        for idx, change in self.changepoints:\n            X.iloc[idx:] += change\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.RandomChangeInMeanGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomChangeInMeanGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is numpy's default_rng with seed 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomChangeInMeanGenerator with a given random number generator.\n\n    :param random_generator: A random number generator instance (default is numpy's default_rng with seed 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/changepoints/#badgers.generators.time_series.changepoints.RandomChangeInMeanGenerator.generate","title":"<code>generate(X, y, n_changepoints=10, min_change=-5, max_change=5)</code>","text":"<p>Generate random changepoints in the time-series data where the mean changes at each changepoint.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features of the time-series data.</p> required <code>y</code> <p>Target values of the time-series data.</p> required <code>n_changepoints</code> <code>int</code> <p>Number of changepoints to generate.</p> <code>10</code> <code>min_change</code> <code>float</code> <p>Minimum value of the change in mean.</p> <code>-5</code> <code>max_change</code> <code>float</code> <p>Maximum value of the change in mean.</p> <code>5</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified time-series data and the generated changepoints.</p> Source code in <code>badgers/generators/time_series/changepoints.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_changepoints: int = 10, min_change: float = -5,\n             max_change: float = 5) -&gt; Tuple:\n    \"\"\"\n    Generate random changepoints in the time-series data where the mean changes at each changepoint.\n\n    :param X: Input features of the time-series data.\n    :param y: Target values of the time-series data.\n    :param n_changepoints: Number of changepoints to generate.\n    :param min_change: Minimum value of the change in mean.\n    :param max_change: Maximum value of the change in mean.\n    :return: A tuple containing the modified time-series data and the generated changepoints.\n    \"\"\"\n    # Generate change points\n    self.changepoints = list(\n        zip(\n            self.random_generator.integers(int(0.05 * len(X)), int(0.95 * len(X)), size=n_changepoints),\n            self.random_generator.uniform(min_change, max_change, size=n_changepoints)\n        )\n    )\n\n    for idx, change in self.changepoints:\n        X.iloc[idx:] += change\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/missingness/","title":"missingness","text":""},{"location":"reference/badgers/generators/time_series/missingness/#badgers.generators.time_series.missingness.MissingAtRandomGenerator","title":"<code>MissingAtRandomGenerator</code>","text":"<p>               Bases: <code>MissingValuesGenerator</code></p> <p>Randomly set data points to nan (missing)</p> Source code in <code>badgers/generators/time_series/missingness.py</code> <pre><code>class MissingAtRandomGenerator(MissingValuesGenerator):\n    \"\"\"\n    Randomly set data points to nan (missing)\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the MissingAtRandomGenerator with a given random number generator.\n\n        :param random_generator: An instance of a random number generator from NumPy,\n                                 used to introduce randomness in the generation process.\n                                 Defaults to a default_rng seeded with 0.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_missing: int = 10) -&gt; Tuple:\n        \"\"\"\n        Randomly sets a specified number of values in the input array X to np.nan, representing missing values.\n\n        :param X: A numpy array of shape (n_samples, n_features) containing the input time-series data.\n        :param y: A numpy array of shape (n_samples,) containing the target values. This parameter is not modified by this method.\n        :param n_missing: The number of missing values to randomly introduce into the data. Defaults to 10.\n        :return: A tuple (X_out, y_out) where X_out is the modified array with missing values and y_out is the original target array.\n        \"\"\"\n        # generate missing values indices and values\n        rows = self.random_generator.choice(X.shape[0], size=n_missing, replace=False, p=None)\n        cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_missing)\n\n        self.missing_indices_ = list(zip(rows, cols))\n\n        for r, c in self.missing_indices_:\n            X.iloc[r, c] = np.nan\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/missingness/#badgers.generators.time_series.missingness.MissingAtRandomGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the MissingAtRandomGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from NumPy, used to introduce randomness in the generation process. Defaults to a default_rng seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/missingness.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the MissingAtRandomGenerator with a given random number generator.\n\n    :param random_generator: An instance of a random number generator from NumPy,\n                             used to introduce randomness in the generation process.\n                             Defaults to a default_rng seeded with 0.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/missingness/#badgers.generators.time_series.missingness.MissingAtRandomGenerator.generate","title":"<code>generate(X, y, n_missing=10)</code>","text":"<p>Randomly sets a specified number of values in the input array X to np.nan, representing missing values.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A numpy array of shape (n_samples, n_features) containing the input time-series data.</p> required <code>y</code> <p>A numpy array of shape (n_samples,) containing the target values. This parameter is not modified by this method.</p> required <code>n_missing</code> <code>int</code> <p>The number of missing values to randomly introduce into the data. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (X_out, y_out) where X_out is the modified array with missing values and y_out is the original target array.</p> Source code in <code>badgers/generators/time_series/missingness.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_missing: int = 10) -&gt; Tuple:\n    \"\"\"\n    Randomly sets a specified number of values in the input array X to np.nan, representing missing values.\n\n    :param X: A numpy array of shape (n_samples, n_features) containing the input time-series data.\n    :param y: A numpy array of shape (n_samples,) containing the target values. This parameter is not modified by this method.\n    :param n_missing: The number of missing values to randomly introduce into the data. Defaults to 10.\n    :return: A tuple (X_out, y_out) where X_out is the modified array with missing values and y_out is the original target array.\n    \"\"\"\n    # generate missing values indices and values\n    rows = self.random_generator.choice(X.shape[0], size=n_missing, replace=False, p=None)\n    cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_missing)\n\n    self.missing_indices_ = list(zip(rows, cols))\n\n    for r, c in self.missing_indices_:\n        X.iloc[r, c] = np.nan\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/missingness/#badgers.generators.time_series.missingness.MissingValuesGenerator","title":"<code>MissingValuesGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate point outliers in time-series data</p> Source code in <code>badgers/generators/time_series/missingness.py</code> <pre><code>class MissingValuesGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate point outliers in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the MissingValuesGenerator with a given random number generator.\n\n        :param random_generator: An instance of a random number generator from NumPy,\n                                 used to introduce randomness in the generation process.\n                                 Defaults to a default_rng seeded with 0.\n        \"\"\"\n        self.random_generator = random_generator\n        self.missing_indices_ = []\n</code></pre>"},{"location":"reference/badgers/generators/time_series/missingness/#badgers.generators.time_series.missingness.MissingValuesGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the MissingValuesGenerator with a given random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from NumPy, used to introduce randomness in the generation process. Defaults to a default_rng seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/missingness.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the MissingValuesGenerator with a given random number generator.\n\n    :param random_generator: An instance of a random number generator from NumPy,\n                             used to introduce randomness in the generation process.\n                             Defaults to a default_rng seeded with 0.\n    \"\"\"\n    self.random_generator = random_generator\n    self.missing_indices_ = []\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/","title":"noise","text":""},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.GlobalGaussianNoiseGenerator","title":"<code>GlobalGaussianNoiseGenerator</code>","text":"<p>               Bases: <code>NoiseGenerator</code></p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>class GlobalGaussianNoiseGenerator(NoiseGenerator):\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the GlobalGaussianNoiseGenerator with a specified random generator.\n        :param random_generator: An instance of a random number generator from `numpy.random`.\n                                 Default is `default_rng(seed=0)`.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, noise_std: float = 0.1):\n        \"\"\"\n        Adds Gaussian white noise to the entire dataset.\n        The data is first standardized (each feature has a mean = 0 and variance = 1).\n        The noise is generated from a normal distribution with standard deviation = `noise_std`.\n        The noise is then added to the standardized data, and the result is inverse-standardized to restore the original scale.\n\n        :param X: Input features DataFrame.\n        :param y: Target Series.\n        :param noise_std: The standard deviation of the noise to be added.\n        :return: A tuple containing the modified features DataFrame and the original target Series.\n        \"\"\"\n        scaler = StandardScaler()\n        # fit, transform\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n        # add noise\n        Xt = Xt + self.random_generator.normal(loc=0, scale=noise_std, size=Xt.shape)\n        # inverse standardization\n        return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.GlobalGaussianNoiseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the GlobalGaussianNoiseGenerator with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>. Default is <code>default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the GlobalGaussianNoiseGenerator with a specified random generator.\n    :param random_generator: An instance of a random number generator from `numpy.random`.\n                             Default is `default_rng(seed=0)`.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.GlobalGaussianNoiseGenerator.generate","title":"<code>generate(X, y, noise_std=0.1)</code>","text":"<p>Adds Gaussian white noise to the entire dataset. The data is first standardized (each feature has a mean = 0 and variance = 1). The noise is generated from a normal distribution with standard deviation = <code>noise_std</code>. The noise is then added to the standardized data, and the result is inverse-standardized to restore the original scale.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features DataFrame.</p> required <code>y</code> <p>Target Series.</p> required <code>noise_std</code> <code>float</code> <p>The standard deviation of the noise to be added.</p> <code>0.1</code> <p>Returns:</p> Type Description <p>A tuple containing the modified features DataFrame and the original target Series.</p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, noise_std: float = 0.1):\n    \"\"\"\n    Adds Gaussian white noise to the entire dataset.\n    The data is first standardized (each feature has a mean = 0 and variance = 1).\n    The noise is generated from a normal distribution with standard deviation = `noise_std`.\n    The noise is then added to the standardized data, and the result is inverse-standardized to restore the original scale.\n\n    :param X: Input features DataFrame.\n    :param y: Target Series.\n    :param noise_std: The standard deviation of the noise to be added.\n    :return: A tuple containing the modified features DataFrame and the original target Series.\n    \"\"\"\n    scaler = StandardScaler()\n    # fit, transform\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n    # add noise\n    Xt = Xt + self.random_generator.normal(loc=0, scale=noise_std, size=Xt.shape)\n    # inverse standardization\n    return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.LocalGaussianNoiseGenerator","title":"<code>LocalGaussianNoiseGenerator</code>","text":"<p>               Bases: <code>NoiseGenerator</code></p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>class LocalGaussianNoiseGenerator(NoiseGenerator):\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the LocalGaussianNoiseGenerator with a specified random generator.\n\n        :param random_generator: An instance of a random number generator from `numpy.random`.\n                                 Default is `default_rng(seed=0)`.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5, max_width_patterns: int = 10,\n                 noise_std: float = 0.1) -&gt; Tuple[pd.DataFrame, pd.Series]:\n        \"\"\"\n        Adds Gaussian noise to randomly selected local patterns within the input data.\n\n        :param X: Input features DataFrame.\n        :param y: Target Series.\n        :param n_patterns: Number of local patterns to add noise to.\n        :param min_width_pattern: Minimum width of each pattern.\n        :param max_width_patterns: Maximum width of each pattern.\n        :param noise_std: Standard deviation of the Gaussian noise.\n        :return: A tuple containing the modified features DataFrame and the original target Series.\n        \"\"\"\n        # Generate indices for random patterns\n        self.patterns_indices_ = generate_random_patterns_indices(\n            random_generator=self.random_generator,\n            n_patterns=n_patterns,\n            signal_size=len(X),\n            min_width_pattern=min_width_pattern,\n            max_width_patterns=max_width_patterns)\n\n        scaler = StandardScaler()\n        # Fit and transform the data\n        scaler.fit(X)\n        Xt = scaler.transform(X)\n\n        # Add Gaussian noise to each pattern\n        for (start, end) in self.patterns_indices_:\n            Xt[start:end, :] += self.random_generator.normal(loc=0, scale=noise_std, size=(end-start, Xt.shape[1]))\n\n        # Inverse standardize the data\n        return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.LocalGaussianNoiseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the LocalGaussianNoiseGenerator with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>. Default is <code>default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the LocalGaussianNoiseGenerator with a specified random generator.\n\n    :param random_generator: An instance of a random number generator from `numpy.random`.\n                             Default is `default_rng(seed=0)`.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.LocalGaussianNoiseGenerator.generate","title":"<code>generate(X, y, n_patterns=10, min_width_pattern=5, max_width_patterns=10, noise_std=0.1)</code>","text":"<p>Adds Gaussian noise to randomly selected local patterns within the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features DataFrame.</p> required <code>y</code> <p>Target Series.</p> required <code>n_patterns</code> <code>int</code> <p>Number of local patterns to add noise to.</p> <code>10</code> <code>min_width_pattern</code> <code>int</code> <p>Minimum width of each pattern.</p> <code>5</code> <code>max_width_patterns</code> <code>int</code> <p>Maximum width of each pattern.</p> <code>10</code> <code>noise_std</code> <code>float</code> <p>Standard deviation of the Gaussian noise.</p> <code>0.1</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Series]</code> <p>A tuple containing the modified features DataFrame and the original target Series.</p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5, max_width_patterns: int = 10,\n             noise_std: float = 0.1) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Adds Gaussian noise to randomly selected local patterns within the input data.\n\n    :param X: Input features DataFrame.\n    :param y: Target Series.\n    :param n_patterns: Number of local patterns to add noise to.\n    :param min_width_pattern: Minimum width of each pattern.\n    :param max_width_patterns: Maximum width of each pattern.\n    :param noise_std: Standard deviation of the Gaussian noise.\n    :return: A tuple containing the modified features DataFrame and the original target Series.\n    \"\"\"\n    # Generate indices for random patterns\n    self.patterns_indices_ = generate_random_patterns_indices(\n        random_generator=self.random_generator,\n        n_patterns=n_patterns,\n        signal_size=len(X),\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns)\n\n    scaler = StandardScaler()\n    # Fit and transform the data\n    scaler.fit(X)\n    Xt = scaler.transform(X)\n\n    # Add Gaussian noise to each pattern\n    for (start, end) in self.patterns_indices_:\n        Xt[start:end, :] += self.random_generator.normal(loc=0, scale=noise_std, size=(end-start, Xt.shape[1]))\n\n    # Inverse standardize the data\n    return pd.DataFrame(data=scaler.inverse_transform(Xt), columns=X.columns, index=X.index), y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.NoiseGenerator","title":"<code>NoiseGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that add noise to tabular data</p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>class NoiseGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that add noise to tabular data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the NoiseGenerator with a specified random generator.\n        :param random_generator: An instance of a random number generator from `numpy.random`.\n                                 Default is `default_rng(seed=0)`.\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple[pd.DataFrame, pd.Series]:\n        \"\"\"\n        Abstract method to be implemented by subclasses. Adds noise to the input data.\n\n        :param X: Input features DataFrame.\n        :param y: Target Series.\n        :param params: Additional parameters that might be required for noise generation.\n        :return: A tuple containing the modified features DataFrame and the target Series.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.NoiseGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the NoiseGenerator with a specified random generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>. Default is <code>default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the NoiseGenerator with a specified random generator.\n    :param random_generator: An instance of a random number generator from `numpy.random`.\n                             Default is `default_rng(seed=0)`.\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/time_series/noise/#badgers.generators.time_series.noise.NoiseGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to be implemented by subclasses. Adds noise to the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features DataFrame.</p> required <code>y</code> <p>Target Series.</p> required <code>params</code> <p>Additional parameters that might be required for noise generation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Series]</code> <p>A tuple containing the modified features DataFrame and the target Series.</p> Source code in <code>badgers/generators/time_series/noise.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Abstract method to be implemented by subclasses. Adds noise to the input data.\n\n    :param X: Input features DataFrame.\n    :param y: Target Series.\n    :param params: Additional parameters that might be required for noise generation.\n    :return: A tuple containing the modified features DataFrame and the target Series.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/","title":"outliers","text":""},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.LocalZScoreGenerator","title":"<code>LocalZScoreGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly generates locally extreme values. Given a time interval (a window) of size l, an outlier is generated by setting the value a time t</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>class LocalZScoreGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly generates locally extreme values.\n    Given a time interval (a window) of size l, an outlier is generated by setting the value a time t\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the LocalZScoreGenerator with a specified random number generator.\n\n        :param random_generator: An instance of a random number generator from NumPy's random module.\n                                 Default is a default_rng seeded with 0.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_outliers: int = 10,\n                 local_window_size: int = 10):\n        \"\"\"\n        Generates outliers based on local Z-scores.\n\n        For each outlier, a local window of size `local_window_size` is selected, and the local mean and standard deviation are computed.\n        An outlier is then generated by setting the value at a randomly chosen index within this window to a value outside the range\n        [local_mean - 3 * local_std, local_mean + 3 * local_std]. The sign of the outlier value is the same as the sign of the original value.\n\n        :param X: The input features (time-series data), expected to be a 2D numpy array.\n        :param y: The target values, optional and can be None.\n        :param n_outliers: The number of outliers to generate. Defaults to 10.\n        :param local_window_size: The width (number of data points) of the local window used to compute the local Z-score. Defaults to 10.\n        :return: A tuple containing the modified data with outliers and the indices of the generated outliers.\n        \"\"\"\n        # generate extreme values indices and values\n        delta = int(local_window_size / 2)\n\n        rows = self.random_generator.choice(\n            np.arange(delta, X.shape[0] - delta, dtype=int), size=n_outliers, replace=False, p=None)\n        cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_outliers)\n\n        self.outliers_indices_ = list(zip(rows, cols))\n\n        for r, c in self.outliers_indices_:\n            local_window = X.iloc[r - delta:r + delta, c]\n            local_mean = local_window.mean(axis=0)\n            local_std = local_window.std(axis=0)\n            value = local_mean + random_sign(self.random_generator) * (\n                3. * local_std + self.random_generator.exponential())\n            # updating with new outliers\n            X.iloc[r, c] = value\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.LocalZScoreGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the LocalZScoreGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from NumPy's random module. Default is a default_rng seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the LocalZScoreGenerator with a specified random number generator.\n\n    :param random_generator: An instance of a random number generator from NumPy's random module.\n                             Default is a default_rng seeded with 0.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.LocalZScoreGenerator.generate","title":"<code>generate(X, y, n_outliers=10, local_window_size=10)</code>","text":"<p>Generates outliers based on local Z-scores.</p> <p>For each outlier, a local window of size <code>local_window_size</code> is selected, and the local mean and standard deviation are computed. An outlier is then generated by setting the value at a randomly chosen index within this window to a value outside the range [local_mean - 3 * local_std, local_mean + 3 * local_std]. The sign of the outlier value is the same as the sign of the original value.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input features (time-series data), expected to be a 2D numpy array.</p> required <code>y</code> <p>The target values, optional and can be None.</p> required <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate. Defaults to 10.</p> <code>10</code> <code>local_window_size</code> <code>int</code> <p>The width (number of data points) of the local window used to compute the local Z-score. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <p>A tuple containing the modified data with outliers and the indices of the generated outliers.</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_outliers: int = 10,\n             local_window_size: int = 10):\n    \"\"\"\n    Generates outliers based on local Z-scores.\n\n    For each outlier, a local window of size `local_window_size` is selected, and the local mean and standard deviation are computed.\n    An outlier is then generated by setting the value at a randomly chosen index within this window to a value outside the range\n    [local_mean - 3 * local_std, local_mean + 3 * local_std]. The sign of the outlier value is the same as the sign of the original value.\n\n    :param X: The input features (time-series data), expected to be a 2D numpy array.\n    :param y: The target values, optional and can be None.\n    :param n_outliers: The number of outliers to generate. Defaults to 10.\n    :param local_window_size: The width (number of data points) of the local window used to compute the local Z-score. Defaults to 10.\n    :return: A tuple containing the modified data with outliers and the indices of the generated outliers.\n    \"\"\"\n    # generate extreme values indices and values\n    delta = int(local_window_size / 2)\n\n    rows = self.random_generator.choice(\n        np.arange(delta, X.shape[0] - delta, dtype=int), size=n_outliers, replace=False, p=None)\n    cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_outliers)\n\n    self.outliers_indices_ = list(zip(rows, cols))\n\n    for r, c in self.outliers_indices_:\n        local_window = X.iloc[r - delta:r + delta, c]\n        local_mean = local_window.mean(axis=0)\n        local_std = local_window.std(axis=0)\n        value = local_mean + random_sign(self.random_generator) * (\n            3. * local_std + self.random_generator.exponential())\n        # updating with new outliers\n        X.iloc[r, c] = value\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.OutliersGenerator","title":"<code>OutliersGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate point outliers in time-series data</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>class OutliersGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate point outliers in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the OutliersGenerator with a specified random number generator.\n\n        :param random_generator: An instance of a random number generator from NumPy's random module.\n                                 Default is a default_rng seeded with 0.\n        \"\"\"\n        self.random_generator = random_generator\n        self.outliers_indices_ = []\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n        Generate point outliers in the given time-series data.\n\n        This method should be overridden by subclasses to implement specific outlier generation strategies.\n\n        :param X: Input features (time-series data).\n        :param y: Target values (optional, may be None).\n        :param params: Additional parameters that may be required for outlier generation.\n        :return: A tuple containing the modified data with outliers and any additional information.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.OutliersGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the OutliersGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from NumPy's random module. Default is a default_rng seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the OutliersGenerator with a specified random number generator.\n\n    :param random_generator: An instance of a random number generator from NumPy's random module.\n                             Default is a default_rng seeded with 0.\n    \"\"\"\n    self.random_generator = random_generator\n    self.outliers_indices_ = []\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.OutliersGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Generate point outliers in the given time-series data.</p> <p>This method should be overridden by subclasses to implement specific outlier generation strategies.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (time-series data).</p> required <code>y</code> <p>Target values (optional, may be None).</p> required <code>params</code> <p>Additional parameters that may be required for outlier generation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified data with outliers and any additional information.</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n    Generate point outliers in the given time-series data.\n\n    This method should be overridden by subclasses to implement specific outlier generation strategies.\n\n    :param X: Input features (time-series data).\n    :param y: Target values (optional, may be None).\n    :param params: Additional parameters that may be required for outlier generation.\n    :return: A tuple containing the modified data with outliers and any additional information.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.RandomZerosGenerator","title":"<code>RandomZerosGenerator</code>","text":"<p>               Bases: <code>OutliersGenerator</code></p> <p>Randomly set data points to 0</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>class RandomZerosGenerator(OutliersGenerator):\n    \"\"\"\n    Randomly set data points to 0\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomZerosGenerator with a specified random number generator.\n\n        :param random_generator: An instance of a random number generator from NumPy's random module.\n                                 Default is a default_rng seeded with 0.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_outliers: int = 10) -&gt; Tuple:\n        \"\"\"\n        Randomly set a specified number of values in the input data to zero.\n\n        :param X: The input features (time-series data), expected to be a 2D numpy array.\n        :param y: The target values, optional and can be None.\n        :param n_outliers: The number of outliers to generate by setting to zero.\n                           Defaults to 10.\n        :return: A tuple containing the modified data with outliers and the indices of the generated outliers.\n        \"\"\"\n        # generate extreme values indices and values\n        rows = self.random_generator.choice(X.shape[0], size=n_outliers, replace=False, p=None)\n        cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_outliers)\n\n        self.outliers_indices_ = list(zip(rows, cols))\n\n        for r, c in self.outliers_indices_:\n            X.iloc[r, c] = 0\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.RandomZerosGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomZerosGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from NumPy's random module. Default is a default_rng seeded with 0.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomZerosGenerator with a specified random number generator.\n\n    :param random_generator: An instance of a random number generator from NumPy's random module.\n                             Default is a default_rng seeded with 0.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/outliers/#badgers.generators.time_series.outliers.RandomZerosGenerator.generate","title":"<code>generate(X, y, n_outliers=10)</code>","text":"<p>Randomly set a specified number of values in the input data to zero.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input features (time-series data), expected to be a 2D numpy array.</p> required <code>y</code> <p>The target values, optional and can be None.</p> required <code>n_outliers</code> <code>int</code> <p>The number of outliers to generate by setting to zero. Defaults to 10.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified data with outliers and the indices of the generated outliers.</p> Source code in <code>badgers/generators/time_series/outliers.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_outliers: int = 10) -&gt; Tuple:\n    \"\"\"\n    Randomly set a specified number of values in the input data to zero.\n\n    :param X: The input features (time-series data), expected to be a 2D numpy array.\n    :param y: The target values, optional and can be None.\n    :param n_outliers: The number of outliers to generate by setting to zero.\n                       Defaults to 10.\n    :return: A tuple containing the modified data with outliers and the indices of the generated outliers.\n    \"\"\"\n    # generate extreme values indices and values\n    rows = self.random_generator.choice(X.shape[0], size=n_outliers, replace=False, p=None)\n    cols = self.random_generator.integers(low=0, high=X.shape[1], size=n_outliers)\n\n    self.outliers_indices_ = list(zip(rows, cols))\n\n    for r, c in self.outliers_indices_:\n        X.iloc[r, c] = 0\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/","title":"patterns","text":""},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.Pattern","title":"<code>Pattern</code>","text":"Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>class Pattern:\n\n    def __init__(self, values: np.array):\n        \"\"\"\n        Initialize a Pattern object.\n\n        :param values: A 1D or 2D numpy array where rows represent the time axis and columns represent features.\n                       If only a single feature is provided (1D array), it is automatically reshaped into a 2D array with shape (-1, 1).\n        \"\"\"\n        if values.ndim == 1:\n            values = values.reshape(-1, 1)\n        if values.ndim &gt; 2:\n            raise ValueError(\n                \"Values has more thant 2 dimensions where it is expected to have either 1 or 2!\"\n            )\n        self.values = values\n        self.interpolation_function = CubicSpline(np.linspace(0, 1, values.shape[0]), values, bc_type='natural')\n\n    def resample(self, nb_point: int) -&gt; np.array:\n        return self.interpolation_function(np.linspace(0, 1, nb_point))\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.Pattern.__init__","title":"<code>__init__(values)</code>","text":"<p>Initialize a Pattern object.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array</code> <p>A 1D or 2D numpy array where rows represent the time axis and columns represent features. If only a single feature is provided (1D array), it is automatically reshaped into a 2D array with shape (-1, 1).</p> required Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def __init__(self, values: np.array):\n    \"\"\"\n    Initialize a Pattern object.\n\n    :param values: A 1D or 2D numpy array where rows represent the time axis and columns represent features.\n                   If only a single feature is provided (1D array), it is automatically reshaped into a 2D array with shape (-1, 1).\n    \"\"\"\n    if values.ndim == 1:\n        values = values.reshape(-1, 1)\n    if values.ndim &gt; 2:\n        raise ValueError(\n            \"Values has more thant 2 dimensions where it is expected to have either 1 or 2!\"\n        )\n    self.values = values\n    self.interpolation_function = CubicSpline(np.linspace(0, 1, values.shape[0]), values, bc_type='natural')\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.PatternsGenerator","title":"<code>PatternsGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate patterns in time-series data</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>class PatternsGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate patterns in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the PatternsGenerator with a random number generator.\n\n        :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n        \"\"\"\n        self.random_generator = random_generator\n        self.patterns_indices_ = []\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n        Abstract method to inject patterns into the time-series data.\n        This method should be overridden by subclasses to implement specific pattern generation logic.\n\n        :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n        :param y: Target values as a 1D numpy array or pandas Series.\n        :param params: Additional parameters that might be required for pattern generation.\n        :return: A tuple containing the modified time-series data and target values.\n        \"\"\"\n        pass\n\n    def _inject_pattern(self, X: pd.DataFrame, p: Pattern, start_index: int, end_index: int,\n                        scaling_factor: Union[float, str, None] = 'auto'):\n        \"\"\"\n        Utility function to inject a predefined pattern `p` into a signal `X`.\n\n        :param X: The signal (time-series data) to inject the pattern into, as a pandas DataFrame.\n        :param p: The pattern to be injected, represented as a `Pattern` object.\n        :param start_index: The starting index in `X` where the pattern injection begins.\n        :param end_index: The ending index in `X` where the pattern injection ends.\n        :param scaling_factor: The factor by which to scale the pattern before injection. Can be a float, 'auto' to scale based on the signal's range, or None to apply no scaling.\n        :return: The transformed signal (time-series data) as a pandas DataFrame, where the pattern has been injected.\n        \"\"\"\n\n        # start and end values\n        v_start = X.iloc[start_index, :].values\n        v_end = X.iloc[start_index, :].values\n\n        # number of points needed for resampling\n        nb_points = end_index - start_index + 1\n\n        if scaling_factor == 'auto':\n            # compute a scaling factor to make the pattern looks realistic\n            scaling_factor = (np.max(X[start_index:end_index + 1]) - np.min(X[start_index:end_index + 1])) / (\n                np.max(p.values) - np.min(p.values)) * self.random_generator.normal(1, 0.2)\n        elif scaling_factor is None:\n            # default to 1\n            scaling_factor = 1.0\n\n        transformed_pattern = p.resample(nb_point=nb_points)\n        transformed_pattern = scale(transformed_pattern, scaling_factor=scaling_factor)\n        transformed_pattern = add_linear_trend(start_value=v_start, end_value=v_end, values=transformed_pattern)\n\n        X.iloc[start_index:end_index + 1, :] = transformed_pattern\n        return X\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.PatternsGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the PatternsGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>, used for generating random patterns.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the PatternsGenerator with a random number generator.\n\n    :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n    \"\"\"\n    self.random_generator = random_generator\n    self.patterns_indices_ = []\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.PatternsGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to inject patterns into the time-series data. This method should be overridden by subclasses to implement specific pattern generation logic.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input time-series data as a 2D numpy array or pandas DataFrame.</p> required <code>y</code> <p>Target values as a 1D numpy array or pandas Series.</p> required <code>params</code> <p>Additional parameters that might be required for pattern generation.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified time-series data and target values.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n    Abstract method to inject patterns into the time-series data.\n    This method should be overridden by subclasses to implement specific pattern generation logic.\n\n    :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n    :param y: Target values as a 1D numpy array or pandas Series.\n    :param params: Additional parameters that might be required for pattern generation.\n    :return: A tuple containing the modified time-series data and target values.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedConstantPatterns","title":"<code>RandomlySpacedConstantPatterns</code>","text":"<p>               Bases: <code>PatternsGenerator</code></p> <p>Generates constant patterns of constant value with random width and indices</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>class RandomlySpacedConstantPatterns(PatternsGenerator):\n    \"\"\"\n    Generates constant patterns of constant value with random width and indices\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomlySpacedConstantPatterns with a random number generator.\n\n        :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n                 max_width_patterns: int = 10,\n                 constant_value: float = 0) -&gt; Tuple:\n        \"\"\"\n        Generate constant patterns with random width and indices in the time-series data.\n\n        :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n        :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n        :param n_patterns: The number of constant patterns to inject into the time-series data.\n        :param min_width_pattern: The minimum width of each constant pattern to inject.\n        :param max_width_patterns: The maximum width of each constant pattern to inject.\n        :param constant_value: The constant value of the patterns to inject.\n        :return: A tuple containing the transformed time-series data and the unchanged target values.\n        \"\"\"\n        # generate patterns indices and values\n        self.patterns_indices_ = generate_random_patterns_indices(\n            random_generator=self.random_generator,\n            n_patterns=n_patterns,\n            signal_size=len(X),\n            min_width_pattern=min_width_pattern,\n            max_width_patterns=max_width_patterns)\n\n        for (start, end) in self.patterns_indices_:\n            X.iloc[start:end, :] = constant_value\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedConstantPatterns.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomlySpacedConstantPatterns with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>, used for generating random patterns.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomlySpacedConstantPatterns with a random number generator.\n\n    :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedConstantPatterns.generate","title":"<code>generate(X, y, n_patterns=10, min_width_pattern=5, max_width_patterns=10, constant_value=0)</code>","text":"<p>Generate constant patterns with random width and indices in the time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input time-series data as a 2D numpy array or pandas DataFrame.</p> required <code>y</code> <p>Target values as a 1D numpy array or pandas Series (not used in this method).</p> required <code>n_patterns</code> <code>int</code> <p>The number of constant patterns to inject into the time-series data.</p> <code>10</code> <code>min_width_pattern</code> <code>int</code> <p>The minimum width of each constant pattern to inject.</p> <code>5</code> <code>max_width_patterns</code> <code>int</code> <p>The maximum width of each constant pattern to inject.</p> <code>10</code> <code>constant_value</code> <code>float</code> <p>The constant value of the patterns to inject.</p> <code>0</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed time-series data and the unchanged target values.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n             max_width_patterns: int = 10,\n             constant_value: float = 0) -&gt; Tuple:\n    \"\"\"\n    Generate constant patterns with random width and indices in the time-series data.\n\n    :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n    :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n    :param n_patterns: The number of constant patterns to inject into the time-series data.\n    :param min_width_pattern: The minimum width of each constant pattern to inject.\n    :param max_width_patterns: The maximum width of each constant pattern to inject.\n    :param constant_value: The constant value of the patterns to inject.\n    :return: A tuple containing the transformed time-series data and the unchanged target values.\n    \"\"\"\n    # generate patterns indices and values\n    self.patterns_indices_ = generate_random_patterns_indices(\n        random_generator=self.random_generator,\n        n_patterns=n_patterns,\n        signal_size=len(X),\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns)\n\n    for (start, end) in self.patterns_indices_:\n        X.iloc[start:end, :] = constant_value\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedLinearPatterns","title":"<code>RandomlySpacedLinearPatterns</code>","text":"<p>               Bases: <code>PatternsGenerator</code></p> <p>Generates patterns of constant slope (linear) with random width and indices</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>class RandomlySpacedLinearPatterns(PatternsGenerator):\n    \"\"\"\n    Generates patterns of constant slope (linear) with random width and indices\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomlySpacedLinearPatterns with a random number generator.\n\n        :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n                 max_width_patterns: int = 10) -&gt; Tuple:\n        \"\"\"\n        Generate linear patterns with random width and indices in the time-series data.\n\n        :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n        :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n        :param n_patterns: The number of linear patterns to inject into the time-series data.\n        :param min_width_pattern: The minimum width of each linear pattern to inject.\n        :param max_width_patterns: The maximum width of each linear pattern to inject.\n        :return: A tuple containing the transformed time-series data and the unchanged target values.\n        \"\"\"\n        # generate patterns indices and values\n        self.patterns_indices_ = generate_random_patterns_indices(\n            random_generator=self.random_generator,\n            n_patterns=n_patterns,\n            signal_size=len(X),\n            min_width_pattern=min_width_pattern,\n            max_width_patterns=max_width_patterns)\n\n        for (start, end) in self.patterns_indices_:\n            for col in range(X.shape[1]):\n                X.iloc[start:end, col] = np.linspace(X.iloc[start, col], X.iloc[end, col], end - start)\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedLinearPatterns.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomlySpacedLinearPatterns with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>, used for generating random patterns.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomlySpacedLinearPatterns with a random number generator.\n\n    :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedLinearPatterns.generate","title":"<code>generate(X, y, n_patterns=10, min_width_pattern=5, max_width_patterns=10)</code>","text":"<p>Generate linear patterns with random width and indices in the time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input time-series data as a 2D numpy array or pandas DataFrame.</p> required <code>y</code> <p>Target values as a 1D numpy array or pandas Series (not used in this method).</p> required <code>n_patterns</code> <code>int</code> <p>The number of linear patterns to inject into the time-series data.</p> <code>10</code> <code>min_width_pattern</code> <code>int</code> <p>The minimum width of each linear pattern to inject.</p> <code>5</code> <code>max_width_patterns</code> <code>int</code> <p>The maximum width of each linear pattern to inject.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed time-series data and the unchanged target values.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n             max_width_patterns: int = 10) -&gt; Tuple:\n    \"\"\"\n    Generate linear patterns with random width and indices in the time-series data.\n\n    :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n    :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n    :param n_patterns: The number of linear patterns to inject into the time-series data.\n    :param min_width_pattern: The minimum width of each linear pattern to inject.\n    :param max_width_patterns: The maximum width of each linear pattern to inject.\n    :return: A tuple containing the transformed time-series data and the unchanged target values.\n    \"\"\"\n    # generate patterns indices and values\n    self.patterns_indices_ = generate_random_patterns_indices(\n        random_generator=self.random_generator,\n        n_patterns=n_patterns,\n        signal_size=len(X),\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns)\n\n    for (start, end) in self.patterns_indices_:\n        for col in range(X.shape[1]):\n            X.iloc[start:end, col] = np.linspace(X.iloc[start, col], X.iloc[end, col], end - start)\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedPatterns","title":"<code>RandomlySpacedPatterns</code>","text":"<p>               Bases: <code>PatternsGenerator</code></p> <p>Inject given patterns with random width and indices</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>class RandomlySpacedPatterns(PatternsGenerator):\n    \"\"\"\n    Inject given patterns with random width and indices\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomlySpacedPatterns with a random number generator.\n\n        :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n                 max_width_patterns: int = 10,\n                 pattern: Pattern = Pattern(values=np.array([0, 0, 0, 0, 0])),\n                 scaling_factor: Union[float, str, None] = 'auto') -&gt; Tuple:\n        \"\"\"\n        Inject patterns with random width and indices in the time-series data.\n\n        :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n        :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n        :param n_patterns: The number of patterns to inject into the time-series data.\n        :param min_width_pattern: The minimum width of the pattern to inject.\n        :param max_width_patterns: The maximum width of the pattern to inject.\n        :param pattern: The pattern to inject, represented as a `Pattern` object.\n        :param scaling_factor: The factor by which to scale the pattern before injection. Can be a float, 'auto' to scale based on the signal's range, or None to apply no scaling.\n        :return: A tuple containing the transformed time-series data and the unchanged target values.\n        \"\"\"\n        # generate patterns indices and values\n        self.patterns_indices_ = generate_random_patterns_indices(\n            random_generator=self.random_generator,\n            n_patterns=n_patterns,\n            signal_size=len(X),\n            min_width_pattern=min_width_pattern,\n            max_width_patterns=max_width_patterns)\n\n        for (start, end) in self.patterns_indices_:\n            X = self._inject_pattern(X, p=pattern, start_index=start, end_index=end, scaling_factor=scaling_factor)\n\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedPatterns.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomlySpacedPatterns with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator from <code>numpy.random</code>, used for generating random patterns.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomlySpacedPatterns with a random number generator.\n\n    :param random_generator: An instance of a random number generator from `numpy.random`, used for generating random patterns.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.RandomlySpacedPatterns.generate","title":"<code>generate(X, y, n_patterns=10, min_width_pattern=5, max_width_patterns=10, pattern=Pattern(values=(np.array([0, 0, 0, 0, 0]))), scaling_factor='auto')</code>","text":"<p>Inject patterns with random width and indices in the time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input time-series data as a 2D numpy array or pandas DataFrame.</p> required <code>y</code> <p>Target values as a 1D numpy array or pandas Series (not used in this method).</p> required <code>n_patterns</code> <code>int</code> <p>The number of patterns to inject into the time-series data.</p> <code>10</code> <code>min_width_pattern</code> <code>int</code> <p>The minimum width of the pattern to inject.</p> <code>5</code> <code>max_width_patterns</code> <code>int</code> <p>The maximum width of the pattern to inject.</p> <code>10</code> <code>pattern</code> <code>Pattern</code> <p>The pattern to inject, represented as a <code>Pattern</code> object.</p> <code>Pattern(values=array([0, 0, 0, 0, 0]))</code> <code>scaling_factor</code> <code>Union[float, str, None]</code> <p>The factor by which to scale the pattern before injection. Can be a float, 'auto' to scale based on the signal's range, or None to apply no scaling.</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed time-series data and the unchanged target values.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n             max_width_patterns: int = 10,\n             pattern: Pattern = Pattern(values=np.array([0, 0, 0, 0, 0])),\n             scaling_factor: Union[float, str, None] = 'auto') -&gt; Tuple:\n    \"\"\"\n    Inject patterns with random width and indices in the time-series data.\n\n    :param X: Input time-series data as a 2D numpy array or pandas DataFrame.\n    :param y: Target values as a 1D numpy array or pandas Series (not used in this method).\n    :param n_patterns: The number of patterns to inject into the time-series data.\n    :param min_width_pattern: The minimum width of the pattern to inject.\n    :param max_width_patterns: The maximum width of the pattern to inject.\n    :param pattern: The pattern to inject, represented as a `Pattern` object.\n    :param scaling_factor: The factor by which to scale the pattern before injection. Can be a float, 'auto' to scale based on the signal's range, or None to apply no scaling.\n    :return: A tuple containing the transformed time-series data and the unchanged target values.\n    \"\"\"\n    # generate patterns indices and values\n    self.patterns_indices_ = generate_random_patterns_indices(\n        random_generator=self.random_generator,\n        n_patterns=n_patterns,\n        signal_size=len(X),\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns)\n\n    for (start, end) in self.patterns_indices_:\n        X = self._inject_pattern(X, p=pattern, start_index=start, end_index=end, scaling_factor=scaling_factor)\n\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.add_linear_trend","title":"<code>add_linear_trend(values, start_value=0.0, end_value=1.0)</code>","text":"<p>Adds a linear trend to the given array of values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array</code> <p>The input array of values to which the linear trend will be added.</p> required <code>start_value</code> <code>float</code> <p>The starting value of the linear trend.</p> <code>0.0</code> <code>end_value</code> <code>float</code> <p>The ending value of the linear trend.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>array</code> <p>A new array with the linear trend added to each element.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def add_linear_trend(values: np.array, start_value: float = 0., end_value: float = 1.) -&gt; np.array:\n    \"\"\"\n    Adds a linear trend to the given array of values.\n\n    :param values: The input array of values to which the linear trend will be added.\n    :param start_value: The starting value of the linear trend.\n    :param end_value: The ending value of the linear trend.\n    :return: A new array with the linear trend added to each element.\n    \"\"\"\n    return values + np.linspace(start_value - values[0], end_value - values[-1], len(values))\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.add_offset","title":"<code>add_offset(values, offset=0.0)</code>","text":"<p>Adds an offset to the given array of values.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array</code> <p>The input array of values to which the offset will be added.</p> required <code>offset</code> <code>float</code> <p>The offset value to be added to each element in the array.</p> <code>0.0</code> <p>Returns:</p> Type Description <code>array</code> <p>A new array with the offset added to each element.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def add_offset(values: np.array, offset: float = 0.) -&gt; np.array:\n    \"\"\"\n    Adds an offset to the given array of values.\n\n    :param values: The input array of values to which the offset will be added.\n    :param offset: The offset value to be added to each element in the array.\n    :return: A new array with the offset added to each element.\n    \"\"\"\n    return values + offset\n</code></pre>"},{"location":"reference/badgers/generators/time_series/patterns/#badgers.generators.time_series.patterns.scale","title":"<code>scale(values, scaling_factor=1.0)</code>","text":"<p>Scales the given array of values by a specified factor.</p> <p>Parameters:</p> Name Type Description Default <code>values</code> <code>array</code> <p>The input array of values to be scaled.</p> required <code>scaling_factor</code> <code>float</code> <p>The factor by which to scale the values.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>array</code> <p>A new array with each element scaled by the specified factor.</p> Source code in <code>badgers/generators/time_series/patterns.py</code> <pre><code>def scale(values: np.array, scaling_factor: float = 1.) -&gt; np.array:\n    \"\"\"\n    Scales the given array of values by a specified factor.\n\n    :param values: The input array of values to be scaled.\n    :param scaling_factor: The factor by which to scale the values.\n    :return: A new array with each element scaled by the specified factor.\n    \"\"\"\n    return values * scaling_factor\n</code></pre>"},{"location":"reference/badgers/generators/time_series/seasons/","title":"seasons","text":""},{"location":"reference/badgers/generators/time_series/seasons/#badgers.generators.time_series.seasons.GlobalAdditiveSinusoidalSeasonGenerator","title":"<code>GlobalAdditiveSinusoidalSeasonGenerator</code>","text":"<p>               Bases: <code>SeasonsGenerator</code></p> <p>Add a sinusoidal season to the input time-series data</p> Source code in <code>badgers/generators/time_series/seasons.py</code> <pre><code>class GlobalAdditiveSinusoidalSeasonGenerator(SeasonsGenerator):\n    \"\"\"\n    Add a sinusoidal season to the input time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, period: int = 10) -&gt; Tuple:\n        \"\"\"\n        Adds a global sinusoidal seasonal pattern to the input time-series data.\n\n        :param X: Input features (time-series data). Expected to be a 2D numpy array where each row represents a time step.\n        :param y: Target variable (can be None if not applicable). Expected to be a 1D numpy array.\n        :param period: The period of the sinusoidal season. Determines the length of one complete cycle of the sinusoidal wave.\n        :return: A tuple containing the modified input features with the added sinusoidal season and the unchanged target variable.\n        \"\"\"\n        t = np.arange(len(X))\n        season = np.sin(t[:,np.newaxis]*2*np.pi/period)\n        Xt = X.add(season, axis=0)\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/seasons/#badgers.generators.time_series.seasons.GlobalAdditiveSinusoidalSeasonGenerator.generate","title":"<code>generate(X, y, period=10)</code>","text":"<p>Adds a global sinusoidal seasonal pattern to the input time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (time-series data). Expected to be a 2D numpy array where each row represents a time step.</p> required <code>y</code> <p>Target variable (can be None if not applicable). Expected to be a 1D numpy array.</p> required <code>period</code> <code>int</code> <p>The period of the sinusoidal season. Determines the length of one complete cycle of the sinusoidal wave.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified input features with the added sinusoidal season and the unchanged target variable.</p> Source code in <code>badgers/generators/time_series/seasons.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, period: int = 10) -&gt; Tuple:\n    \"\"\"\n    Adds a global sinusoidal seasonal pattern to the input time-series data.\n\n    :param X: Input features (time-series data). Expected to be a 2D numpy array where each row represents a time step.\n    :param y: Target variable (can be None if not applicable). Expected to be a 1D numpy array.\n    :param period: The period of the sinusoidal season. Determines the length of one complete cycle of the sinusoidal wave.\n    :return: A tuple containing the modified input features with the added sinusoidal season and the unchanged target variable.\n    \"\"\"\n    t = np.arange(len(X))\n    season = np.sin(t[:,np.newaxis]*2*np.pi/period)\n    Xt = X.add(season, axis=0)\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/seasons/#badgers.generators.time_series.seasons.SeasonsGenerator","title":"<code>SeasonsGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate seasons in time-series data</p> Source code in <code>badgers/generators/time_series/seasons.py</code> <pre><code>class SeasonsGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate seasons in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        :param random_generator: A random number generator instance used for generating random numbers.\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n        Generates seasonal patterns in the input time-series data.\n\n        :param X: Input features (time-series data).\n        :param y: Target variable (can be None if not applicable).\n        :param params: Additional parameters that may be required for generating seasons.\n        :return: A tuple containing the modified input features and target variable.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/seasons/#badgers.generators.time_series.seasons.SeasonsGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance used for generating random numbers.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/seasons.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    :param random_generator: A random number generator instance used for generating random numbers.\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/time_series/seasons/#badgers.generators.time_series.seasons.SeasonsGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Generates seasonal patterns in the input time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features (time-series data).</p> required <code>y</code> <p>Target variable (can be None if not applicable).</p> required <code>params</code> <p>Additional parameters that may be required for generating seasons.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified input features and target variable.</p> Source code in <code>badgers/generators/time_series/seasons.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n    Generates seasonal patterns in the input time-series data.\n\n    :param X: Input features (time-series data).\n    :param y: Target variable (can be None if not applicable).\n    :param params: Additional parameters that may be required for generating seasons.\n    :return: A tuple containing the modified input features and target variable.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/","title":"transmission_errors","text":""},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomDropGenerator","title":"<code>LocalRegionsRandomDropGenerator</code>","text":"<p>               Bases: <code>TransmissionErrorGenerator</code></p> <p>Drops randomly values in specific regions of time</p> <p>This simulates a problem in transmission where several values are randomly dropped at specific time intervals (time regions)</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class LocalRegionsRandomDropGenerator(TransmissionErrorGenerator):\n    \"\"\"\n    Drops randomly values in specific regions of time\n\n    This simulates a problem in transmission where several values are randomly dropped at specific time intervals (time regions)\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the LocalRegionsRandomDropGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.drops_indices_ = None  # to store the indices of the drops\n        self.drops_probabilities_ = None # to store the probability of dropping values\n\n    @preprocess_inputs\n    def generate(self, X, y, n_drops: int = 10, n_regions: int = 5, min_width_regions: int = 5,\n                 max_width_regions: int = 10) -&gt; Tuple:\n        \"\"\"\n        Introduces `n_drops` random drops in the input time series data X within `n_regions` specific time regions.\n\n        This method randomly defines `n_regions` time regions within the time series, each having a width between\n        `min_width_regions` and `max_width_regions`. Within each region, values are randomly dropped until the total number of\n        dropped values reaches `n_drops`. The target variable y remains unchanged.\n\n        :param X: A pandas DataFrame representing the input time series data.\n        :param y: A pandas Series representing the target variable (remains unchanged).\n        :param n_drops: An integer specifying the total number of random drops to introduce in X.\n        :param n_regions: An integer specifying the number of time regions where values will be dropped.\n        :param min_width_regions: An integer specifying the minimum width of the time regions (intervals).\n        :param max_width_regions: An integer specifying the maximum width of the time regions (intervals).\n        :return: A tuple (Xt, y) where Xt is the modified input time series data with random drops applied within specific\n                 time regions, and y is the original target variable.\n        \"\"\"\n        assert n_drops &gt; 0, 'n_drops should be strictly greater than 0'\n\n        # generate probability for where to drop points\n        self.drops_probabilities_ = get_patterns_uniform_probability(\n            signal_size=len(X),\n            random_generator=self.random_generator,\n            n_patterns=n_regions,\n            min_width_pattern=min_width_regions,\n            max_width_patterns=max_width_regions\n        )\n\n        # generate indices for drops\n        self.drops_indices_ = self.random_generator.choice(len(X), size=n_drops, p=self.drops_probabilities_, replace=False, shuffle=False)\n\n        Xt = X.drop(X.index[self.drops_indices_], axis=0).reset_index(drop=True)\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomDropGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the LocalRegionsRandomDropGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the LocalRegionsRandomDropGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.drops_indices_ = None  # to store the indices of the drops\n    self.drops_probabilities_ = None # to store the probability of dropping values\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomDropGenerator.generate","title":"<code>generate(X, y, n_drops=10, n_regions=5, min_width_regions=5, max_width_regions=10)</code>","text":"<p>Introduces <code>n_drops</code> random drops in the input time series data X within <code>n_regions</code> specific time regions.</p> <p>This method randomly defines <code>n_regions</code> time regions within the time series, each having a width between <code>min_width_regions</code> and <code>max_width_regions</code>. Within each region, values are randomly dropped until the total number of dropped values reaches <code>n_drops</code>. The target variable y remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A pandas DataFrame representing the input time series data.</p> required <code>y</code> <p>A pandas Series representing the target variable (remains unchanged).</p> required <code>n_drops</code> <code>int</code> <p>An integer specifying the total number of random drops to introduce in X.</p> <code>10</code> <code>n_regions</code> <code>int</code> <p>An integer specifying the number of time regions where values will be dropped.</p> <code>5</code> <code>min_width_regions</code> <code>int</code> <p>An integer specifying the minimum width of the time regions (intervals).</p> <code>5</code> <code>max_width_regions</code> <code>int</code> <p>An integer specifying the maximum width of the time regions (intervals).</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (Xt, y) where Xt is the modified input time series data with random drops applied within specific time regions, and y is the original target variable.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_drops: int = 10, n_regions: int = 5, min_width_regions: int = 5,\n             max_width_regions: int = 10) -&gt; Tuple:\n    \"\"\"\n    Introduces `n_drops` random drops in the input time series data X within `n_regions` specific time regions.\n\n    This method randomly defines `n_regions` time regions within the time series, each having a width between\n    `min_width_regions` and `max_width_regions`. Within each region, values are randomly dropped until the total number of\n    dropped values reaches `n_drops`. The target variable y remains unchanged.\n\n    :param X: A pandas DataFrame representing the input time series data.\n    :param y: A pandas Series representing the target variable (remains unchanged).\n    :param n_drops: An integer specifying the total number of random drops to introduce in X.\n    :param n_regions: An integer specifying the number of time regions where values will be dropped.\n    :param min_width_regions: An integer specifying the minimum width of the time regions (intervals).\n    :param max_width_regions: An integer specifying the maximum width of the time regions (intervals).\n    :return: A tuple (Xt, y) where Xt is the modified input time series data with random drops applied within specific\n             time regions, and y is the original target variable.\n    \"\"\"\n    assert n_drops &gt; 0, 'n_drops should be strictly greater than 0'\n\n    # generate probability for where to drop points\n    self.drops_probabilities_ = get_patterns_uniform_probability(\n        signal_size=len(X),\n        random_generator=self.random_generator,\n        n_patterns=n_regions,\n        min_width_pattern=min_width_regions,\n        max_width_patterns=max_width_regions\n    )\n\n    # generate indices for drops\n    self.drops_indices_ = self.random_generator.choice(len(X), size=n_drops, p=self.drops_probabilities_, replace=False, shuffle=False)\n\n    Xt = X.drop(X.index[self.drops_indices_], axis=0).reset_index(drop=True)\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomRepeatGenerator","title":"<code>LocalRegionsRandomRepeatGenerator</code>","text":"<p>               Bases: <code>TransmissionErrorGenerator</code></p> <p>Repeats randomly values x(t) only in certain time regions (time intervals)</p> <p>This simulates a delay in transmission where several values are repeated over time (in certain time intervals)</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class LocalRegionsRandomRepeatGenerator(TransmissionErrorGenerator):\n    \"\"\"\n    Repeats randomly values x(t) only in certain time regions (time intervals)\n\n    This simulates a delay in transmission where several values are repeated over time (in certain time intervals)\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the LocalRegionsRandomRepeatGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.repeats_ = None  # to store the indices of the repeats (from the original X) and the length of the repeat\n        self.repeats_probabilities_ = None  # to store the probability of repeating values\n\n    @preprocess_inputs\n    def generate(self, X, y, n_repeats: int = 10, min_nb_repeats: int = 1,\n                 max_nb_repeats: int = 10, n_regions: int = 5, min_width_regions: int = 5,\n                 max_width_regions: int = 10) -&gt; Tuple:\n        \"\"\"\n        Introduces `n_repeats` random repetitions in the input time series data X within `n_regions` specific time regions.\n\n        This method randomly defines `n_regions` time regions within the time series, each having a width between\n        `min_width_regions` and `max_width_regions`. Within each region, values are randomly selected and repeated a random number of times\n        between `min_nb_repeats` and `max_nb_repeats`. The repeated values are inserted immediately after the selected index in X.\n        The target variable y remains unchanged.\n\n        :param X: A pandas DataFrame representing the input time series data.\n        :param y: A pandas Series representing the target variable (remains unchanged).\n        :param n_repeats: An integer specifying the total number of random repetitions to introduce in X.\n        :param min_nb_repeats: An integer specifying the minimum number of times a value can be repeated.\n        :param max_nb_repeats: An integer specifying the maximum number of times a value can be repeated.\n        :param n_regions: An integer specifying the number of time regions where values will be repeated.\n        :param min_width_regions: An integer specifying the minimum width of the time regions (intervals).\n        :param max_width_regions: An integer specifying the maximum width of the time regions (intervals).\n        :return: A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied within specific\n                 time regions, and y is the original target variable.\n        \"\"\"\n        assert n_repeats &gt; 0, 'n_repeats should be strictly greater than 0'\n\n        # generate probability for where to drop points\n        self.repeats_probabilities_ = get_patterns_uniform_probability(\n            signal_size=len(X),\n            random_generator=self.random_generator,\n            n_patterns=n_regions,\n            min_width_pattern=min_width_regions,\n            max_width_patterns=max_width_regions\n        )\n\n        # generate indices for repeats\n        self.repeats_ = [(i, l) for i, l in zip(\n            sorted(self.random_generator.choice(len(X), size=n_repeats, p=self.repeats_probabilities_, replace=False, shuffle=False)),\n            self.random_generator.integers(low=min_nb_repeats, high=max_nb_repeats, size=n_repeats)\n        )]\n\n        Xt = X.values\n\n        # generate the repeats and insert them\n        offset = 0\n\n        for i, l in self.repeats_:\n            repeat = np.repeat(X.iloc[i], l)\n            Xt = np.insert(Xt, i + offset, repeat)\n            offset += l\n\n        # create a pandas dataframe with same columns as X\n        Xt = pd.DataFrame(data=Xt, columns=X.columns)\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomRepeatGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the LocalRegionsRandomRepeatGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the LocalRegionsRandomRepeatGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.repeats_ = None  # to store the indices of the repeats (from the original X) and the length of the repeat\n    self.repeats_probabilities_ = None  # to store the probability of repeating values\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.LocalRegionsRandomRepeatGenerator.generate","title":"<code>generate(X, y, n_repeats=10, min_nb_repeats=1, max_nb_repeats=10, n_regions=5, min_width_regions=5, max_width_regions=10)</code>","text":"<p>Introduces <code>n_repeats</code> random repetitions in the input time series data X within <code>n_regions</code> specific time regions.</p> <p>This method randomly defines <code>n_regions</code> time regions within the time series, each having a width between <code>min_width_regions</code> and <code>max_width_regions</code>. Within each region, values are randomly selected and repeated a random number of times between <code>min_nb_repeats</code> and <code>max_nb_repeats</code>. The repeated values are inserted immediately after the selected index in X. The target variable y remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A pandas DataFrame representing the input time series data.</p> required <code>y</code> <p>A pandas Series representing the target variable (remains unchanged).</p> required <code>n_repeats</code> <code>int</code> <p>An integer specifying the total number of random repetitions to introduce in X.</p> <code>10</code> <code>min_nb_repeats</code> <code>int</code> <p>An integer specifying the minimum number of times a value can be repeated.</p> <code>1</code> <code>max_nb_repeats</code> <code>int</code> <p>An integer specifying the maximum number of times a value can be repeated.</p> <code>10</code> <code>n_regions</code> <code>int</code> <p>An integer specifying the number of time regions where values will be repeated.</p> <code>5</code> <code>min_width_regions</code> <code>int</code> <p>An integer specifying the minimum width of the time regions (intervals).</p> <code>5</code> <code>max_width_regions</code> <code>int</code> <p>An integer specifying the maximum width of the time regions (intervals).</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied within specific time regions, and y is the original target variable.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_repeats: int = 10, min_nb_repeats: int = 1,\n             max_nb_repeats: int = 10, n_regions: int = 5, min_width_regions: int = 5,\n             max_width_regions: int = 10) -&gt; Tuple:\n    \"\"\"\n    Introduces `n_repeats` random repetitions in the input time series data X within `n_regions` specific time regions.\n\n    This method randomly defines `n_regions` time regions within the time series, each having a width between\n    `min_width_regions` and `max_width_regions`. Within each region, values are randomly selected and repeated a random number of times\n    between `min_nb_repeats` and `max_nb_repeats`. The repeated values are inserted immediately after the selected index in X.\n    The target variable y remains unchanged.\n\n    :param X: A pandas DataFrame representing the input time series data.\n    :param y: A pandas Series representing the target variable (remains unchanged).\n    :param n_repeats: An integer specifying the total number of random repetitions to introduce in X.\n    :param min_nb_repeats: An integer specifying the minimum number of times a value can be repeated.\n    :param max_nb_repeats: An integer specifying the maximum number of times a value can be repeated.\n    :param n_regions: An integer specifying the number of time regions where values will be repeated.\n    :param min_width_regions: An integer specifying the minimum width of the time regions (intervals).\n    :param max_width_regions: An integer specifying the maximum width of the time regions (intervals).\n    :return: A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied within specific\n             time regions, and y is the original target variable.\n    \"\"\"\n    assert n_repeats &gt; 0, 'n_repeats should be strictly greater than 0'\n\n    # generate probability for where to drop points\n    self.repeats_probabilities_ = get_patterns_uniform_probability(\n        signal_size=len(X),\n        random_generator=self.random_generator,\n        n_patterns=n_regions,\n        min_width_pattern=min_width_regions,\n        max_width_patterns=max_width_regions\n    )\n\n    # generate indices for repeats\n    self.repeats_ = [(i, l) for i, l in zip(\n        sorted(self.random_generator.choice(len(X), size=n_repeats, p=self.repeats_probabilities_, replace=False, shuffle=False)),\n        self.random_generator.integers(low=min_nb_repeats, high=max_nb_repeats, size=n_repeats)\n    )]\n\n    Xt = X.values\n\n    # generate the repeats and insert them\n    offset = 0\n\n    for i, l in self.repeats_:\n        repeat = np.repeat(X.iloc[i], l)\n        Xt = np.insert(Xt, i + offset, repeat)\n        offset += l\n\n    # create a pandas dataframe with same columns as X\n    Xt = pd.DataFrame(data=Xt, columns=X.columns)\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomDropGenerator","title":"<code>RandomDropGenerator</code>","text":"<p>               Bases: <code>TransmissionErrorGenerator</code></p> <p>Drops randomly values</p> <p>a time series x(t) = {x(0), x(1), x(2), x(3), x(4), x(5)} would be transformed to              x'(t) = {x(0), x(1), x(3), x(4)}</p> <p>This simulates a problem in transmission where several values are randomly dropped</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class RandomDropGenerator(TransmissionErrorGenerator):\n    \"\"\"\n    Drops randomly values\n\n    a time series x(t) = {x(0), x(1), x(2), x(3), x(4), x(5)} would be transformed to\n                 x'(t) = {x(0), x(1), x(3), x(4)}\n\n    This simulates a problem in transmission where several values are randomly dropped\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the RandomDropGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.drops_indices_ = None  # to store the indices of the drops\n\n    @preprocess_inputs\n    def generate(self, X, y, n_drops: int = 10) -&gt; Tuple:\n        \"\"\"\n        Introduces `n_drops` random drops in the input time series data X.\n\n        This method randomly selects `n_drops` indices from X and removes the corresponding rows.\n        The target variable y remains unchanged.\n\n        :param X: A pandas DataFrame representing the input time series data.\n        :param y: A pandas Series representing the target variable (remains unchanged).\n        :param n_drops: An integer specifying the number of random drops to introduce in X.\n        :return: A tuple (Xt, y) where Xt is the modified input time series data with random drops applied,\n                 and y is the original target variable.\n        \"\"\"\n        assert n_drops &gt; 0, 'n_drops should be strictly greater than 0'\n\n        # generate indices for drops\n        self.drops_indices_ = self.random_generator.choice(len(X), size=n_drops, replace=False, shuffle=False)\n\n        Xt = X.drop(X.index[self.drops_indices_], axis=0).reset_index(drop=True)\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomDropGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the RandomDropGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the RandomDropGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.drops_indices_ = None  # to store the indices of the drops\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomDropGenerator.generate","title":"<code>generate(X, y, n_drops=10)</code>","text":"<p>Introduces <code>n_drops</code> random drops in the input time series data X.</p> <p>This method randomly selects <code>n_drops</code> indices from X and removes the corresponding rows. The target variable y remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A pandas DataFrame representing the input time series data.</p> required <code>y</code> <p>A pandas Series representing the target variable (remains unchanged).</p> required <code>n_drops</code> <code>int</code> <p>An integer specifying the number of random drops to introduce in X.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (Xt, y) where Xt is the modified input time series data with random drops applied, and y is the original target variable.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_drops: int = 10) -&gt; Tuple:\n    \"\"\"\n    Introduces `n_drops` random drops in the input time series data X.\n\n    This method randomly selects `n_drops` indices from X and removes the corresponding rows.\n    The target variable y remains unchanged.\n\n    :param X: A pandas DataFrame representing the input time series data.\n    :param y: A pandas Series representing the target variable (remains unchanged).\n    :param n_drops: An integer specifying the number of random drops to introduce in X.\n    :return: A tuple (Xt, y) where Xt is the modified input time series data with random drops applied,\n             and y is the original target variable.\n    \"\"\"\n    assert n_drops &gt; 0, 'n_drops should be strictly greater than 0'\n\n    # generate indices for drops\n    self.drops_indices_ = self.random_generator.choice(len(X), size=n_drops, replace=False, shuffle=False)\n\n    Xt = X.drop(X.index[self.drops_indices_], axis=0).reset_index(drop=True)\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomRepeatGenerator","title":"<code>RandomRepeatGenerator</code>","text":"<p>               Bases: <code>TransmissionErrorGenerator</code></p> <p>Repeats randomly values</p> <p>a time series x(t) = {x(0), x(1), x(2), x(3), x(4), x(5)} would be transformed to              x'(t) = {x(0), x(1), x(1), x(2), x(3), x(4), x(4), x(4), x(5)}</p> <p>This simulates a delay in transmission where several values are repeated over time</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class RandomRepeatGenerator(TransmissionErrorGenerator):\n    \"\"\"\n    Repeats randomly values\n\n    a time series x(t) = {x(0), x(1), x(2), x(3), x(4), x(5)} would be transformed to\n                 x'(t) = {x(0), x(1), x(1), x(2), x(3), x(4), x(4), x(4), x(5)}\n\n    This simulates a delay in transmission where several values are repeated over time\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the RandomRepeatGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.repeats_ = None  # to store the indices of the repeats (from the original X) and the length of the repeat\n\n    @preprocess_inputs\n    def generate(self, X, y, n_repeats: int = 10, min_nb_repeats: int = 1,\n                 max_nb_repeats: int = 10) -&gt; Tuple:\n        \"\"\"\n        Introduces `n_repeats` random repetitions in the input time series data X.\n\n        This method randomly selects `n_repeats` indices from X and repeats each selected value a random number of times between\n        `min_nb_repeats` and `max_nb_repeats`. The repeated values are inserted immediately after the selected index in X.\n        The target variable y remains unchanged.\n\n        :param X: A pandas DataFrame representing the input time series data.\n        :param y: A pandas Series representing the target variable (remains unchanged).\n        :param n_repeats: An integer specifying the number of random repetitions to introduce in X.\n        :param min_nb_repeats: An integer specifying the minimum number of times a value can be repeated.\n        :param max_nb_repeats: An integer specifying the maximum number of times a value can be repeated.\n        :return: A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied,\n                 and y is the original target variable.\n        \"\"\"\n        assert n_repeats &gt; 0, 'n_repeats should be strictly greater than 0'\n\n        # generate indices for repeats\n        self.repeats_ = [(i, l) for i, l in zip(\n            sorted(self.random_generator.choice(len(X), size=n_repeats, replace=False, shuffle=False)),\n            self.random_generator.integers(low=min_nb_repeats, high=max_nb_repeats, size=n_repeats)\n        )]\n\n        Xt = X.values\n\n        # generate the repeats and insert them\n        offset = 0\n\n        for i, l in self.repeats_:\n            repeat = np.repeat(X.iloc[i], l)\n            Xt = np.insert(Xt, i + offset, repeat)\n            offset += l\n\n        # create a pandas dataframe with same columns as X\n        Xt = pd.DataFrame(data=Xt, columns=X.columns)\n\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomRepeatGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the RandomRepeatGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the RandomRepeatGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.repeats_ = None  # to store the indices of the repeats (from the original X) and the length of the repeat\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomRepeatGenerator.generate","title":"<code>generate(X, y, n_repeats=10, min_nb_repeats=1, max_nb_repeats=10)</code>","text":"<p>Introduces <code>n_repeats</code> random repetitions in the input time series data X.</p> <p>This method randomly selects <code>n_repeats</code> indices from X and repeats each selected value a random number of times between <code>min_nb_repeats</code> and <code>max_nb_repeats</code>. The repeated values are inserted immediately after the selected index in X. The target variable y remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A pandas DataFrame representing the input time series data.</p> required <code>y</code> <p>A pandas Series representing the target variable (remains unchanged).</p> required <code>n_repeats</code> <code>int</code> <p>An integer specifying the number of random repetitions to introduce in X.</p> <code>10</code> <code>min_nb_repeats</code> <code>int</code> <p>An integer specifying the minimum number of times a value can be repeated.</p> <code>1</code> <code>max_nb_repeats</code> <code>int</code> <p>An integer specifying the maximum number of times a value can be repeated.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied, and y is the original target variable.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_repeats: int = 10, min_nb_repeats: int = 1,\n             max_nb_repeats: int = 10) -&gt; Tuple:\n    \"\"\"\n    Introduces `n_repeats` random repetitions in the input time series data X.\n\n    This method randomly selects `n_repeats` indices from X and repeats each selected value a random number of times between\n    `min_nb_repeats` and `max_nb_repeats`. The repeated values are inserted immediately after the selected index in X.\n    The target variable y remains unchanged.\n\n    :param X: A pandas DataFrame representing the input time series data.\n    :param y: A pandas Series representing the target variable (remains unchanged).\n    :param n_repeats: An integer specifying the number of random repetitions to introduce in X.\n    :param min_nb_repeats: An integer specifying the minimum number of times a value can be repeated.\n    :param max_nb_repeats: An integer specifying the maximum number of times a value can be repeated.\n    :return: A tuple (Xt, y) where Xt is the modified input time series data with random repetitions applied,\n             and y is the original target variable.\n    \"\"\"\n    assert n_repeats &gt; 0, 'n_repeats should be strictly greater than 0'\n\n    # generate indices for repeats\n    self.repeats_ = [(i, l) for i, l in zip(\n        sorted(self.random_generator.choice(len(X), size=n_repeats, replace=False, shuffle=False)),\n        self.random_generator.integers(low=min_nb_repeats, high=max_nb_repeats, size=n_repeats)\n    )]\n\n    Xt = X.values\n\n    # generate the repeats and insert them\n    offset = 0\n\n    for i, l in self.repeats_:\n        repeat = np.repeat(X.iloc[i], l)\n        Xt = np.insert(Xt, i + offset, repeat)\n        offset += l\n\n    # create a pandas dataframe with same columns as X\n    Xt = pd.DataFrame(data=Xt, columns=X.columns)\n\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomTimeSwitchGenerator","title":"<code>RandomTimeSwitchGenerator</code>","text":"<p>               Bases: <code>TransmissionErrorGenerator</code></p> <p>Switches time randomly (for now uniformly at random). A time series x(t) = {x(0), x(1), x(2), ..., x(t), x(t+1), ..., x(n)} is transformed to              x'(t) = {x(0), x(1), x(2), ..., x(t+1), x(t), ..., x(n)}</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class RandomTimeSwitchGenerator(TransmissionErrorGenerator):\n    \"\"\"\n    Switches time randomly (for now uniformly at random).\n    A time series x(t) = {x(0), x(1), x(2), ..., x(t), x(t+1), ..., x(n)} is transformed to\n                 x'(t) = {x(0), x(1), x(2), ..., x(t+1), x(t), ..., x(n)}\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the RandomTimeSwitchGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n        self.switch_indices_ = None\n\n    @preprocess_inputs\n    def generate(self, X, y, n_switches: int = 10) -&gt; Tuple:\n        \"\"\"\n        Introduces `n_switches` random switches in the input time series data X.\n\n        This method randomly selects `n_switches` pairs of consecutive indices (i, i+1) and swaps their values in X.\n        The target variable y remains unchanged.\n\n        :param X: A pandas DataFrame representing the input time series data.\n        :param y: A pandas Series representing the target variable (remains unchanged).\n        :param n_switches: An integer specifying the number of random switches to introduce in X.\n        :return: A tuple (Xt, y) where Xt is the modified input time series data with random switches applied,\n                 and y is the original target variable.\n        \"\"\"\n        assert n_switches &gt; 0, 'n_switches should be strictly greater than 0'\n\n        self.switch_indices_ = self.random_generator.choice(len(X) - 1, size=n_switches, replace=False)\n        for i in self.switch_indices_:\n            tmp = X.iloc[i].copy()\n            X.iloc[i] = X.iloc[i + 1].copy()\n            X.iloc[i + 1] = tmp\n        return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomTimeSwitchGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the RandomTimeSwitchGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the RandomTimeSwitchGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n    self.switch_indices_ = None\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.RandomTimeSwitchGenerator.generate","title":"<code>generate(X, y, n_switches=10)</code>","text":"<p>Introduces <code>n_switches</code> random switches in the input time series data X.</p> <p>This method randomly selects <code>n_switches</code> pairs of consecutive indices (i, i+1) and swaps their values in X. The target variable y remains unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>A pandas DataFrame representing the input time series data.</p> required <code>y</code> <p>A pandas Series representing the target variable (remains unchanged).</p> required <code>n_switches</code> <code>int</code> <p>An integer specifying the number of random switches to introduce in X.</p> <code>10</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple (Xt, y) where Xt is the modified input time series data with random switches applied, and y is the original target variable.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_switches: int = 10) -&gt; Tuple:\n    \"\"\"\n    Introduces `n_switches` random switches in the input time series data X.\n\n    This method randomly selects `n_switches` pairs of consecutive indices (i, i+1) and swaps their values in X.\n    The target variable y remains unchanged.\n\n    :param X: A pandas DataFrame representing the input time series data.\n    :param y: A pandas Series representing the target variable (remains unchanged).\n    :param n_switches: An integer specifying the number of random switches to introduce in X.\n    :return: A tuple (Xt, y) where Xt is the modified input time series data with random switches applied,\n             and y is the original target variable.\n    \"\"\"\n    assert n_switches &gt; 0, 'n_switches should be strictly greater than 0'\n\n    self.switch_indices_ = self.random_generator.choice(len(X) - 1, size=n_switches, replace=False)\n    for i in self.switch_indices_:\n        tmp = X.iloc[i].copy()\n        X.iloc[i] = X.iloc[i + 1].copy()\n        X.iloc[i + 1] = tmp\n    return X, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.TransmissionErrorGenerator","title":"<code>TransmissionErrorGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate transmission errors</p> <p>Transmission errors are errors that includes values dropped, delay, switching values over time...</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>class TransmissionErrorGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate transmission errors\n\n    Transmission errors are errors that includes values dropped, delay, switching values over time...\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initializes the TransmissionErrorGenerator with a specified random number generator.\n\n        :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple[pd.DataFrame, pd.Series]:\n        \"\"\"\n        Abstract method to generate transmission errors on the input data.\n\n        :param X: Input features, expected to be a pandas DataFrame.\n        :param y: Target variable, expected to be a pandas Series.\n        :param params: Additional parameters that might be needed for generating errors.\n        :return: A tuple containing the modified input features and target variable with transmission errors applied.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.TransmissionErrorGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initializes the TransmissionErrorGenerator with a specified random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>A random number generator instance (default is a NumPy random generator seeded with 0).</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initializes the TransmissionErrorGenerator with a specified random number generator.\n\n    :param random_generator: A random number generator instance (default is a NumPy random generator seeded with 0).\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/time_series/transmission_errors/#badgers.generators.time_series.transmission_errors.TransmissionErrorGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate transmission errors on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>Input features, expected to be a pandas DataFrame.</p> required <code>y</code> <p>Target variable, expected to be a pandas Series.</p> required <code>params</code> <p>Additional parameters that might be needed for generating errors.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple[DataFrame, Series]</code> <p>A tuple containing the modified input features and target variable with transmission errors applied.</p> Source code in <code>badgers/generators/time_series/transmission_errors.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple[pd.DataFrame, pd.Series]:\n    \"\"\"\n    Abstract method to generate transmission errors on the input data.\n\n    :param X: Input features, expected to be a pandas DataFrame.\n    :param y: Target variable, expected to be a pandas Series.\n    :param params: Additional parameters that might be needed for generating errors.\n    :return: A tuple containing the modified input features and target variable with transmission errors applied.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/","title":"trends","text":""},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.AdditiveLinearTrendGenerator","title":"<code>AdditiveLinearTrendGenerator</code>","text":"<p>               Bases: <code>TrendsGenerator</code></p> <p>Add a linear trend to the input time-series data</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>class AdditiveLinearTrendGenerator(TrendsGenerator):\n    \"\"\"\n    Add a linear trend to the input time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the AdditiveLinearTrendGenerator with a random number generator.\n\n        :param random_generator: An instance of a random number generator,\n                                 default is `numpy.random.default_rng(seed=0)`.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, slope, start: int, end: int) -&gt; Tuple:\n        \"\"\"\n        Add a linear trend to a specified segment of the input time-series data.\n\n        :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n        :param y: The target variable, which remains unchanged in this transformation.\n        :param slope: The slope of the trend (increase per time unit). Can be a single float value or a list of slopes\n                      for each feature in X.\n        :type slope: Union[float, list]\n        :param start: The starting index of the segment to apply the trend.\n        :param end: The ending index of the segment to apply the trend.\n        :return: A tuple containing the transformed signal Xt (X with the linear trend applied to the specified segment)\n                 and the unchanged target variable y.\n        \"\"\"\n        if start is None:\n            # when start is not given, it is chosen randomly in the first half of the signal\n            start = self.random_generator.uniform(0, int(0.5 * len(X)))\n\n        if end is None:\n            # when end is not given, the trend will last until the end of the signal\n            end = len(X)\n\n        # computing offset:\n        # - 0s until \"start\"\n        # - from \"start\" to \"end\": linear trend with slope \"slope\",\n        # - from \"end\" on: the last value\n        offset = np.zeros(shape=X.shape)\n        offset[start:end, :] = np.linspace(0, slope * (end - start), end - start)\n        offset[end:, :] = offset[end - 1, :]\n\n        Xt = X + offset\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.AdditiveLinearTrendGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the AdditiveLinearTrendGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator, default is <code>numpy.random.default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the AdditiveLinearTrendGenerator with a random number generator.\n\n    :param random_generator: An instance of a random number generator,\n                             default is `numpy.random.default_rng(seed=0)`.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.AdditiveLinearTrendGenerator.generate","title":"<code>generate(X, y, slope, start, end)</code>","text":"<p>Add a linear trend to a specified segment of the input time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input signal to be transformed, expected to be a 2D array where each row represents a time step.</p> required <code>y</code> <p>The target variable, which remains unchanged in this transformation.</p> required <code>slope</code> <code>Union[float, list]</code> <p>The slope of the trend (increase per time unit). Can be a single float value or a list of slopes for each feature in X.</p> required <code>start</code> <code>int</code> <p>The starting index of the segment to apply the trend.</p> required <code>end</code> <code>int</code> <p>The ending index of the segment to apply the trend.</p> required <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed signal Xt (X with the linear trend applied to the specified segment) and the unchanged target variable y.</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, slope, start: int, end: int) -&gt; Tuple:\n    \"\"\"\n    Add a linear trend to a specified segment of the input time-series data.\n\n    :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n    :param y: The target variable, which remains unchanged in this transformation.\n    :param slope: The slope of the trend (increase per time unit). Can be a single float value or a list of slopes\n                  for each feature in X.\n    :type slope: Union[float, list]\n    :param start: The starting index of the segment to apply the trend.\n    :param end: The ending index of the segment to apply the trend.\n    :return: A tuple containing the transformed signal Xt (X with the linear trend applied to the specified segment)\n             and the unchanged target variable y.\n    \"\"\"\n    if start is None:\n        # when start is not given, it is chosen randomly in the first half of the signal\n        start = self.random_generator.uniform(0, int(0.5 * len(X)))\n\n    if end is None:\n        # when end is not given, the trend will last until the end of the signal\n        end = len(X)\n\n    # computing offset:\n    # - 0s until \"start\"\n    # - from \"start\" to \"end\": linear trend with slope \"slope\",\n    # - from \"end\" on: the last value\n    offset = np.zeros(shape=X.shape)\n    offset[start:end, :] = np.linspace(0, slope * (end - start), end - start)\n    offset[end:, :] = offset[end - 1, :]\n\n    Xt = X + offset\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.GlobalAdditiveLinearTrendGenerator","title":"<code>GlobalAdditiveLinearTrendGenerator</code>","text":"<p>               Bases: <code>TrendsGenerator</code></p> <p>Add a linear trend to the input time-series data</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>class GlobalAdditiveLinearTrendGenerator(TrendsGenerator):\n    \"\"\"\n    Add a linear trend to the input time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the GlobalAdditiveLinearTrendGenerator with a random number generator.\n\n        :param random_generator: An instance of a random number generator,\n                                 default is `numpy.random.default_rng(seed=0)`.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, slope) -&gt; Tuple:\n        \"\"\"\n        Add a global linear trend to the input time-series data.\n\n        :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n        :param y: The target variable, which remains unchanged in this transformation.\n        :param slope: The slope of the trend (increase per time unit). Can be a single float value or a list of slopes\n                      for each feature in X.\n        :type slope: Union[float, list]\n        :return: A tuple containing the transformed signal Xt (X + linear trend) and the unchanged target variable y.\n        \"\"\"\n\n        offset = np.linspace(0, slope * len(X), len(X))\n        Xt = X + offset\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.GlobalAdditiveLinearTrendGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the GlobalAdditiveLinearTrendGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator, default is <code>numpy.random.default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the GlobalAdditiveLinearTrendGenerator with a random number generator.\n\n    :param random_generator: An instance of a random number generator,\n                             default is `numpy.random.default_rng(seed=0)`.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.GlobalAdditiveLinearTrendGenerator.generate","title":"<code>generate(X, y, slope)</code>","text":"<p>Add a global linear trend to the input time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input signal to be transformed, expected to be a 2D array where each row represents a time step.</p> required <code>y</code> <p>The target variable, which remains unchanged in this transformation.</p> required <code>slope</code> <code>Union[float, list]</code> <p>The slope of the trend (increase per time unit). Can be a single float value or a list of slopes for each feature in X.</p> required <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed signal Xt (X + linear trend) and the unchanged target variable y.</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, slope) -&gt; Tuple:\n    \"\"\"\n    Add a global linear trend to the input time-series data.\n\n    :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n    :param y: The target variable, which remains unchanged in this transformation.\n    :param slope: The slope of the trend (increase per time unit). Can be a single float value or a list of slopes\n                  for each feature in X.\n    :type slope: Union[float, list]\n    :return: A tuple containing the transformed signal Xt (X + linear trend) and the unchanged target variable y.\n    \"\"\"\n\n    offset = np.linspace(0, slope * len(X), len(X))\n    Xt = X + offset\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.RandomlySpacedLinearTrends","title":"<code>RandomlySpacedLinearTrends</code>","text":"<p>               Bases: <code>TrendsGenerator</code></p> <p>Generates randomly time intervals where a linear trend is added to the signal Slopes, Tme intervals locations and widths are chosen randomly</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>class RandomlySpacedLinearTrends(TrendsGenerator):\n    \"\"\"\n    Generates randomly time intervals where a linear trend is added to the signal\n    Slopes, Tme intervals locations and widths are chosen randomly\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the RandomlySpacedLinearTrends with a random number generator.\n\n        :param random_generator: An instance of a random number generator,\n                                 default is `numpy.random.default_rng(seed=0)`.\n        \"\"\"\n        super().__init__(random_generator=random_generator)\n\n    @preprocess_inputs\n    def generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n                 max_width_patterns: int = 10, slope_min: float = -0.05, slope_max: float = 0.05) -&gt; Tuple:\n        \"\"\"\n        Generates randomly spaced time intervals where a linear trend is added to the signal.\n        Slopes, time interval locations, and widths are chosen randomly.\n\n        :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n        :param y: The target variable, which remains unchanged in this transformation.\n        :param n_patterns: The total number of time intervals where a linear trend is added.\n        :param min_width_pattern: The minimum width of the time intervals.\n        :param max_width_patterns: The maximum width of the time intervals.\n        :param slope_min: The minimum value of the slope. The slope is chosen uniformly at random between `slope_min` and `slope_max` for each time interval and each column of X.\n        :param slope_max: The maximum value of the slope. The slope is chosen uniformly at random between `slope_min` and `slope_max` for each time interval and each column of X.\n\n        :return: A tuple containing the transformed signal Xt (X with randomly spaced linear trends added) and the unchanged target variable y.\n        \"\"\"\n\n        # generate patterns indices and values\n        self.patterns_indices_ = generate_random_patterns_indices(\n            random_generator=self.random_generator,\n            n_patterns=n_patterns,\n            signal_size=len(X),\n            min_width_pattern=min_width_pattern,\n            max_width_patterns=max_width_patterns)\n\n        # generate random slopes\n        self.slopes_ = self.random_generator.uniform(low=slope_min, high=slope_max, size=(n_patterns, X.shape[1]))\n\n        offset = np.zeros(shape=X.shape)\n\n        for (start, end), slope in zip(self.patterns_indices_, self.slopes_):\n            # computing offset:\n            # - don't change until \"start\"\n            # - from \"start\" to \"end\": add linear trend with slope \"slope\",\n            # - from \"end\" on: add the last value\n            offset[start:end, :] = np.linspace(offset[start, :], offset[start, :] + slope * (end - start), end - start)\n            offset[end:, :] = offset[end - 1, :]\n\n        Xt = X + offset\n        return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.RandomlySpacedLinearTrends.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the RandomlySpacedLinearTrends with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator, default is <code>numpy.random.default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the RandomlySpacedLinearTrends with a random number generator.\n\n    :param random_generator: An instance of a random number generator,\n                             default is `numpy.random.default_rng(seed=0)`.\n    \"\"\"\n    super().__init__(random_generator=random_generator)\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.RandomlySpacedLinearTrends.generate","title":"<code>generate(X, y, n_patterns=10, min_width_pattern=5, max_width_patterns=10, slope_min=-0.05, slope_max=0.05)</code>","text":"<p>Generates randomly spaced time intervals where a linear trend is added to the signal. Slopes, time interval locations, and widths are chosen randomly.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input signal to be transformed, expected to be a 2D array where each row represents a time step.</p> required <code>y</code> <p>The target variable, which remains unchanged in this transformation.</p> required <code>n_patterns</code> <code>int</code> <p>The total number of time intervals where a linear trend is added.</p> <code>10</code> <code>min_width_pattern</code> <code>int</code> <p>The minimum width of the time intervals.</p> <code>5</code> <code>max_width_patterns</code> <code>int</code> <p>The maximum width of the time intervals.</p> <code>10</code> <code>slope_min</code> <code>float</code> <p>The minimum value of the slope. The slope is chosen uniformly at random between <code>slope_min</code> and <code>slope_max</code> for each time interval and each column of X.</p> <code>-0.05</code> <code>slope_max</code> <code>float</code> <p>The maximum value of the slope. The slope is chosen uniformly at random between <code>slope_min</code> and <code>slope_max</code> for each time interval and each column of X.</p> <code>0.05</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the transformed signal Xt (X with randomly spaced linear trends added) and the unchanged target variable y.</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>@preprocess_inputs\ndef generate(self, X, y, n_patterns: int = 10, min_width_pattern: int = 5,\n             max_width_patterns: int = 10, slope_min: float = -0.05, slope_max: float = 0.05) -&gt; Tuple:\n    \"\"\"\n    Generates randomly spaced time intervals where a linear trend is added to the signal.\n    Slopes, time interval locations, and widths are chosen randomly.\n\n    :param X: The input signal to be transformed, expected to be a 2D array where each row represents a time step.\n    :param y: The target variable, which remains unchanged in this transformation.\n    :param n_patterns: The total number of time intervals where a linear trend is added.\n    :param min_width_pattern: The minimum width of the time intervals.\n    :param max_width_patterns: The maximum width of the time intervals.\n    :param slope_min: The minimum value of the slope. The slope is chosen uniformly at random between `slope_min` and `slope_max` for each time interval and each column of X.\n    :param slope_max: The maximum value of the slope. The slope is chosen uniformly at random between `slope_min` and `slope_max` for each time interval and each column of X.\n\n    :return: A tuple containing the transformed signal Xt (X with randomly spaced linear trends added) and the unchanged target variable y.\n    \"\"\"\n\n    # generate patterns indices and values\n    self.patterns_indices_ = generate_random_patterns_indices(\n        random_generator=self.random_generator,\n        n_patterns=n_patterns,\n        signal_size=len(X),\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns)\n\n    # generate random slopes\n    self.slopes_ = self.random_generator.uniform(low=slope_min, high=slope_max, size=(n_patterns, X.shape[1]))\n\n    offset = np.zeros(shape=X.shape)\n\n    for (start, end), slope in zip(self.patterns_indices_, self.slopes_):\n        # computing offset:\n        # - don't change until \"start\"\n        # - from \"start\" to \"end\": add linear trend with slope \"slope\",\n        # - from \"end\" on: add the last value\n        offset[start:end, :] = np.linspace(offset[start, :], offset[start, :] + slope * (end - start), end - start)\n        offset[end:, :] = offset[end - 1, :]\n\n    Xt = X + offset\n    return Xt, y\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.TrendsGenerator","title":"<code>TrendsGenerator</code>","text":"<p>               Bases: <code>GeneratorMixin</code></p> <p>Base class for transformers that generate trends in time-series data</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>class TrendsGenerator(GeneratorMixin):\n    \"\"\"\n    Base class for transformers that generate trends in time-series data\n    \"\"\"\n\n    def __init__(self, random_generator=default_rng(seed=0)):\n        \"\"\"\n        Initialize the TrendsGenerator with a random number generator.\n\n        :param random_generator: An instance of a random number generator,\n                                 default is `numpy.random.default_rng(seed=0)`.\n        \"\"\"\n        self.random_generator = random_generator\n\n    @abc.abstractmethod\n    def generate(self, X, y, **params) -&gt; Tuple:\n        \"\"\"\n        Abstract method to generate trends in time-series data.\n\n        :param X: The input features, typically a 2D array where each row represents a time step.\n        :param y: The target variable, typically a 1D array.\n        :param params: Additional parameters that can be used by the generating method.\n        :return: A tuple containing the modified features and target variable with generated trends.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.TrendsGenerator.__init__","title":"<code>__init__(random_generator=default_rng(seed=0))</code>","text":"<p>Initialize the TrendsGenerator with a random number generator.</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <p>An instance of a random number generator, default is <code>numpy.random.default_rng(seed=0)</code>.</p> <code>default_rng(seed=0)</code> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>def __init__(self, random_generator=default_rng(seed=0)):\n    \"\"\"\n    Initialize the TrendsGenerator with a random number generator.\n\n    :param random_generator: An instance of a random number generator,\n                             default is `numpy.random.default_rng(seed=0)`.\n    \"\"\"\n    self.random_generator = random_generator\n</code></pre>"},{"location":"reference/badgers/generators/time_series/trends/#badgers.generators.time_series.trends.TrendsGenerator.generate","title":"<code>generate(X, y, **params)</code>  <code>abstractmethod</code>","text":"<p>Abstract method to generate trends in time-series data.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <p>The input features, typically a 2D array where each row represents a time step.</p> required <code>y</code> <p>The target variable, typically a 1D array.</p> required <code>params</code> <p>Additional parameters that can be used by the generating method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Tuple</code> <p>A tuple containing the modified features and target variable with generated trends.</p> Source code in <code>badgers/generators/time_series/trends.py</code> <pre><code>@abc.abstractmethod\ndef generate(self, X, y, **params) -&gt; Tuple:\n    \"\"\"\n    Abstract method to generate trends in time-series data.\n\n    :param X: The input features, typically a 2D array where each row represents a time step.\n    :param y: The target variable, typically a 1D array.\n    :param params: Additional parameters that can be used by the generating method.\n    :return: A tuple containing the modified features and target variable with generated trends.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/badgers/generators/time_series/utils/","title":"utils","text":""},{"location":"reference/badgers/generators/time_series/utils/#badgers.generators.time_series.utils.generate_random_patterns_indices","title":"<code>generate_random_patterns_indices(random_generator, signal_size, n_patterns, min_width_pattern, max_width_patterns)</code>","text":"<p>Generates a list of patterns indices (start index, stop index) randomly such that: - the patterns have a size in [min_width_pattern, max_width_patterns[ - the patterns do not overlap - the patterns indices stays within the total signal size</p> <p>The algorithm is the following:</p> <ol> <li> <p>Compute patterns size (uniformly between min_width_pattern and max_width_patterns).</p> </li> <li> <p>Split the total signal size into equal length segments.     Each segment will contain exactly one pattern.     So there are <code>n_patterns</code> segments.</p> </li> <li> <p>For each segment, choose uniformly the starting and end points of the pattern such that the patterns fits into the segment.</p> </li> </ol> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>a random generator</p> required <code>signal_size</code> <code>int</code> <p>total signal size</p> required <code>n_patterns</code> <code>int</code> <p>total number of patterns</p> required <code>min_width_pattern</code> <code>int</code> <p>the minimal width of the patterns</p> required <code>max_width_patterns</code> <code>int</code> <p>the maximal width of the patterns</p> required <p>Returns:</p> Type Description <code>List[Tuple[int, int]]</code> <p>a list of patterns indices (start index, stop index)</p> Source code in <code>badgers/generators/time_series/utils.py</code> <pre><code>def generate_random_patterns_indices(random_generator: np.random.Generator, signal_size: int, n_patterns: int,\n                                     min_width_pattern: int, max_width_patterns: int) -&gt; List[Tuple[int, int]]:\n    \"\"\"\n    Generates a list of patterns indices (start index, stop index) randomly such that:\n    - the patterns have a size in [min_width_pattern, max_width_patterns[\n    - the patterns do not overlap\n    - the patterns indices stays within the total signal size\n\n    The algorithm is the following:\n\n    1.  Compute patterns size (uniformly between min_width_pattern and max_width_patterns).\n\n    2.  Split the total signal size into equal length segments.\n        Each segment will contain exactly one pattern.\n        So there are `n_patterns` segments.\n\n    3.  For each segment, choose uniformly the starting and end points of the pattern such that the patterns fits into the segment.\n\n\n\n    :param random_generator: a random generator\n    :param signal_size: total signal size\n    :param n_patterns: total number of patterns\n    :param min_width_pattern: the minimal width of the patterns\n    :param max_width_patterns: the maximal width of the patterns\n    :return: a list of patterns indices (start index, stop index)\n    \"\"\"\n    assert n_patterns &gt; 0, 'the number of patterns should be greater than zero'\n    assert (max_width_patterns - 1) * n_patterns &lt; signal_size, 'the number of patterns * their maximum width should be smaller thant the total signal size'\n    # randomly generates sizes for all patterns\n    patterns_sizes = random_generator.integers(low=min_width_pattern, high=max_width_patterns, size=n_patterns)\n    # size of segments (for splitting the total signal length)\n    segment_size = signal_size // n_patterns\n    # compute patterns indices\n    patterns_indices = []\n\n    if n_patterns == 1:\n        start = random_generator.integers(low=0, high=signal_size - patterns_sizes[0])\n        end = start + patterns_sizes[0]\n        patterns_indices += [(start, end)]\n    else:\n        for i in range(n_patterns - 1):\n            start = random_generator.integers(low=i * segment_size, high=(i + 1) * segment_size - patterns_sizes[i])\n            end = start + patterns_sizes[i]\n            patterns_indices += [(start, end)]\n        else:\n            # take care of the last remaining segment\n            start = random_generator.integers(low=(i + 1) * segment_size, high=signal_size - patterns_sizes[i + 1])\n            end = start + patterns_sizes[i + 1]\n            patterns_indices += [(start, end)]\n    return patterns_indices\n</code></pre>"},{"location":"reference/badgers/generators/time_series/utils/#badgers.generators.time_series.utils.get_patterns_uniform_probability","title":"<code>get_patterns_uniform_probability(random_generator, signal_size, n_patterns, min_width_pattern, max_width_patterns)</code>","text":"<p>Generate a probability array (sum = 1) of size <code>signal_size</code> that contains <code>n_patterns</code> segments where the probability is constant and non-zero and the rest is zero.</p> <p>Useful for some events (e.g., values drop) in some region of time</p> <p>Example</p> <p>get_patterns_uniform_probability(random_generator=np.random.default_rng(0), signal_size=10, n_patterns=2, min_width_pattern=2, max_width_patterns=3) ... np.array([0., 0., 0.25, 0.25, 0., 0., 0.25, 0.25, 0., 0.])</p> <p>Parameters:</p> Name Type Description Default <code>random_generator</code> <code>Generator</code> <p>a random generator</p> required <code>signal_size</code> <code>int</code> <p>total signal size</p> required <code>n_patterns</code> <code>int</code> <p>total number of patterns</p> required <code>min_width_pattern</code> <code>int</code> <p>the minimal width of the patterns</p> required <code>max_width_patterns</code> <code>int</code> <p>the maximal width of the patterns</p> required <p>Returns:</p> Type Description <code>array</code> <p>a numpy array of probabilies (sum = 1)</p> Source code in <code>badgers/generators/time_series/utils.py</code> <pre><code>def get_patterns_uniform_probability(random_generator: np.random.Generator, signal_size: int, n_patterns: int,\n                                     min_width_pattern: int, max_width_patterns: int) -&gt; np.array:\n    \"\"\"\n    Generate a probability array (sum = 1) of size `signal_size` that contains `n_patterns` segments where the probability is constant and non-zero and the rest is zero.\n\n    Useful for some events (e.g., values drop) in some region of time\n\n    Example\n    &gt;&gt;&gt; get_patterns_uniform_probability(random_generator=np.random.default_rng(0), signal_size=10, n_patterns=2, min_width_pattern=2, max_width_patterns=3)\n    ... np.array([0., 0., 0.25, 0.25, 0., 0., 0.25, 0.25, 0., 0.])\n\n    :param random_generator: a random generator\n    :param signal_size: total signal size\n    :param n_patterns: total number of patterns\n    :param min_width_pattern: the minimal width of the patterns\n    :param max_width_patterns: the maximal width of the patterns\n    :return: a list of patterns indices (start index, stop index)\n    :return: a numpy array of probabilies (sum = 1)\n    \"\"\"\n    # generate indices for patterns (regions where the probabilities should be constant)\n    patterns_indices = generate_random_patterns_indices(\n        random_generator=random_generator,\n        signal_size=signal_size,\n        n_patterns=n_patterns,\n        min_width_pattern=min_width_pattern,\n        max_width_patterns=max_width_patterns\n    )\n\n    # initialize probability array with zeros\n    p = np.zeros(signal_size)\n\n    # set constant values for patterns regions\n    for i, j in patterns_indices:\n        p[i:j] = 1\n\n    # normalize and return\n    return p / sum(p)\n</code></pre>"},{"location":"tutorials/Pipeline-Tabular-Data/","title":"Chaining generators through pipelines","text":"In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.datasets import make_blobs\nfrom badgers.generators.tabular_data.noise import GaussianNoiseGenerator\nfrom badgers.generators.tabular_data.imbalance import RandomSamplingClassesGenerator\nfrom badgers.core.pipeline import Pipeline\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns  from sklearn.datasets import make_blobs from badgers.generators.tabular_data.noise import GaussianNoiseGenerator from badgers.generators.tabular_data.imbalance import RandomSamplingClassesGenerator from badgers.core.pipeline import Pipeline In\u00a0[3]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[4]: Copied! <pre># load data\nX, y = make_blobs(centers=4, random_state=0, cluster_std=0.6)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y)\n</pre> # load data X, y = make_blobs(centers=4, random_state=0, cluster_std=0.6) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y) In\u00a0[5]: Copied! <pre>generators = {\n    'imbalance': RandomSamplingClassesGenerator(random_generator=rng),\n    'noise': GaussianNoiseGenerator(random_generator=rng)\n}\n\npipeline = Pipeline(generators=generators)\n\nparams = {\n    'imbalance': {'proportion_classes':{0:0.6, 1:0.25, 2:0.1, 3:0.05}},\n    'noise': {'noise_std': 0.5}\n}\n\n\n\nXt, yt = pipeline.generate(X=X.copy(), y=y, params=params)\n</pre> generators = {     'imbalance': RandomSamplingClassesGenerator(random_generator=rng),     'noise': GaussianNoiseGenerator(random_generator=rng) }  pipeline = Pipeline(generators=generators)  params = {     'imbalance': {'proportion_classes':{0:0.6, 1:0.25, 2:0.1, 3:0.05}},     'noise': {'noise_std': 0.5} }    Xt, yt = pipeline.generate(X=X.copy(), y=y, params=params) In\u00a0[6]: Copied! <pre>Xt.head()\n</pre> Xt.head() Out[6]: dimension_0 dimension_1 0 1.205728 3.453411 1 1.240226 5.064597 2 -0.239724 3.452729 3 2.566115 4.025563 4 -0.189044 3.970859 In\u00a0[7]: Copied! <pre>fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\nsns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette(\"tab10\")[:4], ax=axes[0])\nsns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette(\"tab10\")[:4], ax=axes[1])\n\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\n\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4)) sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette(\"tab10\")[:4], ax=axes[0]) sns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette(\"tab10\")[:4], ax=axes[1])  axes[0].set_title('Original') axes[1].set_title('Transformed')  plt.tight_layout(); In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\n\nclasses, nb = np.unique(y, return_counts=True)\naxes[0].bar(classes, nb, color=[f'C{i}' for i in range(len(classes))])\naxes[0].set_xlabel('classes')\naxes[0].set_ylabel('number of instances')\n\nclasses_t, nb_t = np.unique(yt, return_counts=True)\naxes[1].bar(classes_t, nb_t, color=[f'C{i}' for i in range(len(classes_t))])\naxes[1].set_xlabel('classes')\naxes[1].set_ylabel('number of instances')\n\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))  classes, nb = np.unique(y, return_counts=True) axes[0].bar(classes, nb, color=[f'C{i}' for i in range(len(classes))]) axes[0].set_xlabel('classes') axes[0].set_ylabel('number of instances')  classes_t, nb_t = np.unique(yt, return_counts=True) axes[1].bar(classes_t, nb_t, color=[f'C{i}' for i in range(len(classes_t))]) axes[1].set_xlabel('classes') axes[1].set_ylabel('number of instances')  axes[0].set_title('Original') axes[1].set_title('Transformed') plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/Pipeline-Tabular-Data/#chaining-generators-through-pipelines","title":"Chaining generators through pipelines\u00b6","text":"<p>This tutorial shows how to chain different generators using the provided Pipeline class.</p> <p>Beware, this pipeline class is not compatible with the sklearn Pipeline class</p>"},{"location":"tutorials/Pipeline-Tabular-Data/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/Pipeline-Tabular-Data/#load-data","title":"Load data\u00b6","text":"<p>Here we simply generate fake data using <code>make_blobs</code> from scikit-learn (see documentation)</p>"},{"location":"tutorials/Pipeline-Tabular-Data/#chaining-the-generators","title":"Chaining the generators\u00b6","text":""},{"location":"tutorials/Pipeline-Tabular-Data/#visualization","title":"Visualization\u00b6","text":"<p>Here is some code to visualize both the original and the transformed data</p>"},{"location":"tutorials/Pipeline-Tabular-Data/#visualizing-the-number-of-instances-for-all-classs","title":"Visualizing the number of instances for all classs\u00b6","text":""},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/","title":"Generating imbalancedness in tabular data","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom sklearn.datasets import load_iris, make_blobs\n\nfrom badgers.generators.tabular_data.imbalance import RandomSamplingClassesGenerator, RandomSamplingTargetsGenerator, RandomSamplingFeaturesGenerator\nfrom badgers.core.utils import normalize_proba\n</pre> import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns  from sklearn.datasets import load_iris, make_blobs  from badgers.generators.tabular_data.imbalance import RandomSamplingClassesGenerator, RandomSamplingTargetsGenerator, RandomSamplingFeaturesGenerator from badgers.core.utils import normalize_proba  In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre># load data\nX, y = make_blobs(centers=4, random_state=0)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y)\n</pre> # load data X, y = make_blobs(centers=4, random_state=0) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y) In\u00a0[4]: Copied! <pre>proportion_classes = {0:0.5, 1:0.05, 2:0.25, 3:0.2}\ntrf = RandomSamplingClassesGenerator(random_generator=rng)\nXt, yt = trf.generate(X=X.copy(),y=y,proportion_classes=proportion_classes)\n</pre> proportion_classes = {0:0.5, 1:0.05, 2:0.25, 3:0.2} trf = RandomSamplingClassesGenerator(random_generator=rng) Xt, yt = trf.generate(X=X.copy(),y=y,proportion_classes=proportion_classes) In\u00a0[5]: Copied! <pre>fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\nsns.scatterplot(data=X, ax=axes[0], x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette(\"tab10\")[:4], legend=True)\nsns.scatterplot(data=Xt, ax=axes[1], x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette(\"tab10\")[:4], legend=True)\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4)) sns.scatterplot(data=X, ax=axes[0], x='dimension_0', y='dimension_1', hue=y, palette=sns.color_palette(\"tab10\")[:4], legend=True) sns.scatterplot(data=Xt, ax=axes[1], x='dimension_0', y='dimension_1', hue=yt, palette=sns.color_palette(\"tab10\")[:4], legend=True) axes[0].set_title('Original') axes[1].set_title('Transformed') plt.tight_layout() In\u00a0[6]: Copied! <pre># generate fake regression target\ny = -2*X['dimension_0'] + 3*X['dimension_1'] + 5\n</pre> # generate fake regression target y = -2*X['dimension_0'] + 3*X['dimension_1'] + 5 In\u00a0[7]: Copied! <pre>def sampling_proba_func(y):\n    # this simply normalize the regression target\n    return normalize_proba(\n        (y-np.min(y)) / (np.max(y)-np.min(y))\n    )\n\ntrf = RandomSamplingTargetsGenerator(random_generator=rng)\nXt,_ = trf.generate(X=X.copy(),y=y,sampling_proba_func=sampling_proba_func)\n</pre> def sampling_proba_func(y):     # this simply normalize the regression target     return normalize_proba(         (y-np.min(y)) / (np.max(y)-np.min(y))     )  trf = RandomSamplingTargetsGenerator(random_generator=rng) Xt,_ = trf.generate(X=X.copy(),y=y,sampling_proba_func=sampling_proba_func) In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\nsns.scatterplot(data=X, ax=axes[0], x='dimension_0', y='dimension_1', hue=y, legend=False)\nsns.scatterplot(data=Xt, ax=axes[1], x='dimension_0', y='dimension_1', legend=False)\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4)) sns.scatterplot(data=X, ax=axes[0], x='dimension_0', y='dimension_1', hue=y, legend=False) sns.scatterplot(data=Xt, ax=axes[1], x='dimension_0', y='dimension_1', legend=False) axes[0].set_title('Original') axes[1].set_title('Transformed') plt.tight_layout() In\u00a0[9]: Copied! <pre>def sampling_proba_func(X):\n    feature = X['dimension_0']\n    return normalize_proba(\n        (feature - np.min(feature)) / (np.max(feature)-np.min(feature))\n    )\n\ntrf = RandomSamplingFeaturesGenerator(random_generator=rng)\nXt, _ = trf.generate(X=X.copy(), y=y, sampling_proba_func=sampling_proba_func)\n</pre> def sampling_proba_func(X):     feature = X['dimension_0']     return normalize_proba(         (feature - np.min(feature)) / (np.max(feature)-np.min(feature))     )  trf = RandomSamplingFeaturesGenerator(random_generator=rng) Xt, _ = trf.generate(X=X.copy(), y=y, sampling_proba_func=sampling_proba_func) In\u00a0[10]: Copied! <pre>fig, axes = plt.subplots(2,2, sharex=True, sharey=False, figsize=(8,8))\nsns.scatterplot(data=X, x=\"dimension_0\", y=\"dimension_1\", hue=sampling_proba_func(X), ax=axes[0,0], legend=False)\nsns.scatterplot(data=Xt, x=\"dimension_0\", y=\"dimension_1\", ax=axes[0,1])\nsns.histplot(data=X, x=\"dimension_0\", kde=True, ax=axes[1,0])\nsns.histplot(data=Xt, x=\"dimension_0\", kde=True, ax=axes[1,1])\naxes[0,0].set_title('Original')\naxes[0,1].set_title('Transformed')\n\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2,2, sharex=True, sharey=False, figsize=(8,8)) sns.scatterplot(data=X, x=\"dimension_0\", y=\"dimension_1\", hue=sampling_proba_func(X), ax=axes[0,0], legend=False) sns.scatterplot(data=Xt, x=\"dimension_0\", y=\"dimension_1\", ax=axes[0,1]) sns.histplot(data=X, x=\"dimension_0\", kde=True, ax=axes[1,0]) sns.histplot(data=Xt, x=\"dimension_0\", kde=True, ax=axes[1,1]) axes[0,0].set_title('Original') axes[0,1].set_title('Transformed')  plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/#generating-imbalancedness-in-tabular-data","title":"Generating imbalancedness in tabular data\u00b6","text":"<p>This tutorial shows how to generate imbalanced data on pre-existing tabular data and to visualize both the original and the transformed data</p>"},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/#sample-data-from-different-classes","title":"Sample data from different classes\u00b6","text":"<p>Here we are going to sample the dataset in a way that we will have 50% of all data coming from the first class, 5% coming form the second class, and 45% coming from the last class.</p>"},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/#sample-data-based-upon-the-regression-target","title":"Sample data based upon the regression target\u00b6","text":"<p>Here, we create some imbalanced data set by sampling data points propotionally to the regression target.</p> <p>For this tutorial we create a fake regression target <code>y</code>.</p>"},{"location":"tutorials/tabular-data/Imbalance-Tabular-Data/#sample-data-based-upon-the-features-themselves","title":"Sample data based upon the features themselves\u00b6","text":"<p>Instead of using the classification labels or the regression target, we create an imbalanced data set in which we remove data points based upon some features.</p> <p>In the example below we use the value of the first features <code>X[:,0]</code> to determing whether a data point will be removed, therefore creating a kind of imbalancedness.</p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/","title":"Generating missing values in tabular data","text":"In\u00a0[1]: Copied! <pre>from sklearn.datasets import make_blobs\nfrom badgers.generators.tabular_data.missingness import MissingCompletelyAtRandom, DummyMissingNotAtRandom, DummyMissingAtRandom\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n</pre> from sklearn.datasets import make_blobs from badgers.generators.tabular_data.missingness import MissingCompletelyAtRandom, DummyMissingNotAtRandom, DummyMissingAtRandom import matplotlib.pyplot as plt import numpy as np import pandas as pd In\u00a0[2]: Copied! <pre>def plot_missing(X, y, Xt):\n    \"\"\"\n    Some utility function to generate the plots\n    \"\"\"\n    missing_mask = np.isnan(Xt).any(axis=1)\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\n    for label in np.unique(y):\n        ix = np.where(y == label)\n        axes[0].scatter(X[ix,0],X[ix,1], c = f'C{label}', label = f'{label}')\n        ix = np.where(y[~missing_mask] == label )\n        axes[1].scatter(Xt[~missing_mask][ix,0], Xt[~missing_mask][ix,1], c = f'C{label}', label = f'{label}')\n    # plot missing values\n    axes[1].scatter(X[missing_mask][:,0],X[missing_mask][:,1],marker='x', color='black', label = 'missing')\n    axes[0].set_title('Original')\n    axes[1].set_title('Transformed')\n    axes[0].set_xlabel('dimension 0', fontsize=10)\n    axes[1].set_xlabel('dimension 0', fontsize=10)\n    axes[0].set_ylabel('dimension 1', fontsize=10)\n    axes[1].set_ylabel('dimension 1', fontsize=10)\n    axes[0].legend()\n    axes[1].legend()\n    return fig, axes\n</pre> def plot_missing(X, y, Xt):     \"\"\"     Some utility function to generate the plots     \"\"\"     missing_mask = np.isnan(Xt).any(axis=1)     fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))     for label in np.unique(y):         ix = np.where(y == label)         axes[0].scatter(X[ix,0],X[ix,1], c = f'C{label}', label = f'{label}')         ix = np.where(y[~missing_mask] == label )         axes[1].scatter(Xt[~missing_mask][ix,0], Xt[~missing_mask][ix,1], c = f'C{label}', label = f'{label}')     # plot missing values     axes[1].scatter(X[missing_mask][:,0],X[missing_mask][:,1],marker='x', color='black', label = 'missing')     axes[0].set_title('Original')     axes[1].set_title('Transformed')     axes[0].set_xlabel('dimension 0', fontsize=10)     axes[1].set_xlabel('dimension 0', fontsize=10)     axes[0].set_ylabel('dimension 1', fontsize=10)     axes[1].set_ylabel('dimension 1', fontsize=10)     axes[0].legend()     axes[1].legend()     return fig, axes  In\u00a0[3]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[4]: Copied! <pre># load data\nX, y = make_blobs(centers=4, random_state=0)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y)\n</pre> # load data X, y = make_blobs(centers=4, random_state=0) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y) In\u00a0[5]: Copied! <pre>trf = MissingCompletelyAtRandom(random_generator=rng)\nXt, _ = trf.generate(X.copy(), y, percentage_missing=0.25)\n</pre> trf = MissingCompletelyAtRandom(random_generator=rng) Xt, _ = trf.generate(X.copy(), y, percentage_missing=0.25) In\u00a0[6]: Copied! <pre>Xt.head()\n</pre> Xt.head() Out[6]: dimension_0 dimension_1 0 NaN 3.123155 1 NaN 8.102511 2 1.737308 4.425462 3 NaN 4.681950 4 2.206561 5.506167 In\u00a0[7]: Copied! <pre>fig, axes = plot_missing(X.values, y.values, Xt.values)\n</pre> fig, axes = plot_missing(X.values, y.values, Xt.values) In\u00a0[8]: Copied! <pre>trf = DummyMissingAtRandom(random_generator=rng)\nXt, _ = trf.generate(X.copy(), y, percentage_missing=0.25)\n</pre> trf = DummyMissingAtRandom(random_generator=rng) Xt, _ = trf.generate(X.copy(), y, percentage_missing=0.25) In\u00a0[9]: Copied! <pre>Xt.head()\n</pre> Xt.head() Out[9]: dimension_0 dimension_1 0 0.465465 3.123155 1 -2.541113 NaN 2 1.737308 4.425462 3 1.131218 4.681950 4 2.206561 5.506167 In\u00a0[10]: Copied! <pre>fig, axes = plot_missing(X.values, y.values, Xt.values)\n</pre> fig, axes = plot_missing(X.values, y.values, Xt.values) In\u00a0[11]: Copied! <pre>trf = DummyMissingNotAtRandom(random_generator=rng)\nXt, _ = trf.generate(X.copy(), y, percentage_missing=0.25)\n</pre> trf = DummyMissingNotAtRandom(random_generator=rng) Xt, _ = trf.generate(X.copy(), y, percentage_missing=0.25) In\u00a0[12]: Copied! <pre>Xt.head()\n</pre> Xt.head() Out[12]: dimension_0 dimension_1 0 0.465465 NaN 1 NaN 8.102511 2 NaN 4.425462 3 1.131218 4.681950 4 NaN 5.506167 In\u00a0[13]: Copied! <pre>fig, axes = plot_missing(X.values, y.values, Xt.values)\n</pre> fig, axes = plot_missing(X.values, y.values, Xt.values) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#generating-missing-values-in-tabular-data","title":"Generating missing values in tabular data\u00b6","text":"<p>This tutorial shows how to generate missing values on pre-existing tabular data and to visualize both the original and the transformed data</p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#load-and-prepare-data","title":"Load and prepare data\u00b6","text":"<p>We first load an existing dataset from <code>sklearn.datasets</code></p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#generate-missing-values","title":"Generate missing values\u00b6","text":"<p>Missing value mechanisms are usually categorized as missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR).</p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#missing-completely-at-random-mcar","title":"Missing completely at random (MCAR)\u00b6","text":"<p>The transformer simply replaces values (row, col) with <code>np.nan</code> independently at random.</p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#missing-at-random-mar","title":"Missing at random (MAR)\u00b6","text":"<p>Missing not at random means that the fact that a value is missing correlates with some other features.</p> <p>The DummyMissingAtRandom transformer replaces a value (row,col) with <code>np.nan</code> depending upon another feature chosen randomly. The probability of missingness depends linearly on the other chosen feature.</p>"},{"location":"tutorials/tabular-data/Missingness-Tabular-Data/#missing-not-at-random-mnar","title":"Missing not at random (MNAR)\u00b6","text":"<p>Missing not at random means that the value that is missing depends on its own value had it not been missing.</p> <p>The DummyMissingNotAtRandom simply replaces a value with <code>np.nan</code> with a probability proportional to the original value.</p>"},{"location":"tutorials/tabular-data/Noise-Tabular-Data/","title":"Generating noise in tabular data","text":"In\u00a0[1]: Copied! <pre>from sklearn.datasets import make_blobs\nfrom badgers.generators.tabular_data.noise import GaussianNoiseGenerator, GaussianNoiseClassesGenerator\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n</pre> from sklearn.datasets import make_blobs from badgers.generators.tabular_data.noise import GaussianNoiseGenerator, GaussianNoiseClassesGenerator import matplotlib.pyplot as plt import numpy as np import pandas as pd import seaborn as sns In\u00a0[2]: Copied! <pre>def plot_noise(X, y, Xt, yt):\n    \"\"\"\n    Some utility function to generate the plots\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\n    sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, ax=axes[0])\n    sns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, ax=axes[1])\n    axes[0].set_title('Original')\n    axes[1].set_title('Transformed')\n    return fig, axes\n</pre> def plot_noise(X, y, Xt, yt):     \"\"\"     Some utility function to generate the plots     \"\"\"     fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))     sns.scatterplot(data=X, x='dimension_0', y='dimension_1', hue=y, ax=axes[0])     sns.scatterplot(data=Xt, x='dimension_0', y='dimension_1', hue=yt, ax=axes[1])     axes[0].set_title('Original')     axes[1].set_title('Transformed')     return fig, axes  In\u00a0[3]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[4]: Copied! <pre># load data\nX, y = make_blobs(centers=4, random_state=0, cluster_std=0.25)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y)\n</pre> # load data X, y = make_blobs(centers=4, random_state=0, cluster_std=0.25) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y) In\u00a0[5]: Copied! <pre>trf = GaussianNoiseGenerator(random_generator=rng)\nXt, yt = trf.generate(X.copy(), y, noise_std=0.25)\n</pre> trf = GaussianNoiseGenerator(random_generator=rng) Xt, yt = trf.generate(X.copy(), y, noise_std=0.25) In\u00a0[6]: Copied! <pre>fig, axes = plot_noise(X, y, Xt, yt)\n</pre> fig, axes = plot_noise(X, y, Xt, yt) In\u00a0[7]: Copied! <pre>trf = GaussianNoiseClassesGenerator(random_generator=rng)\nXt, yt = trf.generate(X.copy(), y, noise_std_per_class={0:0.1, 1:0.2, 2:0.3, 3:0.4})\n</pre> trf = GaussianNoiseClassesGenerator(random_generator=rng) Xt, yt = trf.generate(X.copy(), y, noise_std_per_class={0:0.1, 1:0.2, 2:0.3, 3:0.4}) In\u00a0[8]: Copied! <pre>fig, axes = plot_noise(X, y, Xt, yt)\n</pre> fig, axes = plot_noise(X, y, Xt, yt) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/tabular-data/Noise-Tabular-Data/#generating-noise-in-tabular-data","title":"Generating noise in tabular data\u00b6","text":"<p>This tutorial shows how to generate noise on pre-existing tabular data and to visualize both the original and the transformed data</p>"},{"location":"tutorials/tabular-data/Noise-Tabular-Data/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/tabular-data/Noise-Tabular-Data/#load-and-prepare-data","title":"Load and prepare data\u00b6","text":"<p>We first load an existing dataset from <code>sklearn.datasets</code></p>"},{"location":"tutorials/tabular-data/Noise-Tabular-Data/#generate-noise","title":"Generate noise\u00b6","text":"<p>The transformer applies an additive Gaussian noise to each dimension</p>"},{"location":"tutorials/tabular-data/Noise-Tabular-Data/#generate-noise-for-each-class-separately","title":"Generate noise for each class separately\u00b6","text":"<p>The transformer applies an additive Gaussian noise to each dimension for each class separately.</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/","title":"Generating outliers in tabular data","text":"In\u00a0[1]: Copied! <pre>from sklearn.datasets import make_blobs\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom badgers.generators.tabular_data.outliers import DecompositionAndOutlierGenerator\nfrom badgers.generators.tabular_data.outliers.distribution_sampling import *\nfrom badgers.generators.tabular_data.outliers.instance_sampling import *\nfrom badgers.generators.tabular_data.outliers.low_density_sampling import *\n</pre>  from sklearn.datasets import make_blobs  import matplotlib.pyplot as plt import numpy as np import pandas as pd  from badgers.generators.tabular_data.outliers import DecompositionAndOutlierGenerator from badgers.generators.tabular_data.outliers.distribution_sampling import * from badgers.generators.tabular_data.outliers.instance_sampling import * from badgers.generators.tabular_data.outliers.low_density_sampling import * In\u00a0[2]: Copied! <pre>def plot_outliers(X, outliers, y):\n    \"\"\"\n    Some utility function to generate the plots\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))\n    # plot original data\n    for i in range(len(np.unique(y))):\n        ix = np.where(y == i)\n        axes[0].scatter(X[ix,0],X[ix,1], c = f'C{i}', label = f'{i}')\n        axes[1].scatter(X[ix,0],X[ix,1], c = f'C{i}', label = f'{i}')\n    # add transformed outliers\n    axes[1].scatter(outliers[:,0],outliers[:,1], marker = 'x', c = f'black', label = 'outliers')\n    # titles and co\n    axes[0].set_title('Original')\n    axes[1].set_title('Transformed')\n    axes[0].set_xlabel('1st dimension')\n    axes[0].set_ylabel('2nd dimension')\n    axes[1].set_xlabel('1st dimension')\n    axes[1].set_ylabel('2nd dimension')\n    axes[1].legend(ncol=1, bbox_to_anchor=(1, 1))\n    plt.tight_layout()\n    return fig, axes\n</pre> def plot_outliers(X, outliers, y):     \"\"\"     Some utility function to generate the plots     \"\"\"     fig, axes = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8,4))     # plot original data     for i in range(len(np.unique(y))):         ix = np.where(y == i)         axes[0].scatter(X[ix,0],X[ix,1], c = f'C{i}', label = f'{i}')         axes[1].scatter(X[ix,0],X[ix,1], c = f'C{i}', label = f'{i}')     # add transformed outliers     axes[1].scatter(outliers[:,0],outliers[:,1], marker = 'x', c = f'black', label = 'outliers')     # titles and co     axes[0].set_title('Original')     axes[1].set_title('Transformed')     axes[0].set_xlabel('1st dimension')     axes[0].set_ylabel('2nd dimension')     axes[1].set_xlabel('1st dimension')     axes[1].set_ylabel('2nd dimension')     axes[1].legend(ncol=1, bbox_to_anchor=(1, 1))     plt.tight_layout()     return fig, axes  In\u00a0[3]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[4]: Copied! <pre># load data\nX, y = make_blobs(centers=4, random_state=0, cluster_std=0.5)\nX = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1'])\ny = pd.Series(y)\n</pre> # load data X, y = make_blobs(centers=4, random_state=0, cluster_std=0.5) X = pd.DataFrame(data=X, columns=['dimension_0', 'dimension_1']) y = pd.Series(y) In\u00a0[5]: Copied! <pre>trf = ZScoreSamplingGenerator(random_generator=rng)\noutliers, _ = trf.generate(X.copy(), y=y, n_outliers=25)\n</pre> trf = ZScoreSamplingGenerator(random_generator=rng) outliers, _ = trf.generate(X.copy(), y=y, n_outliers=25) In\u00a0[6]: Copied! <pre>fig, axes = plot_outliers(X.values, outliers, y.values)\n</pre> fig, axes = plot_outliers(X.values, outliers, y.values) In\u00a0[7]: Copied! <pre>trf = HypersphereSamplingGenerator(random_generator=rng)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = HypersphereSamplingGenerator(random_generator=rng) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[8]: Copied! <pre>fig, axes = plot_outliers(X.values, outliers, y.values)\n</pre> fig, axes = plot_outliers(X.values, outliers, y.values) In\u00a0[9]: Copied! <pre>trf = IndependentHistogramsGenerator(random_generator=rng)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = IndependentHistogramsGenerator(random_generator=rng) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[10]: Copied! <pre>fig, axes = plot_outliers(X.values, outliers, y.values)\n</pre> fig, axes = plot_outliers(X.values, outliers, y.values) In\u00a0[11]: Copied! <pre>trf = HistogramSamplingGenerator(random_generator=rng)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = HistogramSamplingGenerator(random_generator=rng) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[12]: Copied! <pre>fig, axes = plot_outliers(X.values, outliers, y.values)\n</pre> fig, axes = plot_outliers(X.values, outliers, y.values) In\u00a0[13]: Copied! <pre>trf = LowDensitySamplingGenerator(random_generator=rng)\noutliers, _ = trf.generate(X.copy(), y, max_samples=100, n_outliers=25, threshold_low_density=0.25)\n</pre> trf = LowDensitySamplingGenerator(random_generator=rng) outliers, _ = trf.generate(X.copy(), y, max_samples=100, n_outliers=25, threshold_low_density=0.25) In\u00a0[14]: Copied! <pre>fig, axes = plot_outliers(X.values, outliers, y.values)\n</pre> fig, axes = plot_outliers(X.values, outliers, y.values) In\u00a0[15]: Copied! <pre># generate some data with higher dimensionality\nX, y = make_blobs(n_features=10, centers=4, cluster_std=0.60, random_state=0)\n</pre> # generate some data with higher dimensionality X, y = make_blobs(n_features=10, centers=4, cluster_std=0.60, random_state=0) In\u00a0[16]: Copied! <pre>from sklearn.decomposition import PCA, KernelPCA, FastICA\n</pre> from sklearn.decomposition import PCA, KernelPCA, FastICA In\u00a0[17]: Copied! <pre>trf = DecompositionAndOutlierGenerator(\n    decomposition_transformer=PCA(n_components=3), \n    outlier_generator=ZScoreSamplingGenerator()\n)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = DecompositionAndOutlierGenerator(     decomposition_transformer=PCA(n_components=3),      outlier_generator=ZScoreSamplingGenerator() ) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[18]: Copied! <pre>fig, axes = plot_outliers(X, outliers, y)\n</pre> fig, axes = plot_outliers(X, outliers, y) <p>Instread of PCA one can use any class from sklearn.decomposition module that provides a  <code>inverse_transform</code> method.</p> In\u00a0[19]: Copied! <pre>trf = DecompositionAndOutlierGenerator(\n    decomposition_transformer=KernelPCA(n_components=3, fit_inverse_transform=True), \n    outlier_generator=ZScoreSamplingGenerator()\n)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = DecompositionAndOutlierGenerator(     decomposition_transformer=KernelPCA(n_components=3, fit_inverse_transform=True),      outlier_generator=ZScoreSamplingGenerator() ) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[20]: Copied! <pre>fig, axes = plot_outliers(X, outliers, y)\n</pre> fig, axes = plot_outliers(X, outliers, y) <p>Here is yet another example specifying keywords arguments for the decomposition method</p> In\u00a0[21]: Copied! <pre>trf = DecompositionAndOutlierGenerator(\n    decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'), \n    outlier_generator=ZScoreSamplingGenerator()\n)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = DecompositionAndOutlierGenerator(     decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'),      outlier_generator=ZScoreSamplingGenerator() ) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[22]: Copied! <pre>fig, axes = plot_outliers(X, outliers, y)\n</pre> fig, axes = plot_outliers(X, outliers, y) In\u00a0[23]: Copied! <pre>trf = DecompositionAndOutlierGenerator(\n    decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'), \n    outlier_generator=HypersphereSamplingGenerator()\n)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = DecompositionAndOutlierGenerator(     decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'),      outlier_generator=HypersphereSamplingGenerator() ) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[24]: Copied! <pre>fig, axes = plot_outliers(X, outliers, y)\n</pre> fig, axes = plot_outliers(X, outliers, y) In\u00a0[25]: Copied! <pre>trf = DecompositionAndOutlierGenerator(\n    decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'), \n    outlier_generator=HistogramSamplingGenerator()\n)\noutliers, _ = trf.generate(X.copy(), y, n_outliers=25)\n</pre> trf = DecompositionAndOutlierGenerator(     decomposition_transformer=FastICA(n_components=3, whiten='unit-variance'),      outlier_generator=HistogramSamplingGenerator() ) outliers, _ = trf.generate(X.copy(), y, n_outliers=25) In\u00a0[26]: Copied! <pre>fig, axes = plot_outliers(X, outliers, y)\n</pre> fig, axes = plot_outliers(X, outliers, y) In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generating-outliers-in-tabular-data","title":"Generating outliers in tabular data\u00b6","text":"<p>This tutorial shows how to generate outliers (extreme values) by generating data points with a z-score greater than 3.</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#load-and-prepare-data","title":"Load and prepare data\u00b6","text":"<p>We first load an existing dataset from <code>sklearn.datasets</code></p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generating-outliers-directly-with-the-transformers","title":"Generating outliers directly with the transformers\u00b6","text":""},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-using-z-score-sampling","title":"Generate outliers using z-score sampling\u00b6","text":"<p>The transformer generates data points with a z-score greater than 3 for each dimension</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-using-hypersphere-sampling","title":"Generate outliers using hypersphere sampling\u00b6","text":"<p>The transformer generates data points on a hypersphere of radius greater than 3 sigmas</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-using-independent-histogram-sampling","title":"Generate outliers using independent histogram sampling\u00b6","text":""},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-using-histogram-sampling","title":"Generate outliers using histogram sampling\u00b6","text":"<p>Note this only works for datasets with low dimensionality (5 dimensions or less). If you wish to apply it with a dataset with more than 5 dimensions, first apply a dimensionality reduction technique.</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-using-low-density-sampling","title":"Generate outliers using low density sampling\u00b6","text":""},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#generate-outliers-by-first-reducing-the-dimensions-and-then-apply-an-outlier-transformer","title":"Generate outliers by first reducing the dimensions and then apply an outlier transformer\u00b6","text":""},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#dimensionality-reduction-and-z-score-sampling","title":"Dimensionality reduction and z-score sampling\u00b6","text":"<p>Here are a couple of examples on how to generate outliers by first applying dimensionality reduction methods from the slearn.decomposition module (like PCA, KernelPCA, etc.) and then applying the ZScore transformer</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#using-hypersphere-sampling-with-dimension-reduction-techniques","title":"Using hypersphere sampling with dimension reduction techniques\u00b6","text":"<p>Again one can first apply a dimensionality reduction techniques first and then apply the transformer</p>"},{"location":"tutorials/tabular-data/Outliers-Tabular-Data/#using-histogram-sampling-with-dimension-reduction-techniques","title":"Using histogram sampling with dimension reduction techniques\u00b6","text":"<p>Here again, one can first apply a dimensionality reduction techniques first and then apply the transformer</p>"},{"location":"tutorials/text/Typos-Text/","title":"Adding typos to text","text":"In\u00a0[1]: Copied! <pre>from badgers.generators.text.typos import SwapLettersGenerator, LeetSpeakGenerator, SwapCaseGenerator\n</pre> from badgers.generators.text.typos import SwapLettersGenerator, LeetSpeakGenerator, SwapCaseGenerator In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>X = \"the quick brown fox jumps over the lazy dog\".split(' ')\n</pre> X = \"the quick brown fox jumps over the lazy dog\".split(' ') In\u00a0[4]: Copied! <pre>swap_letters = SwapLettersGenerator(random_generator=rng)\n</pre> swap_letters = SwapLettersGenerator(random_generator=rng) In\u00a0[5]: Copied! <pre>Xt, _ = swap_letters.generate(X.copy(), y=None, swap_proba=1)\n</pre> Xt, _ = swap_letters.generate(X.copy(), y=None, swap_proba=1) In\u00a0[6]: Copied! <pre>print('Original:\\t'+' '.join(X))\nprint('Transformed:\\t'+' '.join(Xt))\n</pre> print('Original:\\t'+' '.join(X)) print('Transformed:\\t'+' '.join(Xt)) <pre>Original:\tthe quick brown fox jumps over the lazy dog\nTransformed:\tthe qucik borwn fox jmups oevr the lzay dog\n</pre> In\u00a0[7]: Copied! <pre>leet_speak = LeetSpeakGenerator()\n</pre> leet_speak = LeetSpeakGenerator() In\u00a0[8]: Copied! <pre>Xt, _ = leet_speak.generate(X.copy(), y=None, replacement_proba=0.25)\n</pre> Xt, _ = leet_speak.generate(X.copy(), y=None, replacement_proba=0.25) In\u00a0[9]: Copied! <pre>print('Original:\\t'+' '.join(X))\nprint('Transformed:\\t'+' '.join(Xt))\n</pre> print('Original:\\t'+' '.join(X)) print('Transformed:\\t'+' '.join(Xt)) <pre>Original:\tthe quick brown fox jumps over the lazy dog\nTransformed:\tth3 quick br0w^ /=ox ju/\\/\\ps over the l4zy dog\n</pre> In\u00a0[10]: Copied! <pre>swap_case = SwapCaseGenerator()\n</pre> swap_case = SwapCaseGenerator() In\u00a0[11]: Copied! <pre>Xt, _ = swap_case.generate(X.copy(), y=None, swapcase_proba=0.25)\n</pre> Xt, _ = swap_case.generate(X.copy(), y=None, swapcase_proba=0.25) In\u00a0[12]: Copied! <pre>print('Original:\\t'+' '.join(X))\nprint('Transformed:\\t'+' '.join(Xt))\n</pre> print('Original:\\t'+' '.join(X)) print('Transformed:\\t'+' '.join(Xt)) <pre>Original:\tthe quick brown fox jumps over the lazy dog\nTransformed:\tthE Quick broWn FoX jumpS Over the lazy Dog\n</pre> In\u00a0[13]: Copied! <pre>from badgers.core.pipeline import Pipeline\n</pre> from badgers.core.pipeline import Pipeline In\u00a0[14]: Copied! <pre>generators = {'swap_letters': swap_letters, 'leet_speak': leet_speak, 'swap_case': swap_case}\nparams = {'swap_letters': {'swap_proba':0.5}, 'leet_speak': {'replacement_proba':0.25}, 'swap_case': {'swapcase_proba':0.25}}\npipeline = Pipeline(generators=generators)\nXt, _ = pipeline.generate(X.copy(), y=None, params=params)\n</pre> generators = {'swap_letters': swap_letters, 'leet_speak': leet_speak, 'swap_case': swap_case} params = {'swap_letters': {'swap_proba':0.5}, 'leet_speak': {'replacement_proba':0.25}, 'swap_case': {'swapcase_proba':0.25}} pipeline = Pipeline(generators=generators) Xt, _ = pipeline.generate(X.copy(), y=None, params=params) In\u00a0[15]: Copied! <pre>print('Original:\\t'+' '.join(X))\nprint('Transformed:\\t'+' '.join(Xt))\n</pre> print('Original:\\t'+' '.join(X)) print('Transformed:\\t'+' '.join(Xt)) <pre>Original:\tthe quick brown fox jumps over the lazy dog\nTransformed:\tthe quick /3\u00aeOw^ vo)( Jv(v)|^eHS ov\u20acR t|~|e lzay dog\n</pre>"},{"location":"tutorials/text/Typos-Text/#adding-typos-to-text","title":"Adding typos to text\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#data","title":"Data\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#swapping-letter-randomly","title":"Swapping letter randomly\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#leet-speak","title":"Leet Speak\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#swap-case","title":"Swap case\u00b6","text":""},{"location":"tutorials/text/Typos-Text/#using-pipelines","title":"Using pipelines\u00b6","text":""},{"location":"tutorials/time-series/Changepoints-Time-Series/","title":"Generate changepoints in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.changepoints import RandomChangeInMeanGenerator\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from badgers.generators.time_series.changepoints import RandomChangeInMeanGenerator In\u00a0[3]: Copied! <pre>from numpy.random import default_rng\nseed = 12345\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 12345 rng = default_rng(seed) In\u00a0[4]: Copied! <pre>X = pd.DataFrame(data=rng.normal(size=(100,2), scale=0.25), columns=['dimension_0', 'dimension_1'], index=np.arange(100))\n</pre> X = pd.DataFrame(data=rng.normal(size=(100,2), scale=0.25), columns=['dimension_0', 'dimension_1'], index=np.arange(100)) In\u00a0[5]: Copied! <pre>X.plot(subplots=True)\n</pre> X.plot(subplots=True) Out[5]: <pre>array([&lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object)</pre> In\u00a0[6]: Copied! <pre>generator = RandomChangeInMeanGenerator(random_generator=rng)\n</pre> generator = RandomChangeInMeanGenerator(random_generator=rng) In\u00a0[7]: Copied! <pre>Xt, _ = generator.generate(X=X.copy(), y=None, max_change=2, min_change=-2, n_changepoints=5)\n</pre> Xt, _ = generator.generate(X=X.copy(), y=None, max_change=2, min_change=-2, n_changepoints=5) In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(X)\naxes[0].set_title('Original data')\naxes[1].plot(Xt)\naxes[1].set_title('Transformed data')\nfor cpt in generator.changepoints:\n    axes[1].vlines(cpt[0], ymin=Xt.min().min(), ymax=Xt.max().max(), ls='--', color='r')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(X) axes[0].set_title('Original data') axes[1].plot(Xt) axes[1].set_title('Transformed data') for cpt in generator.changepoints:     axes[1].vlines(cpt[0], ymin=Xt.min().min(), ymax=Xt.max().max(), ls='--', color='r') plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Changepoints-Time-Series/#generate-changepoints-in-time-series","title":"Generate changepoints in time series\u00b6","text":""},{"location":"tutorials/time-series/Changepoints-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Changepoints-Time-Series/#generate-data-gaussian-white-noise","title":"Generate data (gaussian white noise)\u00b6","text":""},{"location":"tutorials/time-series/Changepoints-Time-Series/#randomly-generate-changepoints","title":"Randomly generate changepoints\u00b6","text":""},{"location":"tutorials/time-series/Missingness-Time-Series/","title":"Generate missing data in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.missingness import MissingAtRandomGenerator\n</pre> import numpy as np import matplotlib.pyplot as plt from badgers.generators.time_series.missingness import MissingAtRandomGenerator In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>from sktime.datasets import load_airline\n</pre> from sktime.datasets import load_airline In\u00a0[4]: Copied! <pre>X = load_airline()\nt = X.index.to_timestamp()\n</pre> X = load_airline() t = X.index.to_timestamp() In\u00a0[5]: Copied! <pre>plt.plot(t, X.values)\n</pre> plt.plot(t, X.values) Out[5]: <pre>[&lt;matplotlib.lines.Line2D at 0x2e7bd6568d0&gt;]</pre> In\u00a0[6]: Copied! <pre>generator = MissingAtRandomGenerator(random_generator=rng)\n</pre> generator = MissingAtRandomGenerator(random_generator=rng) In\u00a0[7]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_missing=10)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_missing=10) In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[19]: Copied! <pre>X = np.random.normal(loc=(2,0), scale=(0.5, 0.1), size=(100,2))\n</pre> X = np.random.normal(loc=(2,0), scale=(0.5, 0.1), size=(100,2)) In\u00a0[20]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_missing=25)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_missing=25) In\u00a0[21]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(X)\naxes[0].set_title('Original data')\naxes[1].plot(Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(X) axes[0].set_title('Original data') axes[1].plot(Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Missingness-Time-Series/#generate-missing-data-in-time-series","title":"Generate missing data in time series\u00b6","text":""},{"location":"tutorials/time-series/Missingness-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Missingness-Time-Series/#import-data-using-sktime","title":"Import data (using sktime)\u00b6","text":""},{"location":"tutorials/time-series/Missingness-Time-Series/#missing-randomly-completly-at-random-1-dimension","title":"Missing randomly completly at random (1 Dimension)\u00b6","text":""},{"location":"tutorials/time-series/Missingness-Time-Series/#missing-randomly-completly-at-random-2-dimensions-and-more","title":"Missing randomly completly at random (2 Dimensions and more)\u00b6","text":""},{"location":"tutorials/time-series/Noise-Time-Series/","title":"Generate noise in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.noise import LocalGaussianNoiseGenerator, GlobalGaussianNoiseGenerator\nimport matplotlib.patches as patches\n</pre> import numpy as np import matplotlib.pyplot as plt from badgers.generators.time_series.noise import LocalGaussianNoiseGenerator, GlobalGaussianNoiseGenerator import matplotlib.patches as patches In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>from sktime.datasets import load_airline\n</pre> from sktime.datasets import load_airline In\u00a0[4]: Copied! <pre>X = load_airline()\nt = X.index.to_timestamp()\n</pre> X = load_airline() t = X.index.to_timestamp() In\u00a0[5]: Copied! <pre>plt.plot(t,X)\n</pre> plt.plot(t,X) Out[5]: <pre>[&lt;matplotlib.lines.Line2D at 0x21e3b5cd550&gt;]</pre> In\u00a0[6]: Copied! <pre>generator = GlobalGaussianNoiseGenerator(random_generator=rng)\n</pre> generator = GlobalGaussianNoiseGenerator(random_generator=rng) In\u00a0[7]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, noise_std=0.25)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, noise_std=0.25) In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[9]: Copied! <pre>generator = LocalGaussianNoiseGenerator(random_generator=rng)\n</pre> generator = LocalGaussianNoiseGenerator(random_generator=rng) In\u00a0[10]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, noise_std=0.25, min_width_pattern=8, max_width_patterns=12)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, noise_std=0.25, min_width_pattern=8, max_width_patterns=12) In\u00a0[11]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\n# show where the patterns are located\nbottom = np.min(Xt)\nheight = np.max(Xt) - np.min(Xt)\nfor start, end in generator.patterns_indices_:\n    width = end-start\n    left = X.index[start]\n    rect = plt.Rectangle((left, bottom), width, height,\n                         facecolor=\"red\", alpha=0.1)\n    axes[1].add_patch(rect)\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') # show where the patterns are located bottom = np.min(Xt) height = np.max(Xt) - np.min(Xt) for start, end in generator.patterns_indices_:     width = end-start     left = X.index[start]     rect = plt.Rectangle((left, bottom), width, height,                          facecolor=\"red\", alpha=0.1)     axes[1].add_patch(rect) plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Noise-Time-Series/#generate-noise-in-time-series","title":"Generate noise in time series\u00b6","text":""},{"location":"tutorials/time-series/Noise-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Noise-Time-Series/#import-data-using-sktime","title":"Import data (using sktime)\u00b6","text":""},{"location":"tutorials/time-series/Noise-Time-Series/#adding-gaussian-white-noise-on-the-full-time-series","title":"Adding Gaussian white noise on the full time series\u00b6","text":""},{"location":"tutorials/time-series/Noise-Time-Series/#adding-gaussian-white-noise-on-randomly-chosen-subsequences","title":"Adding Gaussian white noise on randomly chosen subsequences\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/","title":"Generate point outliers in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.outliers import LocalZScoreGenerator, RandomZerosGenerator\n</pre> import numpy as np import matplotlib.pyplot as plt from badgers.generators.time_series.outliers import LocalZScoreGenerator, RandomZerosGenerator In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>from sktime.datasets import load_airline\n</pre> from sktime.datasets import load_airline In\u00a0[4]: Copied! <pre>X = load_airline()\nt = X.index.to_timestamp()\n</pre> X = load_airline() t = X.index.to_timestamp() In\u00a0[5]: Copied! <pre>plt.plot(t, X.values)\n</pre> plt.plot(t, X.values) Out[5]: <pre>[&lt;matplotlib.lines.Line2D at 0x24c31804950&gt;]</pre> In\u00a0[6]: Copied! <pre>generator = RandomZerosGenerator(random_generator=rng)\n</pre> generator = RandomZerosGenerator(random_generator=rng) In\u00a0[7]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_outliers=10)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_outliers=10) In\u00a0[8]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[9]: Copied! <pre>generator = LocalZScoreGenerator(random_generator=rng)\n</pre> generator = LocalZScoreGenerator(random_generator=rng) In\u00a0[10]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_outliers=10,)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_outliers=10,) In\u00a0[11]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[12]: Copied! <pre>X = np.random.normal(loc=(2,0), scale=(0.5, 0.1), size=(100,2))\n</pre> X = np.random.normal(loc=(2,0), scale=(0.5, 0.1), size=(100,2)) In\u00a0[13]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_outliers=25)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_outliers=25) In\u00a0[14]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(X)\naxes[0].set_title('Original data')\naxes[1].plot(Xt)\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(X) axes[0].set_title('Original data') axes[1].plot(Xt) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Outliers-Time-Series/#generate-point-outliers-in-time-series","title":"Generate point outliers in time series\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/#import-data-using-sktime","title":"Import data (using sktime)\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/#randomly-change-values-to-zero","title":"Randomly change values to zero\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/#generate-local-extreme-values-1-dimension","title":"Generate local extreme values (1 Dimension)\u00b6","text":""},{"location":"tutorials/time-series/Outliers-Time-Series/#generate-local-extreme-values-2-dimensions-and-more","title":"Generate local extreme values (2 Dimensions and more)\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/","title":"Generate patterns in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.patterns import add_linear_trend, add_offset, scale, Pattern, RandomlySpacedPatterns, RandomlySpacedLinearPatterns, RandomlySpacedConstantPatterns\nimport matplotlib.patches as patches\n</pre> import numpy as np import matplotlib.pyplot as plt from badgers.generators.time_series.patterns import add_linear_trend, add_offset, scale, Pattern, RandomlySpacedPatterns, RandomlySpacedLinearPatterns, RandomlySpacedConstantPatterns import matplotlib.patches as patches In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>from sktime.datasets import load_airline\n</pre> from sktime.datasets import load_airline In\u00a0[4]: Copied! <pre>X = load_airline()\nt = X.index.to_timestamp()\n</pre> X = load_airline() t = X.index.to_timestamp() In\u00a0[5]: Copied! <pre>plt.plot(t, X.values)\n</pre> plt.plot(t, X.values) Out[5]: <pre>[&lt;matplotlib.lines.Line2D at 0x1ef8d8668d0&gt;]</pre> In\u00a0[6]: Copied! <pre>p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0]))\n</pre> p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0])) In\u00a0[7]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')\n</pre> fig, ax = plt.subplots() ax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original') Out[7]: <pre>[&lt;matplotlib.lines.Line2D at 0x1ef8d8c57d0&gt;]</pre> In\u00a0[8]: Copied! <pre>p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0]))\ngenerator = RandomlySpacedPatterns(random_generator=rng)\n</pre> p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0])) generator = RandomlySpacedPatterns(random_generator=rng) In\u00a0[9]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15, pattern=p)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15, pattern=p) In\u00a0[10]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\n# show where the patterns are located\nbottom = np.min(Xt)\nheight = np.max(Xt) - np.min(Xt)\nfor start, end in generator.patterns_indices_:\n    width = t[end]-t[start]\n    left = t[start]\n    rect = plt.Rectangle((left, bottom), width, height,\n                         facecolor=\"red\", alpha=0.1)\n    axes[1].add_patch(rect)\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') # show where the patterns are located bottom = np.min(Xt) height = np.max(Xt) - np.min(Xt) for start, end in generator.patterns_indices_:     width = t[end]-t[start]     left = t[start]     rect = plt.Rectangle((left, bottom), width, height,                          facecolor=\"red\", alpha=0.1)     axes[1].add_patch(rect) plt.tight_layout(); In\u00a0[11]: Copied! <pre>generator = RandomlySpacedConstantPatterns(random_generator=rng)\n</pre> generator = RandomlySpacedConstantPatterns(random_generator=rng) In\u00a0[12]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15, constant_value=0)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15, constant_value=0) In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\n# show where the patterns are located\nbottom = np.min(Xt)\nheight = np.max(Xt) - np.min(Xt)\nfor start, end in generator.patterns_indices_:\n    width = t[end]-t[start]\n    left = t[start]\n    rect = plt.Rectangle((left, bottom), width, height,\n                         facecolor=\"red\", alpha=0.1)\n    axes[1].add_patch(rect)\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') # show where the patterns are located bottom = np.min(Xt) height = np.max(Xt) - np.min(Xt) for start, end in generator.patterns_indices_:     width = t[end]-t[start]     left = t[start]     rect = plt.Rectangle((left, bottom), width, height,                          facecolor=\"red\", alpha=0.1)     axes[1].add_patch(rect) plt.tight_layout(); In\u00a0[14]: Copied! <pre>generator = RandomlySpacedLinearPatterns(random_generator=rng)\n</pre> generator = RandomlySpacedLinearPatterns(random_generator=rng) In\u00a0[15]: Copied! <pre>Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15,)\n</pre> Xt, _ = generator.generate(X.copy(), y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=15,) In\u00a0[16]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(t, X.values)\naxes[0].set_title('Original data')\naxes[1].plot(t, Xt)\naxes[1].set_title('Transformed data')\n# show where the patterns are located\nbottom = np.min(Xt)\nheight = np.max(Xt) - np.min(Xt)\nfor start, end in generator.patterns_indices_:\n    width = t[end]-t[start]\n    left = t[start]\n    rect = plt.Rectangle((left, bottom), width, height,\n                         facecolor=\"red\", alpha=0.1)\n    axes[1].add_patch(rect)\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(t, X.values) axes[0].set_title('Original data') axes[1].plot(t, Xt) axes[1].set_title('Transformed data') # show where the patterns are located bottom = np.min(Xt) height = np.max(Xt) - np.min(Xt) for start, end in generator.patterns_indices_:     width = t[end]-t[start]     left = t[start]     rect = plt.Rectangle((left, bottom), width, height,                          facecolor=\"red\", alpha=0.1)     axes[1].add_patch(rect) plt.tight_layout(); In\u00a0[17]: Copied! <pre>p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0]))\n</pre> p = Pattern(values=np.array([0,0.2,0.1,0.3,0.2,0.4,-0.4,-0.2,-0.3,-0.1,-0.2,-0.0])) In\u00a0[18]: Copied! <pre>upsampled_pattern = p.resample(nb_point=30)\ndownsampled_pattern = p.resample(nb_point=5)\n\nfig, ax = plt.subplots()\nax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')\nax.plot(np.linspace(0,1,len(upsampled_pattern)), upsampled_pattern, 'o', ls='--', color='C1', label='upsampled')\nax.plot(np.linspace(0,1,len(downsampled_pattern)), downsampled_pattern, 'o', ls='--', color='C2', label='downsampled')\nplt.legend()\n</pre> upsampled_pattern = p.resample(nb_point=30) downsampled_pattern = p.resample(nb_point=5)  fig, ax = plt.subplots() ax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original') ax.plot(np.linspace(0,1,len(upsampled_pattern)), upsampled_pattern, 'o', ls='--', color='C1', label='upsampled') ax.plot(np.linspace(0,1,len(downsampled_pattern)), downsampled_pattern, 'o', ls='--', color='C2', label='downsampled') plt.legend() Out[18]: <pre>&lt;matplotlib.legend.Legend at 0x1ef8fc4bbd0&gt;</pre> In\u00a0[19]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')\n\nfor i, (start, end) in enumerate([(0,0.5),(0.5,-0.5)]):\n    ax.plot(np.linspace(0,1,len(p.values)), add_linear_trend(p.values, start_value=start, end_value=end), 'o', ls='--', color=f'C{i+1}', label=f'trend ({start}, {end})')\n\nplt.legend()\n</pre> fig, ax = plt.subplots() ax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')  for i, (start, end) in enumerate([(0,0.5),(0.5,-0.5)]):     ax.plot(np.linspace(0,1,len(p.values)), add_linear_trend(p.values, start_value=start, end_value=end), 'o', ls='--', color=f'C{i+1}', label=f'trend ({start}, {end})')  plt.legend() Out[19]: <pre>&lt;matplotlib.legend.Legend at 0x1ef902bb110&gt;</pre> In\u00a0[20]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')\n\nfor i, offset in enumerate([0.5,-0.5]):\n    ax.plot(np.linspace(0,1,len(p.values)), add_offset(p.values, offset), 'o', ls='--', color=f'C{i+1}', label=f'offset ({offset})')\n\nplt.legend()\n</pre> fig, ax = plt.subplots() ax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')  for i, offset in enumerate([0.5,-0.5]):     ax.plot(np.linspace(0,1,len(p.values)), add_offset(p.values, offset), 'o', ls='--', color=f'C{i+1}', label=f'offset ({offset})')  plt.legend() Out[20]: <pre>&lt;matplotlib.legend.Legend at 0x1ef8fe56310&gt;</pre> In\u00a0[21]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')\n\nfor i, scaling_factor in enumerate([-0.5,2]):\n    ax.plot(np.linspace(0,1,len(p.values)), scale(p.values, scaling_factor), 'o', ls='--', color=f'C{i+1}', label=f'scale ({scaling_factor})')\n\nplt.legend()\n</pre> fig, ax = plt.subplots() ax.plot(np.linspace(0,1,len(p.values)), p.values, 'o', ls='-', color='C0', label='original')  for i, scaling_factor in enumerate([-0.5,2]):     ax.plot(np.linspace(0,1,len(p.values)), scale(p.values, scaling_factor), 'o', ls='--', color=f'C{i+1}', label=f'scale ({scaling_factor})')  plt.legend() Out[21]: <pre>&lt;matplotlib.legend.Legend at 0x1ef8fe33410&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Patterns-Time-Series/#generate-patterns-in-time-series","title":"Generate patterns in time series\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#import-data-using-sktime","title":"Import data (using sktime)\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#injecting-a-predefined-pattern","title":"Injecting a predefined Pattern\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#defining-a-pattern","title":"Defining a pattern\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#inject-predefined-patterns-randomly-spaced","title":"Inject predefined patterns (randomly spaced)\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#generate-patterns-subsequences-with-constant-values-randomly-spaced","title":"Generate patterns (subsequences) with constant values (randomly spaced)\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#generate-patterns-with-constant-slope-randomly-spaced","title":"Generate patterns with constant slope (randomly spaced)\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#behind-the-scene-functions-to-manipulate-patterns","title":"Behind the scene: functions to manipulate patterns\u00b6","text":""},{"location":"tutorials/time-series/Patterns-Time-Series/#resampling-a-pattern","title":"Resampling a pattern\u00b6","text":"<p>The Pattern class provides a method for resampling a pattern. It is based on Cubic Spline Interpolation</p>"},{"location":"tutorials/time-series/Patterns-Time-Series/#add-a-linear-trend-to-the-pattern","title":"Add a linear trend to the pattern\u00b6","text":"<p>The function <code>add_linear_trend</code> takes three arguments: the values to be transformed, a start_value (were the new pattern should start) and end_value (where the new pattern should end)</p>"},{"location":"tutorials/time-series/Patterns-Time-Series/#add-an-offset-bias-to-the-pattern","title":"Add an offset (bias) to the pattern\u00b6","text":"<p>The function <code>add_offset</code> takes two arguments: the values to be transformed and an offset (float or int)</p>"},{"location":"tutorials/time-series/Patterns-Time-Series/#scale-a-pattern","title":"Scale a pattern\u00b6","text":""},{"location":"tutorials/time-series/Seasons-Time-Series/","title":"Generate seasons in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.seasons import GlobalAdditiveSinusoidalSeasonGenerator\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from badgers.generators.time_series.seasons import GlobalAdditiveSinusoidalSeasonGenerator In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>X = pd.DataFrame(data=rng.normal(loc=0, scale=0.1, size=(100, 2)), columns=['dimension_0', 'dimension_1'])\n</pre> X = pd.DataFrame(data=rng.normal(loc=0, scale=0.1, size=(100, 2)), columns=['dimension_0', 'dimension_1']) In\u00a0[4]: Copied! <pre>X.plot(subplots=True)\n</pre> X.plot(subplots=True) Out[4]: <pre>array([&lt;Axes: &gt;, &lt;Axes: &gt;], dtype=object)</pre> In\u00a0[5]: Copied! <pre>generator = GlobalAdditiveSinusoidalSeasonGenerator(random_generator=rng)\n</pre> generator = GlobalAdditiveSinusoidalSeasonGenerator(random_generator=rng) In\u00a0[6]: Copied! <pre>Xt, _ = generator.generate(X=X, y=None, period=np.array([10,50]))\n</pre> Xt, _ = generator.generate(X=X, y=None, period=np.array([10,50])) In\u00a0[7]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\nX.plot(ax=axes[0])\naxes[0].set_title('Original data')\nXt.plot(ax=axes[1])\naxes[1].set_title('Transformed data')\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) X.plot(ax=axes[0]) axes[0].set_title('Original data') Xt.plot(ax=axes[1]) axes[1].set_title('Transformed data') plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Seasons-Time-Series/#generate-seasons-in-time-series","title":"Generate seasons in time series\u00b6","text":""},{"location":"tutorials/time-series/Seasons-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Seasons-Time-Series/#generate-data-gaussian-white-noise","title":"Generate data (gaussian white noise)\u00b6","text":""},{"location":"tutorials/time-series/Seasons-Time-Series/#add-sinusoidal-season","title":"Add sinusoidal season\u00b6","text":""},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/","title":"Generate \"transmission errors\" in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.transmission_errors import RandomTimeSwitchGenerator, RandomRepeatGenerator, RandomDropGenerator, LocalRegionsRandomDropGenerator, LocalRegionsRandomRepeatGenerator\nimport matplotlib.patches as patches\n</pre> import numpy as np import matplotlib.pyplot as plt from badgers.generators.time_series.transmission_errors import RandomTimeSwitchGenerator, RandomRepeatGenerator, RandomDropGenerator, LocalRegionsRandomDropGenerator, LocalRegionsRandomRepeatGenerator import matplotlib.patches as patches In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>from sktime.datasets import load_airline\n</pre> from sktime.datasets import load_airline In\u00a0[4]: Copied! <pre>X = load_airline()\nt = X.index.to_timestamp()\n</pre> X = load_airline() t = X.index.to_timestamp() In\u00a0[5]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(X.values)\nax.set_title('original data')\nplt.tight_layout()\n</pre> fig, ax = plt.subplots() ax.plot(X.values) ax.set_title('original data') plt.tight_layout() In\u00a0[6]: Copied! <pre>generator = RandomTimeSwitchGenerator(random_generator=rng)\nXt, y = generator.generate(X=X.copy(), y=None, n_switches=20)\n</pre> generator = RandomTimeSwitchGenerator(random_generator=rng) Xt, y = generator.generate(X=X.copy(), y=None, n_switches=20) In\u00a0[7]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(X.values, alpha=0.5, ls='-', marker='.', label='original')\nax.plot(Xt.values, alpha=0.5, ls='-', marker='.', label='with random switches')\nax.set_xlabel('time units (arrows show where the switch occured)')\nfor i in generator.switch_indices_:\n    ax.arrow(i,0,0,50, head_width=2, head_length=10)\n\nplt.legend()\nplt.tight_layout()\n</pre> fig, ax = plt.subplots() ax.plot(X.values, alpha=0.5, ls='-', marker='.', label='original') ax.plot(Xt.values, alpha=0.5, ls='-', marker='.', label='with random switches') ax.set_xlabel('time units (arrows show where the switch occured)') for i in generator.switch_indices_:     ax.arrow(i,0,0,50, head_width=2, head_length=10)  plt.legend() plt.tight_layout() In\u00a0[8]: Copied! <pre>generator = RandomRepeatGenerator(random_generator=rng)\nXt, y = generator.generate(X=X.copy(), y=None, n_repeats=5, min_nb_repeats=3, max_nb_repeats=10)\n</pre> generator = RandomRepeatGenerator(random_generator=rng) Xt, y = generator.generate(X=X.copy(), y=None, n_repeats=5, min_nb_repeats=3, max_nb_repeats=10) In\u00a0[9]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(X.values, color='C0')\naxes[1].plot(Xt.values, color='C1')\naxes[0].set_title('Original')\naxes[1].set_title('Transformed')\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(X.values, color='C0') axes[1].plot(Xt.values, color='C1') axes[0].set_title('Original') axes[1].set_title('Transformed') plt.tight_layout() In\u00a0[10]: Copied! <pre>generator = LocalRegionsRandomRepeatGenerator(random_generator=rng)\nXt, y = generator.generate(X=X.copy(), y=None, n_repeats=10, min_nb_repeats=1, max_nb_repeats=4, n_regions=3, min_width_regions=5, max_width_regions=15)\n</pre> generator = LocalRegionsRandomRepeatGenerator(random_generator=rng) Xt, y = generator.generate(X=X.copy(), y=None, n_repeats=10, min_nb_repeats=1, max_nb_repeats=4, n_regions=3, min_width_regions=5, max_width_regions=15) In\u00a0[11]: Copied! <pre>fig, axes = plt.subplots(3, sharex=True, sharey=False, figsize=(6,8))\naxes[0].plot(X.values, color='C0')\naxes[1].plot(generator.repeats_probabilities_, color='C2')\naxes[2].plot(Xt.values, color='C1')\naxes[0].set_title('Original (arrows show where points were repeated)')\naxes[1].set_title('Repeat probability')\naxes[2].set_title('Transformed')\n\nfor i, l in generator.repeats_:\n    axes[0].arrow(i,0,0,50, head_width=2, head_length=10)\n\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(3, sharex=True, sharey=False, figsize=(6,8)) axes[0].plot(X.values, color='C0') axes[1].plot(generator.repeats_probabilities_, color='C2') axes[2].plot(Xt.values, color='C1') axes[0].set_title('Original (arrows show where points were repeated)') axes[1].set_title('Repeat probability') axes[2].set_title('Transformed')  for i, l in generator.repeats_:     axes[0].arrow(i,0,0,50, head_width=2, head_length=10)  plt.tight_layout() In\u00a0[12]: Copied! <pre>generator = RandomDropGenerator(random_generator=rng)\nXt, y = generator.generate(X=X.copy(), y=None, n_drops=10)\n</pre> generator = RandomDropGenerator(random_generator=rng) Xt, y = generator.generate(X=X.copy(), y=None, n_drops=10) In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\naxes[0].plot(X.values, color='C0')\naxes[1].plot(Xt.values, color='C1')\naxes[0].set_title('Original (arrows show where points were dropped)')\naxes[1].set_title('Transformed')\n\nfor i in generator.drops_indices_:\n    axes[0].arrow(i,0,0,50, head_width=2, head_length=10)\n\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) axes[0].plot(X.values, color='C0') axes[1].plot(Xt.values, color='C1') axes[0].set_title('Original (arrows show where points were dropped)') axes[1].set_title('Transformed')  for i in generator.drops_indices_:     axes[0].arrow(i,0,0,50, head_width=2, head_length=10)  plt.tight_layout() In\u00a0[14]: Copied! <pre>generator = LocalRegionsRandomDropGenerator(random_generator=rng)\nXt, y = generator.generate(X=X.copy(), y=None, n_drops=10, n_regions=3, min_width_regions=5, max_width_regions=15)\n</pre> generator = LocalRegionsRandomDropGenerator(random_generator=rng) Xt, y = generator.generate(X=X.copy(), y=None, n_drops=10, n_regions=3, min_width_regions=5, max_width_regions=15) In\u00a0[15]: Copied! <pre>fig, axes = plt.subplots(3, sharex=True, sharey=False, figsize=(6,8))\naxes[0].plot(X.values, color='C0')\naxes[1].plot(generator.drops_probabilities_, color='C2')\naxes[2].plot(Xt.values, color='C1')\naxes[0].set_title('Original (arrows show where points were dropped)')\naxes[1].set_title('Drop probability')\naxes[2].set_title('Transformed')\n\nfor i in generator.drops_indices_:\n    axes[0].arrow(i,0,0,50, head_width=2, head_length=10)\n\nplt.tight_layout()\n</pre> fig, axes = plt.subplots(3, sharex=True, sharey=False, figsize=(6,8)) axes[0].plot(X.values, color='C0') axes[1].plot(generator.drops_probabilities_, color='C2') axes[2].plot(Xt.values, color='C1') axes[0].set_title('Original (arrows show where points were dropped)') axes[1].set_title('Drop probability') axes[2].set_title('Transformed')  for i in generator.drops_indices_:     axes[0].arrow(i,0,0,50, head_width=2, head_length=10)  plt.tight_layout() In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#generate-transmission-errors-in-time-series","title":"Generate \"transmission errors\" in time series\u00b6","text":"<p>These are errors that affects time index, for example: repeating values x(t) several times, dropping value x(t), or switching x(t) with x(t+1), etc.</p>"},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#import-data-using-sktime","title":"Import data (using sktime)\u00b6","text":""},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#generating-random-switches-in-time","title":"Generating random switches in time\u00b6","text":"<p>Where x(t) and x(t+1) are switched</p>"},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#randomly-repeating-values-equivalent-to-delays","title":"Randomly repeating values (equivalent to delays)\u00b6","text":"<p>Where x(t) is repeated several times</p>"},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#repeating-values-in-certain-regions-of-time-time-intervals","title":"Repeating values in certain regions of time (time intervals)\u00b6","text":""},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#randomly-dropping-values","title":"Randomly dropping values\u00b6","text":"<p>This is different from missingness as in missingness the time index in not affected</p>"},{"location":"tutorials/time-series/Transmission-Errors-Time-Series/#dropping-values-in-certain-regions-of-time-certain-time-intervals","title":"Dropping values in certain regions of time (certain time intervals)\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/","title":"Generate trends / drift in time series","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom badgers.generators.time_series.trends import GlobalAdditiveLinearTrendGenerator, AdditiveLinearTrendGenerator, RandomlySpacedLinearTrends\n</pre> import numpy as np import pandas as pd import matplotlib.pyplot as plt from badgers.generators.time_series.trends import GlobalAdditiveLinearTrendGenerator, AdditiveLinearTrendGenerator, RandomlySpacedLinearTrends In\u00a0[2]: Copied! <pre>from numpy.random import default_rng\nseed = 0\nrng = default_rng(seed)\n</pre> from numpy.random import default_rng seed = 0 rng = default_rng(seed) In\u00a0[3]: Copied! <pre>X = pd.DataFrame(data=rng.normal(loc=0, scale=0.1, size=(100, 2)), columns=['dimension_0', 'dimension_1'])\n</pre> X = pd.DataFrame(data=rng.normal(loc=0, scale=0.1, size=(100, 2)), columns=['dimension_0', 'dimension_1'])  In\u00a0[4]: Copied! <pre>fig, ax = plt.subplots(1, sharex=True, sharey=True, figsize=(6,3))\nX.plot(ax=ax);\n</pre> fig, ax = plt.subplots(1, sharex=True, sharey=True, figsize=(6,3)) X.plot(ax=ax); In\u00a0[5]: Copied! <pre>generator = GlobalAdditiveLinearTrendGenerator(random_generator=rng)\n</pre> generator = GlobalAdditiveLinearTrendGenerator(random_generator=rng) In\u00a0[6]: Copied! <pre>slope = np.array([0.01,-0.02]) # slope: increase per time unit\nXt, _ = generator.generate(X, y=None, slope=slope)\n</pre> slope = np.array([0.01,-0.02]) # slope: increase per time unit Xt, _ = generator.generate(X, y=None, slope=slope) In\u00a0[7]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\n# first plot: original data\nX.plot(ax=axes[0])\naxes[0].set_title('Original data')\n\n# second plot: transformed data\n# visualizing added trends\naxes[1].plot([0,len(X)],[0,len(X)*slope[0]], ls='--', linewidth=1, color='red')\naxes[1].plot([0,len(X)],[0,len(X)*slope[1]], ls='--', linewidth=1, color='red')\nXt.plot(ax=axes[1])\naxes[1].set_title('Transformed data')\n\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) # first plot: original data X.plot(ax=axes[0]) axes[0].set_title('Original data')  # second plot: transformed data # visualizing added trends axes[1].plot([0,len(X)],[0,len(X)*slope[0]], ls='--', linewidth=1, color='red') axes[1].plot([0,len(X)],[0,len(X)*slope[1]], ls='--', linewidth=1, color='red') Xt.plot(ax=axes[1]) axes[1].set_title('Transformed data')  plt.tight_layout(); In\u00a0[8]: Copied! <pre>generator = AdditiveLinearTrendGenerator(random_generator=rng)\n</pre> generator = AdditiveLinearTrendGenerator(random_generator=rng) In\u00a0[9]: Copied! <pre>slope = np.array([0.01,-0.02])\nstart = 25\nend = 75\nXt, _ = generator.generate(X, y=None, slope=slope, start=start, end=end)\n</pre> slope = np.array([0.01,-0.02]) start = 25 end = 75 Xt, _ = generator.generate(X, y=None, slope=slope, start=start, end=end) In\u00a0[10]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\n# first plot: original data\nX.plot(ax=axes[0])\naxes[0].set_title('Original data')\n\n# second plot: transformed data\n# visualizing added trends\naxes[1].plot([start,end],[Xt.iloc[start,0],Xt.iloc[start,0] + (end-start)*slope[0]], ls='--', linewidth=1, color='red')\naxes[1].plot([start,end],[Xt.iloc[start,1],Xt.iloc[start,1] + (end-start)*slope[1]], ls='--', linewidth=1, color='red')\nXt.plot(ax=axes[1])\naxes[1].set_title('Transformed data')\n\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) # first plot: original data X.plot(ax=axes[0]) axes[0].set_title('Original data')  # second plot: transformed data # visualizing added trends axes[1].plot([start,end],[Xt.iloc[start,0],Xt.iloc[start,0] + (end-start)*slope[0]], ls='--', linewidth=1, color='red') axes[1].plot([start,end],[Xt.iloc[start,1],Xt.iloc[start,1] + (end-start)*slope[1]], ls='--', linewidth=1, color='red') Xt.plot(ax=axes[1]) axes[1].set_title('Transformed data')  plt.tight_layout(); In\u00a0[11]: Copied! <pre>generator = RandomlySpacedLinearTrends(random_generator=rng)\n</pre> generator = RandomlySpacedLinearTrends(random_generator=rng) In\u00a0[12]: Copied! <pre>Xt, _ = generator.generate(X, y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=10, slope_min=-0.1, slope_max=0.1)\n</pre> Xt, _ = generator.generate(X, y=None, n_patterns=5, min_width_pattern=5, max_width_patterns=10, slope_min=-0.1, slope_max=0.1) In\u00a0[13]: Copied! <pre>fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6))\n# first plot: original data\nX.plot(ax=axes[0])\naxes[0].set_title('Original data')\n\n# second plot: transformed data\nXt.plot(ax=axes[1])\naxes[1].set_title('Transformed data')\n\n# show where the patterns are located\nbottom = np.min(Xt)\nheight = np.max(Xt) - np.min(Xt)\nfor (start, end), slope in zip(generator.patterns_indices_, generator.slopes_):\n    # add red rectangle for visualizing the time interval\n    width = end-start\n    left = start\n    rect = plt.Rectangle((left, bottom), width, height,\n                         facecolor=\"red\", alpha=0.1)\n    axes[1].add_patch(rect)\n    # vizualizing trends\n    axes[1].plot([start,end],[Xt.iloc[start,0],Xt.iloc[start,0] + (end-start)*slope[0]], ls='--', linewidth=1, color='red')\n    axes[1].plot([start,end],[Xt.iloc[start,1],Xt.iloc[start,1] + (end-start)*slope[1]], ls='--', linewidth=1, color='red')\n\nplt.tight_layout();\n</pre> fig, axes = plt.subplots(2, sharex=True, sharey=True, figsize=(6,6)) # first plot: original data X.plot(ax=axes[0]) axes[0].set_title('Original data')  # second plot: transformed data Xt.plot(ax=axes[1]) axes[1].set_title('Transformed data')  # show where the patterns are located bottom = np.min(Xt) height = np.max(Xt) - np.min(Xt) for (start, end), slope in zip(generator.patterns_indices_, generator.slopes_):     # add red rectangle for visualizing the time interval     width = end-start     left = start     rect = plt.Rectangle((left, bottom), width, height,                          facecolor=\"red\", alpha=0.1)     axes[1].add_patch(rect)     # vizualizing trends     axes[1].plot([start,end],[Xt.iloc[start,0],Xt.iloc[start,0] + (end-start)*slope[0]], ls='--', linewidth=1, color='red')     axes[1].plot([start,end],[Xt.iloc[start,1],Xt.iloc[start,1] + (end-start)*slope[1]], ls='--', linewidth=1, color='red')  plt.tight_layout(); In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/time-series/Trends-Time-Series/#generate-trends-drift-in-time-series","title":"Generate trends / drift in time series\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/#setup-random-generator","title":"Setup random generator\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/#generate-data-gaussian-white-noise","title":"Generate data (gaussian white noise)\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/#add-linear-trend","title":"Add linear trend\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/#add-linear-trend-for-a-specific-time-interval","title":"Add linear trend for a specific time interval\u00b6","text":""},{"location":"tutorials/time-series/Trends-Time-Series/#adding-linear-trends-of-random-slopes-in-randomly-chosen-time-intervals","title":"Adding linear trends (of random slopes) in randomly chosen time intervals\u00b6","text":""}]}